[{
"title":"高级算法模板",
"permalink": "http://localhost:1313/posts/datastructalgorithm/%E9%AB%98%E7%BA%A7%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/",
"summary": " ✅ 总目录（你只要按这个顺序掌握） 类别 内容 定位 一、前缀和 \u0026amp; 差分 区间加减 → O(1) 求和 高频基础 二、字符串 KMP、Trie 面试常客 三、BFS / DFS 多源 BFS，分层 BFS 图模板 四、拓扑排序 DAG 处理 调度/依赖 五、树与图 树直径、并查集、Dijkstra 中高级 六、回溯 子集 / N 皇后 / 剪枝 模板化即可 七、状态压缩 DP 子集 DP / bitmask 稍难但高频 八、数学 快速幂 / gcd / 组合数 必备基础 一、前缀和 \u0026amp; 差分 ✅ 前缀和（快速求区间和） sum[i] = nums[0] + ... + nums[i] 区间 [l, r] 的和 = sum[r] - sum[l-1] func prefixSum(nums []int) []int { n := len(nums) pre := make([]int, n+1) for i := 1; i \u0026lt;= n; i++ { pre[i] = pre[i-1] + nums[i-1] } return pre } ✅ 差分（区间加值） diff[i] = nums[i] - nums[i-1] 区间加 k：diff[l] += k, diff[r+1] -= k func diffBuild(nums []int) []int { n := len(nums) diff := make([]int, n) diff[0] = nums[0] for i := 1; i \u0026lt; n; i++ { diff[i] = nums[i] - nums[i-1] } return diff } func diffApply(diff []int) []int { for i := 1; i \u0026lt; len(diff); i++ { diff[i] += diff[i-1] } return diff } 二、字符串 ✅ KMP（快速匹配） 核心：求 next 数组（最长前后缀相等长度）\n",
"content": " ✅ 总目录（你只要按这个顺序掌握） 类别 内容 定位 一、前缀和 \u0026amp; 差分 区间加减 → O(1) 求和 高频基础 二、字符串 KMP、Trie 面试常客 三、BFS / DFS 多源 BFS，分层 BFS 图模板 四、拓扑排序 DAG 处理 调度/依赖 五、树与图 树直径、并查集、Dijkstra 中高级 六、回溯 子集 / N 皇后 / 剪枝 模板化即可 七、状态压缩 DP 子集 DP / bitmask 稍难但高频 八、数学 快速幂 / gcd / 组合数 必备基础 一、前缀和 \u0026amp; 差分 ✅ 前缀和（快速求区间和） sum[i] = nums[0] + ... + nums[i] 区间 [l, r] 的和 = sum[r] - sum[l-1] func prefixSum(nums []int) []int { n := len(nums) pre := make([]int, n+1) for i := 1; i \u0026lt;= n; i++ { pre[i] = pre[i-1] + nums[i-1] } return pre } ✅ 差分（区间加值） diff[i] = nums[i] - nums[i-1] 区间加 k：diff[l] += k, diff[r+1] -= k func diffBuild(nums []int) []int { n := len(nums) diff := make([]int, n) diff[0] = nums[0] for i := 1; i \u0026lt; n; i++ { diff[i] = nums[i] - nums[i-1] } return diff } func diffApply(diff []int) []int { for i := 1; i \u0026lt; len(diff); i++ { diff[i] += diff[i-1] } return diff } 二、字符串 ✅ KMP（快速匹配） 核心：求 next 数组（最长前后缀相等长度）\nfunc buildNext(p string) []int { n := len(p) next := make([]int, n) j := 0 for i := 1; i \u0026lt; n; i++ { for j \u0026gt; 0 \u0026amp;\u0026amp; p[i] != p[j] { j = next[j-1] } if p[i] == p[j] { j++ } next[i] = j } return next } ✅ Trie 字典树 type Trie struct{ next [26]*Trie; end bool } func (t *Trie) Insert(s string) { cur := t for _, c := range s { idx := c - \u0026#39;a\u0026#39; if cur.next[idx] == nil { cur.next[idx] = \u0026amp;Trie{} } cur = cur.next[idx] } cur.end = true } 三、BFS / DFS ✅ BFS（无权图最短路） func bfs(start int, g map[int][]int) []int { dist := map[int]int{start: 0} q := []int{start} for len(q) \u0026gt; 0 { x := q[0]; q = q[1:] for _, y := range g[x] { if _, seen := dist[y]; !seen { dist[y] = dist[x] + 1 q = append(q, y) } } } return dist } ✅ DFS（搜索 / 连通块） func dfs(x int, g map[int][]int, vis map[int]bool) { vis[x] = true for _, y := range g[x] { if !vis[y] { dfs(y, g, vis) } } } 四、拓扑排序（DAG） func topoSort(g map[int][]int, indeg []int) []int { q := []int{} for i, d := range indeg { if d == 0 { q = append(q, i) } } order := []int{} for len(q) \u0026gt; 0 { x := q[0]; q = q[1:] order = append(order, x) for _, y := range g[x] { indeg[y]-- if indeg[y] == 0 { q = append(q, y) } } } return order } 五、树 \u0026amp; 图 ✅ 树的直径（两次 BFS） 任取 A → 找到最远点 B 从 B 再 BFS → 得到最远点距离，即为直径 ✅ 并查集 type DSU struct{ fa []int } func NewDSU(n int) *DSU { fa := make([]int, n) for i := range fa { fa[i] = i } return \u0026amp;DSU{fa} } func (d *DSU) Find(x int) int { if d.fa[x] != x { d.fa[x] = d.Find(d.fa[x]) } return d.fa[x] } func (d *DSU) Union(a, b int) { d.fa[d.Find(a)] = d.Find(b) } ✅ Dijkstra（带权最短路） type Pair struct{ d, x int } func dijkstra(n int, g map[int][]Pair, src int) []int { const inf = 1e18 dist := make([]int, n) for i := range dist { dist[i] = inf } dist[src] = 0 h := \u0026amp;MinHeap{}; heap.Push(h, Pair{0, src}) for h.Len() \u0026gt; 0 { p := heap.Pop(h).(Pair) if p.d \u0026gt; dist[p.x] { continue } for _, e := range g[p.x] { if dist[e.x] \u0026gt; p.d + e.d { dist[e.x] = p.d + e.d heap.Push(h, Pair{dist[e.x], e.x}) } } } return dist } 六、回溯模板（通杀子集 / 排列 / N 皇后） var res [][]int var path []int func backtrack(nums []int, start int) { res = append(res, append([]int(nil), path...)) for i := start; i \u0026lt; len(nums); i++ { path = append(path, nums[i]) backtrack(nums, i+1) path = path[:len(path)-1] } } 七、状态压缩 DP（经典模板） dp[mask]：表示子集 mask 的最优值 for each sub = mask 的子集: dp[mask] = min(dp[mask], dp[sub] + dp[mask-sub]) 八、数学 func gcd(a, b int) int { if b==0 { return a }; return gcd(b, a%b) } func fastPow(a, b, mod int) int { res := 1 for b \u0026gt; 0 { if b\u0026amp;1 == 1 { res = res*a % mod } a = a*a % mod b \u0026gt;\u0026gt;= 1 } return res } ",
"tags":null,
"categories":null
},{
"title":"延时队列",
"permalink": "http://localhost:1313/posts/scenario/%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97/",
"summary": "使用 Redis Sorted Set (ZSet) 实现延时队列（Delay Queue）是一种高效且常用的方法，因为它利用了 ZSet 的核心特性：元素有序。\n以下是基于 Redis ZSet 设计延时队列的详细步骤、关键操作和代码逻辑。\n基于 Redis ZSet 的延时队列设计 1. 核心数据结构 组件 Redis 数据结构 存储内容 ZSet Score (分数) ZSet Member (成员) 作用 延迟队列 Sorted Set (ZSet) 待执行任务 任务执行时间戳 (毫秒或秒) 任务的唯一 ID (例如：order:123, task:456) 核心结构，按执行时间排序 任务详情 Hash 或 String 任务的具体内容 N/A 任务 ID 存储任务执行所需的所有数据 2. 三个核心操作 一个完整的延时队列系统由三个主要角色构成：生产者（Producer）、消费者/扫描器（Consumer/Scanner） 和 任务处理器（Executor）。\n2.1 生产者：投递任务（将任务放入队列） 生产者负责将一个任务及其计划执行时间写入 Redis。\n操作步骤：\n确定执行时间： 计算任务应被执行的精确时间戳 T。 存储任务详情： 将任务的全部信息（如订单号、用户ID等）存储到 Redis 的 Hash 或 String 结构中，以任务 ID 为 Key。 加入 ZSet： 将任务的 ID 作为 Member，将时间戳 T 作为 Score，存入延迟队列 ZSet 中。 Redis 命令示例：\n",
"content": "使用 Redis Sorted Set (ZSet) 实现延时队列（Delay Queue）是一种高效且常用的方法，因为它利用了 ZSet 的核心特性：元素有序。\n以下是基于 Redis ZSet 设计延时队列的详细步骤、关键操作和代码逻辑。\n基于 Redis ZSet 的延时队列设计 1. 核心数据结构 组件 Redis 数据结构 存储内容 ZSet Score (分数) ZSet Member (成员) 作用 延迟队列 Sorted Set (ZSet) 待执行任务 任务执行时间戳 (毫秒或秒) 任务的唯一 ID (例如：order:123, task:456) 核心结构，按执行时间排序 任务详情 Hash 或 String 任务的具体内容 N/A 任务 ID 存储任务执行所需的所有数据 2. 三个核心操作 一个完整的延时队列系统由三个主要角色构成：生产者（Producer）、消费者/扫描器（Consumer/Scanner） 和 任务处理器（Executor）。\n2.1 生产者：投递任务（将任务放入队列） 生产者负责将一个任务及其计划执行时间写入 Redis。\n操作步骤：\n确定执行时间： 计算任务应被执行的精确时间戳 T。 存储任务详情： 将任务的全部信息（如订单号、用户ID等）存储到 Redis 的 Hash 或 String 结构中，以任务 ID 为 Key。 加入 ZSet： 将任务的 ID 作为 Member，将时间戳 T 作为 Score，存入延迟队列 ZSet 中。 Redis 命令示例：\n# 假设延迟 30 分钟，当前时间为 1678886400 (秒级时间戳) # 计划执行时间 T = 1678886400 + 1800 = 1678888200 # 1. 存储任务详情（使用 Hash 结构） HSET task_detail:order:123 \u0026#34;order_id\u0026#34; \u0026#34;123\u0026#34; \u0026#34;user_id\u0026#34; \u0026#34;A\u0026#34; \u0026#34;action\u0026#34; \u0026#34;cancel\u0026#34; # 2. 加入延迟队列 ZSet ZADD delay_queue 1678888200 order:123 2.2 消费者/扫描器：轮询和提取任务（定时拉取） 消费者/扫描器是一个后台常驻进程，它定时（例如每秒）查询 ZSet 中哪些任务已到期。\n关键在于原子性地取出任务。\n操作步骤：\n查询到期任务： 使用 ZRANGEBYSCORE 命令，查询 Score (时间戳) 小于或等于当前时间戳 Now 的所有任务 ID。因为 ZSet 是有序的，这些就是最早到期的任务。\n原子性移除： 使用 ZREM 命令，从 ZSet 中移除上一步查询到的所有任务 ID。\n注意： 在分布式环境中，为了确保只有一个 Worker 拿到并处理任务，通常需要使用 Lua 脚本将 查询 和 移除 这两步合并成一个原子操作。 Redis 命令示例（使用 Lua 脚本实现原子性 Pop）：\n-- Lua 脚本： local key = KEYS[1] -- delay_queue 的 Key local now_timestamp = ARGV[1] -- 当前时间戳 -- 1. 查询所有 Score 小于等于当前时间戳的 Member（最多查询 N 个，这里假设 100 个） local expired_members = redis.call(\u0026#39;ZRANGEBYSCORE\u0026#39;, key, \u0026#39;-inf\u0026#39;, now_timestamp, \u0026#39;LIMIT\u0026#39;, 0, 100) if #expired_members \u0026gt; 0 then -- 2. 移除这些 Member redis.call(\u0026#39;ZREM\u0026#39;, key, unpack(expired_members)) return expired_members else return {} end 这个 Lua 脚本保证了任务的原子性获取：查询到到期任务后，立即将其移除，避免了多个扫描器进程同时拿到同一个任务。\n2.3 任务处理器：执行任务 拿到任务 ID 后，任务处理器执行实际的业务逻辑。\n操作步骤：\n获取任务详情： 根据任务 ID，从存储任务详情的 Hash 或 String 中取出任务的全部内容。 执行业务： 执行取消订单、发放奖励等业务逻辑。 清理详情： 业务逻辑执行成功后，删除任务详情 Key。 Redis 命令示例：\n# 假设拿到任务 ID: order:123 # 1. 获取任务详情 HGETALL task_detail:order:123 # 2. 执行业务逻辑... # 3. 清理详情 DEL task_detail:order:123 3. 分布式环境下的关键设计点 在实际的生产环境中，系统通常是分布式的，需要解决以下问题：\nA. 扫描器的高可用和去重 问题： 多个服务器都在运行扫描器进程，如何确保只有一个进程在工作，或者如何避免任务被重复处理？ 解决方案： 分布式锁（推荐）： 在多个扫描器进程启动时，竞争一个分布式锁（如 Redisson 提供的 Reentrant Lock）。只有获得锁的进程才执行 ZRANGEBYSCORE 和 ZREM 操作。 原子性消费（Lua 脚本）： 使用上面提到的 Lua 脚本，将“查询”和“移除”原子化。只要脚本执行成功，任务就会立即被移除，其他扫描器就不会再拿到。这是更轻量级和高效的解决方案。 B. 任务执行的幂等性 问题： 尽管使用了原子性移除，但由于网络波动，任务执行结果可能未及时反馈，导致任务被再次取出并执行。 解决方案： 任务处理器必须实现幂等性。例如，在取消订单时，首先检查订单状态是否已经是“已取消”。如果是，则直接退出，不重复执行取消操作。 C. Redis 的持久化和高可用 问题： Redis 宕机或重启会导致内存中的 ZSet 数据丢失。 解决方案： 持久化： 开启 Redis 的 AOF (Append-Only File) 持久化，确保数据在重启后能恢复。 高可用： 使用 Redis Sentinel（哨兵） 或 Redis Cluster（集群） 模式，确保即使主节点宕机，备用节点也能迅速接管，保障服务的连续性。 ",
"tags":null,
"categories":null
},{
"title":"排序算法总结",
"permalink": "http://localhost:1313/posts/datastructalgorithm/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/",
"summary": "总结——所有常见排序算法的核心思想、时间复杂度、空间复杂度、稳定性、是否原地排序、适用场景和简单例子。 下面是最全面且面试导向的总结版本👇\n🧠 排序算法总览表 算法 思想 时间复杂度 空间复杂度 稳定性 原地排序 适用场景 冒泡排序 (Bubble Sort) 相邻交换，最大（或最小）元素逐步“浮出” O(n²) O(1) ✅ 稳定 ✅ 数据量小、部分有序 选择排序 (Selection Sort) 每次选择最小元素放到前面 O(n²) O(1) ❌ 不稳定 ✅ 数据量小，对交换次数敏感 插入排序 (Insertion Sort) 将未排序元素插入到已排序序列中 O(n²) O(1) ✅ 稳定 ✅ 数据基本有序时高效 希尔排序 (Shell Sort) 插入排序的改进版，分组比较减少交换 O(n¹˙³~n²) O(1) ❌ 不稳定 ✅ 中等规模数据 归并排序 (Merge Sort) 分治 + 合并有序子序列 O(n log n) O(n) ✅ 稳定 ❌ 大数据、外部排序 快速排序 (Quick Sort) 分治 + 基准划分 平均 O(n log n)最坏 O(n²) O(log n) ❌ 不稳定 ✅ 通用最快的内部排序 堆排序 (Heap Sort) 利用堆结构维护最大/最小值 O(n log n) O(1) ❌ 不稳定 ✅ 需要快速找最大/最小的场景 计数排序 (Counting Sort) 统计每个元素出现次数 O(n + k) O(n + k) ✅ 稳定 ❌ 整数、范围较小的场景 桶排序 (Bucket Sort) 按区间划分多个桶再分别排序 O(n + k) O(n + k) ✅ 稳定（视子排序） ❌ 数据均匀分布的浮点数 基数排序 (Radix Sort) 按位（个位→高位）排序 O(d·(n+k)) O(n + k) ✅ 稳定 ❌ 整数、字符串排序 🔍 各算法核心思想讲解与代码示例 1️⃣ 冒泡排序 Bubble Sort 每一轮两两比较，把最大值“冒泡”到最后。\n",
"content": "总结——所有常见排序算法的核心思想、时间复杂度、空间复杂度、稳定性、是否原地排序、适用场景和简单例子。 下面是最全面且面试导向的总结版本👇\n🧠 排序算法总览表 算法 思想 时间复杂度 空间复杂度 稳定性 原地排序 适用场景 冒泡排序 (Bubble Sort) 相邻交换，最大（或最小）元素逐步“浮出” O(n²) O(1) ✅ 稳定 ✅ 数据量小、部分有序 选择排序 (Selection Sort) 每次选择最小元素放到前面 O(n²) O(1) ❌ 不稳定 ✅ 数据量小，对交换次数敏感 插入排序 (Insertion Sort) 将未排序元素插入到已排序序列中 O(n²) O(1) ✅ 稳定 ✅ 数据基本有序时高效 希尔排序 (Shell Sort) 插入排序的改进版，分组比较减少交换 O(n¹˙³~n²) O(1) ❌ 不稳定 ✅ 中等规模数据 归并排序 (Merge Sort) 分治 + 合并有序子序列 O(n log n) O(n) ✅ 稳定 ❌ 大数据、外部排序 快速排序 (Quick Sort) 分治 + 基准划分 平均 O(n log n)最坏 O(n²) O(log n) ❌ 不稳定 ✅ 通用最快的内部排序 堆排序 (Heap Sort) 利用堆结构维护最大/最小值 O(n log n) O(1) ❌ 不稳定 ✅ 需要快速找最大/最小的场景 计数排序 (Counting Sort) 统计每个元素出现次数 O(n + k) O(n + k) ✅ 稳定 ❌ 整数、范围较小的场景 桶排序 (Bucket Sort) 按区间划分多个桶再分别排序 O(n + k) O(n + k) ✅ 稳定（视子排序） ❌ 数据均匀分布的浮点数 基数排序 (Radix Sort) 按位（个位→高位）排序 O(d·(n+k)) O(n + k) ✅ 稳定 ❌ 整数、字符串排序 🔍 各算法核心思想讲解与代码示例 1️⃣ 冒泡排序 Bubble Sort 每一轮两两比较，把最大值“冒泡”到最后。\nfunc bubbleSort(nums []int) { n := len(nums) for i := 0; i \u0026lt; n-1; i++ { for j := 0; j \u0026lt; n-i-1; j++ { if nums[j] \u0026gt; nums[j+1] { nums[j], nums[j+1] = nums[j+1], nums[j] } } } } ✅ 稳定、实现简单 ❌ 慢，不适合大数据\n2️⃣ 选择排序 Selection Sort 每轮选出最小值放到前面。\nfunc selectionSort(nums []int) { n := len(nums) for i := 0; i \u0026lt; n-1; i++ { min := i for j := i + 1; j \u0026lt; n; j++ { if nums[j] \u0026lt; nums[min] { min = j } } nums[i], nums[min] = nums[min], nums[i] } } ❌ 不稳定（因为最小值和前面元素交换会破坏顺序） ✅ 简单、交换次数少\n3️⃣ 插入排序 Insertion Sort 把当前元素插入到前面已排序的部分。\nfunc insertionSort(nums []int) { for i := 1; i \u0026lt; len(nums); i++ { key := nums[i] j := i - 1 for j \u0026gt;= 0 \u0026amp;\u0026amp; nums[j] \u0026gt; key { nums[j+1] = nums[j] j-- } nums[j+1] = key } } ✅ 稳定，小规模或几乎有序数组很快。 📈 平均 O(n²)，最好 O(n)。\n4️⃣ 希尔排序 Shell Sort 插入排序 + 分组加速。\nfunc shellSort(nums []int) { for gap := len(nums) / 2; gap \u0026gt; 0; gap /= 2 { for i := gap; i \u0026lt; len(nums); i++ { temp := nums[i] j := i for ; j \u0026gt;= gap \u0026amp;\u0026amp; nums[j-gap] \u0026gt; temp; j -= gap { nums[j] = nums[j-gap] } nums[j] = temp } } } ❌ 不稳定 ✅ 比插入排序快得多。\n5️⃣ 归并排序 Merge Sort 分治 + 合并（见你前面的模板）。 ✅ 稳定 ❌ 需要 O(n) 额外空间。\n6️⃣ 快速排序 Quick Sort 选一个基准，把小于它的放左边，大于的放右边，再递归。\nfunc quickSort(nums []int) { if len(nums) \u0026lt;= 1 { return } sort(nums, 0, len(nums)-1) } func sort(nums []int, l, r int) { if l \u0026gt;= r { return } pivot := partition(nums, l, r) sort(nums, l, pivot-1) sort(nums, pivot+1, r) } func partition(nums []int, l, r int) int { pivot := nums[r] i := l for j := l; j \u0026lt; r; j++ { if nums[j] \u0026lt; pivot { nums[i], nums[j] = nums[j], nums[i] i++ } } nums[i], nums[r] = nums[r], nums[i] return i } ⚡ 通常是最快的内部排序算法。 ❌ 不稳定，最坏情况 O(n²)，但平均非常好。\n7️⃣ 堆排序 Heap Sort 构建最大堆，每次取出堆顶（最大值）放到末尾。\nfunc heapSort(nums []int) { n := len(nums) for i := n/2 - 1; i \u0026gt;= 0; i-- { heapify(nums, n, i) } for i := n - 1; i \u0026gt; 0; i-- { nums[0], nums[i] = nums[i], nums[0] heapify(nums, i, 0) } } func heapify(nums []int, n, i int) { largest := i l, r := 2*i+1, 2*i+2 if l \u0026lt; n \u0026amp;\u0026amp; nums[l] \u0026gt; nums[largest] { largest = l } if r \u0026lt; n \u0026amp;\u0026amp; nums[r] \u0026gt; nums[largest] { largest = r } if largest != i { nums[i], nums[largest] = nums[largest], nums[i] heapify(nums, n, largest) } } ✅ 不需要额外空间，O(1) 空间复杂度 ❌ 不稳定\n8️⃣ 计数排序 Counting Sort 统计每个元素出现次数，按次数输出。\nfunc countingSort(nums []int, maxVal int) []int { count := make([]int, maxVal+1) for _, v := range nums { count[v]++ } idx := 0 for i, c := range count { for c \u0026gt; 0 { nums[idx] = i idx++ c-- } } return nums } ✅ 稳定、线性时间 ❌ 只能用于非负整数，且范围不能太大。\n9️⃣ 桶排序 Bucket Sort 把数据分进多个桶，每个桶内部再排序。\nfunc bucketSort(nums []float64) []float64 { n := len(nums) buckets := make([][]float64, n) for _, v := range nums { idx := int(v * float64(n)) buckets[idx] = append(buckets[idx], v) } // 对每个桶内部排序（可用插入排序） for i := range buckets { insertionSortFloat(buckets[i]) } result := make([]float64, 0, n) for _, b := range buckets { result = append(result, b...) } return result } func insertionSortFloat(nums []float64) { for i := 1; i \u0026lt; len(nums); i++ { key := nums[i] j := i - 1 for j \u0026gt;= 0 \u0026amp;\u0026amp; nums[j] \u0026gt; key { nums[j+1] = nums[j] j-- } nums[j+1] = key } } 适用于：分布均匀的浮点数（例如 [0,1) 区间内）。\n🔟 基数排序 Radix Sort 按个位、十位、百位……依次使用计数排序。\nfunc radixSort(nums []int) { maxVal := 0 for _, v := range nums { if v \u0026gt; maxVal { maxVal = v } } for exp := 1; maxVal/exp \u0026gt; 0; exp *= 10 { countingSortByDigit(nums, exp) } } func countingSortByDigit(nums []int, exp int) { n := len(nums) output := make([]int, n) count := make([]int, 10) for i := 0; i \u0026lt; n; i++ { digit := (nums[i] / exp) % 10 count[digit]++ } for i := 1; i \u0026lt; 10; i++ { count[i] += count[i-1] } for i := n - 1; i \u0026gt;= 0; i-- { digit := (nums[i] / exp) % 10 output[count[digit]-1] = nums[i] count[digit]-- } copy(nums, output) } 适用于：整数、定长字符串。\n📈 总结 类别 算法 口诀 O(n²) 类 冒泡、选择、插入 慢但简单，冒泡插入稳，选择不稳 O(n log n) 类 归并、快排、堆排 分治三兄弟：归并稳，快排快，堆排省空间 线性排序类 计数、桶、基数 利用数据特征换取速度，空间换时间 ",
"tags":null,
"categories":null
},{
"title":"内存分配",
"permalink": "http://localhost:1313/posts/go/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/",
"summary": "go的内存分配 根据对象大小的不同，go的内存分配有3种类型： Tiny(size \u0026lt; 16B): Objects of size less than 16 bytes are allocated using the mcache’s tiny allocator. This is efficient and multiple tiny allocations are done on a single 16-byte block. Small(size 16B ~ 32KB): Objects of size between 16 bytes and 32 Kilobytes are allocated on the corresponding size class(mspan) on mcache of the P where the G is running. In both tiny and small allocation if the mspan’s list is empty the allocator will obtain a run of pages from the mheap to use for the mspan. If the mheap is empty or has no page runs large enough then it allocates a new group of pages (at least 1MB) from the OS. Large(size \u0026gt; 32KB): Objects of size greater than 32 kilobytes are allocated directly on the corresponding size class of mheap. If the mheap is empty or has no page runs large enough then it allocates a new group of pages (at least 1MB) from the OS. 总结一下Go是如何进行内存分配: mcache中如果有空闲的空间， 那么直接在mcache分配 mcache如果没有，那么尝试去mcentral中获取一个空闲的mspan mcentral中也咩有可用的mspan，那么直接去mheap向操作系统申请可用的mspan\n",
"content": "go的内存分配 根据对象大小的不同，go的内存分配有3种类型： Tiny(size \u0026lt; 16B): Objects of size less than 16 bytes are allocated using the mcache’s tiny allocator. This is efficient and multiple tiny allocations are done on a single 16-byte block. Small(size 16B ~ 32KB): Objects of size between 16 bytes and 32 Kilobytes are allocated on the corresponding size class(mspan) on mcache of the P where the G is running. In both tiny and small allocation if the mspan’s list is empty the allocator will obtain a run of pages from the mheap to use for the mspan. If the mheap is empty or has no page runs large enough then it allocates a new group of pages (at least 1MB) from the OS. Large(size \u0026gt; 32KB): Objects of size greater than 32 kilobytes are allocated directly on the corresponding size class of mheap. If the mheap is empty or has no page runs large enough then it allocates a new group of pages (at least 1MB) from the OS. 总结一下Go是如何进行内存分配: mcache中如果有空闲的空间， 那么直接在mcache分配 mcache如果没有，那么尝试去mcentral中获取一个空闲的mspan mcentral中也咩有可用的mspan，那么直接去mheap向操作系统申请可用的mspan\n和 mcache、mcentral、mheap 之间的联系 1. mspan 与大小分类的关系 首先要明确一点：mspan 并不是直接和每个对象大小一一对应的，而是用于管理一定范围内大小的内存块的。每个 mspan 可以包含多个对象，并且一个 mspan 的大小通常是多个相同大小的对象一起构成的。\n对象大小与 mspan 的关系： Tiny 分配（小于 16B）：\n对于 \u0026lt; 16B 的小对象，Go 不会为每个对象单独分配一个 8KB 或 16KB 的 mspan。相反，这些小对象会被 批量分配到一个固定大小的内存区域，通常是一个 16 字节的块，也就是 tiny allocator 的内存池。 mspan 对于这些小对象的作用是：一块小内存块可以包含多个小对象，而 mspan 本身并不是用于存储单一的 16B 或更小的对象。多个小对象（比如多个小于 16B 的对象）会在一个 mspan 中共享这块内存。 Small 分配（16B ~ 32KB）：\n对于这类对象，Go 会根据对象大小将它们划分到不同的大小类（size class）中，并为每个大小类创建一个 mspan。比如，16B、32B、64B 等对象大小就会分别分配到对应的 mspan（每个 mspan 的大小可能是 8KB、16KB 或其他）。 这些 mspan 用来存储多个相同大小的对象，每个 mspan 会有多个空闲的对象块，直到这些 mspan 被填满或者空闲对象用完。 Large 分配（大于 32KB）：\n对于大于 32KB 的对象，Go 直接在 mheap 中分配内存，不会使用 mcache 或 mspan。这些对象会直接向操作系统请求大的内存页（通常是 4KB 或更大的页面），并在 mheap 中进行管理。 2. mcache、mcentral 和 mheap 的关系 这些分配区域和 Tiny、Small、Large 内存分配类别之间有很大的关系，下面是它们如何协作：\nmcache：\n每个处理器（P）都有一个 mcache，它用于快速分配小对象。它有多个 mspan，这些 mspan 存储着多个相同大小的对象。 Tiny 分配：如果你分配的对象小于 16B，mcache 会直接在 tiny allocator 中分配内存（这个区域用于非常小的对象），这些对象不会占用一个完整的 mspan，而是在一个 16 字节大小的块中共享内存。 Small 分配：如果你分配的对象大小在 16B 到 32KB 之间，mcache 会查看其对应的 mspan，如果 mspan 空闲且符合条件，它会直接分配。如果没有空闲的 mspan，mcache 会请求 mcentral 获取新的 mspan。 mcentral：\nmcentral 是一个更大的缓存池，用于存储多个 mspan，如果 mcache 中没有足够的内存块来满足请求，它会向 mcentral 请求新的 mspan。这通常发生在中等大小的对象（16B ~ 32KB）分配时。 mcentral 会缓存各个大小类的 mspan，并将它们分发给不同的 mcache。当 mcache 的空间不足时，它会从 mcentral 获取更多的 mspan。 mheap：\nLarge 分配：对于大于 32KB 的对象，Go 会直接在 mheap 中分配内存，mheap 管理的是操作系统的内存页（每页 4KB）。当 mcache 和 mcentral 没有足够的空闲空间时，mheap 会向操作系统申请新的内存区域（通常至少为 1MB），并将这些内存划分为多个 mspan 进行管理。 3. 总结 ：\nTiny 分配（\u0026lt; 16B）：这类小对象会在 mcache 中的 tiny allocator 中分配，而不会直接占用一个 8KB 的 mspan。这些小对象可以在 16 字节的小块内存区域中分配。 Small 分配（16B ~ 32KB）：这类对象会根据大小分配到 mcache 的 mspan 中，mspan 会缓存多个相同大小的对象。如果没有空闲的 mspan，会从 mcentral 获取。 Large 分配（\u0026gt; 32KB）：这类大对象直接在 mheap 中分配内存。 总的来说，mspan 用于存储相同大小的多个对象，mcache 用来缓存小对象，mcentral 是更大的内存池，用于缓存多个 mspan，mheap 是整个堆内存的管理区。\n",
"tags":null,
"categories":null
},{
"title":"Tcp三次握手和四次挥手",
"permalink": "http://localhost:1313/posts/network/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/",
"summary": "三次握手 客户端发送syn，客户端从close-\u0026gt;syn-send syn服务端收到syn ,同时向客户端发送syn.ack ，自己从listen变成 syn-recd 客户端收到syn-ack会在发送一个ack,自己变成established,服务端收到这个ack，自己变成established。 ",
"content": "三次握手 客户端发送syn，客户端从close-\u0026gt;syn-send syn服务端收到syn ,同时向客户端发送syn.ack ，自己从listen变成 syn-recd 客户端收到syn-ack会在发送一个ack,自己变成established,服务端收到这个ack，自己变成established。 ",
"tags":null,
"categories":null
},{
"title":"sql高频题",
"permalink": "http://localhost:1313/posts/sql/%E9%AB%98%E9%A2%91%E9%A2%98/",
"summary": "分为六个维度：基础聚合 → 子查询 → TopN → 窗口函数 → 业务建模 → 性能优化。\n🎯 高频 SQL 题库（含答案与思路） 一、基础聚合与分组（GROUP BY / HAVING） 🧩 题 1：查询每个部门的平均工资 表结构：\nemployee(emp_id, emp_name, dept_id, salary) SQL：\nSELECT dept_id, AVG(salary) AS avg_salary FROM employee GROUP BY dept_id; 📘 考点： 聚合函数 + 分组\n🧩 题 2：查询带学生数超过 10 人的老师 teacher(teacher_id, name) student(student_id, teacher_id) SQL：\nSELECT teacher_id, COUNT(*) AS student_count FROM student GROUP BY teacher_id HAVING COUNT(*) \u0026gt; 10; 📘 考点： HAVING 与 WHERE 的区别（HAVING 针对聚合后过滤）\n二、子查询（Subquery） 🧩 题 3：查询工资高于本部门平均工资的员工 SELECT e.emp_name, e.salary FROM employee e JOIN ( SELECT dept_id, AVG(salary) AS avg_salary FROM employee GROUP BY dept_id ) d ON e.dept_id = d.dept_id WHERE e.salary \u0026gt; d.avg_salary; 📘 考点： 相关子查询 vs 非相关子查询\n",
"content": "分为六个维度：基础聚合 → 子查询 → TopN → 窗口函数 → 业务建模 → 性能优化。\n🎯 高频 SQL 题库（含答案与思路） 一、基础聚合与分组（GROUP BY / HAVING） 🧩 题 1：查询每个部门的平均工资 表结构：\nemployee(emp_id, emp_name, dept_id, salary) SQL：\nSELECT dept_id, AVG(salary) AS avg_salary FROM employee GROUP BY dept_id; 📘 考点： 聚合函数 + 分组\n🧩 题 2：查询带学生数超过 10 人的老师 teacher(teacher_id, name) student(student_id, teacher_id) SQL：\nSELECT teacher_id, COUNT(*) AS student_count FROM student GROUP BY teacher_id HAVING COUNT(*) \u0026gt; 10; 📘 考点： HAVING 与 WHERE 的区别（HAVING 针对聚合后过滤）\n二、子查询（Subquery） 🧩 题 3：查询工资高于本部门平均工资的员工 SELECT e.emp_name, e.salary FROM employee e JOIN ( SELECT dept_id, AVG(salary) AS avg_salary FROM employee GROUP BY dept_id ) d ON e.dept_id = d.dept_id WHERE e.salary \u0026gt; d.avg_salary; 📘 考点： 相关子查询 vs 非相关子查询\n🧩 题 4：查询至少有一笔订单金额超过 1000 的用户 SELECT user_id FROM orders WHERE amount \u0026gt; 1000 GROUP BY user_id; 📘 变形题： 可以写成 EXISTS：\nSELECT DISTINCT u.user_id FROM users u WHERE EXISTS ( SELECT 1 FROM orders o WHERE o.user_id = u.user_id AND o.amount \u0026gt; 1000 ); 三、Top N 查询（分组取最大 / 最小） 🧩 题 5：查询每个部门工资最高的员工 SELECT e.* FROM employee e JOIN ( SELECT dept_id, MAX(salary) AS max_salary FROM employee GROUP BY dept_id ) t ON e.dept_id = t.dept_id AND e.salary = t.max_salary; 📘 考点： group by + join 拿分组最大值\n🧩 题 6：查询销售额排名前三的商品 SELECT product_id, SUM(amount) AS total_sales FROM orders GROUP BY product_id ORDER BY total_sales DESC LIMIT 3; 📘 考点： 聚合 + 排序 + limit\n四、窗口函数（Window Function） 🧩 题 7：查询每个部门工资第二高的员工 SELECT * FROM ( SELECT emp_id, dept_id, salary, ROW_NUMBER() OVER (PARTITION BY dept_id ORDER BY salary DESC) AS rn FROM employee ) t WHERE rn = 2; 📘 考点： ROW_NUMBER() / RANK() / DENSE_RANK() 区别\n🧩 题 8：统计用户连续签到 \u0026gt;= 3 天的情况 SELECT user_id FROM ( SELECT user_id, DATE_SUB(sign_date, INTERVAL ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY sign_date) DAY) AS grp FROM sign_log ) t GROUP BY user_id, grp HAVING COUNT(*) \u0026gt;= 3; 📘 考点： 窗口函数 + 日期差分连续性判断\n五、业务建模类题（JOIN + 分组 + 条件） 🧩 题 9：查询每个课程的平均评分 SELECT course_id, AVG(score) AS avg_score FROM course_rating GROUP BY course_id ORDER BY avg_score DESC; 🧩 题 10：查询下过订单但从未付款的用户 SELECT DISTINCT o.user_id FROM orders o LEFT JOIN payments p ON o.order_id = p.order_id WHERE p.order_id IS NULL; 📘 考点： 左连接 + null 判断（反查）\n🧩 题 11：查询每个用户最后一次下单时间 SELECT user_id, MAX(order_time) AS last_order_time FROM orders GROUP BY user_id; 🧩 题 12：查询下单金额最高的前 10 个用户及他们的平均下单额 WITH ranked AS ( SELECT user_id, SUM(amount) AS total_amount FROM orders GROUP BY user_id ORDER BY total_amount DESC LIMIT 10 ) SELECT AVG(total_amount) FROM ranked; 六、性能优化与索引设计（开放题） 🧩 题 13：为什么这条 SQL 很慢？ SELECT * FROM orders WHERE DATE(create_time) = \u0026#39;2025-10-24\u0026#39;; 📘 原因：\n使用了函数 DATE() 导致索引失效。 ✅ 优化：\nSELECT * FROM orders WHERE create_time \u0026gt;= \u0026#39;2025-10-24 00:00:00\u0026#39; AND create_time \u0026lt; \u0026#39;2025-10-25 00:00:00\u0026#39;; 🧩 题 14：分页查询优化 问题：\nSELECT * FROM orders ORDER BY id LIMIT 100000, 20; 太慢，因为 offset 过大。\n✅ 优化思路：\n使用「游标分页」： SELECT * FROM orders WHERE id \u0026gt; last_id ORDER BY id LIMIT 20; 🧩 题 15：高并发下防止库存超卖 📘 思路：\nSQL 层面： UPDATE product SET stock = stock - 1 WHERE id = 1 AND stock \u0026gt; 0; 受影响行数 = 1 表示成功，0 表示库存不足； 无需显式事务锁。 业务层：\n可结合 Redis 分布式锁 / MQ 异步削峰。 七、事务与锁机制（理解类） 🧩 题 16：MySQL 死锁的常见原因？ 回答思路：\n不同事务访问相同资源但顺序不一致； 长事务未及时提交； 大量间隙锁（next-key lock）。 ✅ 解决：\n缩小事务范围； 固定访问顺序； 事务重试； 使用较低隔离级别（如 READ COMMITTED）。 🧩 题 17：Explain 常见字段 字段 说明 type 连接类型（ALL, index, range, ref, eq_ref, const） possible_keys 可用索引 key 实际使用的索引 rows 预计扫描行数 Extra 额外信息（Using index, Using temporary, Using filesort） 面试高频问法：\n“Explain 里出现 Using filesort 是什么意思？怎么优化？”\n✅ 答： 排序未走索引，可通过复合索引 (a, b) 或 order by 顺序优化。\n✅ 八、总结 类型 高频考点 建议 聚合统计 group by + having 多练业务类场景 TopN 分组内最大值 会写 join + group 窗口函数 row_number / rank 重点 子查询 exists / not exists 多表条件判断 性能优化 explain + 索引失效 常见面试 killer 题 事务理解 死锁、MVCC、锁等待 二面必问 ",
"tags":null,
"categories":null
},{
"title":"Liunx常用命令",
"permalink": "http://localhost:1313/posts/cs/liunx%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/",
"summary": "Linux 中非常常用和基础的命令，按照功能进行了分类：\n1. 文件和目录管理 ls (list)\n作用：列出目录中的文件和子目录。 常用选项： ls -l：显示详细信息（权限、所有者、大小、修改日期）。 ls -a：显示所有文件，包括隐藏文件（以 . 开头的）。 ls -h：与 -l 配合使用，以人类可读的格式显示文件大小（如 1K, 2M, 3G）。 示例：ls -lah /home/user cd (change directory)\n作用：切换当前工作目录。 常用用法： cd /var/log：切换到 /var/log 目录。 cd ..：切换到上一级目录。 cd ~ 或 cd：切换到当前用户的主目录。 cd -：切换到上一个工作目录。 pwd (print working directory)\n作用：显示当前所在的目录路径。 mkdir (make directory)\n作用：创建新目录。 常用选项： mkdir -p /path/to/new/dir：递归创建目录，如果父目录不存在也会一并创建。 示例：mkdir my_project rmdir (remove directory)\n作用：删除空目录。 rm (remove)\n作用：删除文件或目录。 常用选项： rm file.txt：删除一个文件。 rm -r directory_name：递归删除目录及其所有内容。 rm -f file.txt：强制删除，不进行提示。 rm -rf directory_name：（慎用！） 强制递归删除目录，不会有任何提示。 cp (copy)\n",
"content": "Linux 中非常常用和基础的命令，按照功能进行了分类：\n1. 文件和目录管理 ls (list)\n作用：列出目录中的文件和子目录。 常用选项： ls -l：显示详细信息（权限、所有者、大小、修改日期）。 ls -a：显示所有文件，包括隐藏文件（以 . 开头的）。 ls -h：与 -l 配合使用，以人类可读的格式显示文件大小（如 1K, 2M, 3G）。 示例：ls -lah /home/user cd (change directory)\n作用：切换当前工作目录。 常用用法： cd /var/log：切换到 /var/log 目录。 cd ..：切换到上一级目录。 cd ~ 或 cd：切换到当前用户的主目录。 cd -：切换到上一个工作目录。 pwd (print working directory)\n作用：显示当前所在的目录路径。 mkdir (make directory)\n作用：创建新目录。 常用选项： mkdir -p /path/to/new/dir：递归创建目录，如果父目录不存在也会一并创建。 示例：mkdir my_project rmdir (remove directory)\n作用：删除空目录。 rm (remove)\n作用：删除文件或目录。 常用选项： rm file.txt：删除一个文件。 rm -r directory_name：递归删除目录及其所有内容。 rm -f file.txt：强制删除，不进行提示。 rm -rf directory_name：（慎用！） 强制递归删除目录，不会有任何提示。 cp (copy)\n作用：复制文件或目录。 常用用法： cp source_file destination_file：复制文件。 cp source_file destination_directory/：将文件复制到目录中。 cp -r source_directory destination_directory/：递归复制整个目录。 mv (move)\n作用：移动文件/目录，或者重命名。 常用用法： mv old_name.txt new_name.txt：重命名。 mv file.txt /path/to/destination/：将文件移动到新位置。 touch\n作用：创建一个空文件，或者更新已有文件的时间戳。 示例：touch new_file.log find\n作用：在指定目录中搜索文件。 常用用法： find /home -name \u0026quot;*.txt\u0026quot;：在 /home 目录及子目录中查找所有 .txt 文件。 find . -type d -name \u0026quot;logs\u0026quot;：在当前目录查找所有名为 \u0026ldquo;logs\u0026rdquo; 的目录。 2. 文本查看和处理 cat (concatenate)\n作用：查看文件内容、合并文件。 示例：cat /etc/passwd less\n作用：分页查看文件内容（比 more 更强大，支持前后翻页）。 操作：按 q 退出，按 / 搜索。 示例：less large_file.log head\n作用：显示文件的开头几行（默认 10 行）。 示例：head -n 20 file.txt (显示前 20 行) tail\n作用：显示文件的末尾几行（默认 10 行）。 常用选项： tail -n 50 file.txt (显示后 50 行) tail -f /var/log/syslog：（非常常用） 实时跟踪文件的新增内容，常用于看日志。 grep\n作用：在文件中搜索包含指定字符串的行。 常用选项： grep \u0026quot;error\u0026quot; /var/log/syslog：在文件中搜索 \u0026ldquo;error\u0026rdquo;。 grep -r \u0026quot;my_function\u0026quot; /project/src：在目录中递归搜索。 grep -i \u0026quot;hello\u0026quot;：忽略大小写搜索。 grep -v \u0026quot;debug\u0026quot;：反向搜索，显示不包含 \u0026ldquo;debug\u0026rdquo; 的行。 wc (word count)\n作用：统计文件的行数、单词数、字节数。 常用选项： wc -l file.txt：只统计行数。 wc -w file.txt：只统计单词数。 wc -c file.txt：只统计字节数。 diff\n作用：比较两个文件的差异。 示例：diff file1.txt file2.txt 3. 系统信息和监控 df (disk free)\n作用：查看磁盘空间使用情况。 常用选项：df -h (以人类可读的格式显示)。 du (disk usage)\n作用：查看文件或目录占用的磁盘空间大小。 常用选项： du -sh /path/to/directory：查看指定目录的总大小 (-s 总结, -h 人类可读)。 du -h --max-depth=1 /home：查看 /home 目录下第一级子目录各自的大小。 top\n作用：实时动态地显示系统进程和资源占用情况（CPU、内存等）。 操作：按 q 退出，按 P 按 CPU 排序，按 M 按内存排序。 htop\n作用：top 的增强版，界面更友好，支持鼠标操作（可能需要额外安装）。 free\n作用：查看内存和交换空间（swap）的使用情况。 常用选项：free -h (以人类可读的格式显示)。 ps (process status)\n作用：查看当前系统的进程状态。 常用选项： ps aux：显示所有用户的所有进程（BSD 风格）。 ps -ef：显示所有进程的完整信息（System V 风格）。 组合使用：ps aux | grep \u0026quot;nginx\u0026quot; (查找 nginx 相关的进程)。 kill\n作用：向进程发送信号，通常用于终止进程。 常用用法： kill [PID]：终止指定 PID 的进程 (发送 SIGTERM 信号)。 kill -9 [PID]：（慎用） 强制杀死进程 (发送 SIGKILL 信号)。 uptime\n作用：显示系统已运行时间、登录用户数以及系统平均负载。 uname\n作用：显示系统内核和操作系统信息。 常用选项：uname -a (显示所有信息)。 4. 权限管理 chmod (change mode)\n作用：修改文件或目录的权限。 常用用法： chmod 755 script.sh (使用数字设置权限：rwx r-x r-x)。 chmod +x script.sh (给文件添加执行权限)。 chmod -R 644 /path/to/dir (递归修改目录下所有文件的权限)。 chown (change owner)\n作用：修改文件或目录的所有者和所属组。 常用用法： chown new_owner file.txt：修改所有者。 chown new_owner:new_group file.txt：同时修改所有者和组。 chown -R user:group /path/to/dir：递归修改。 sudo\n作用：以超级用户（root）或其他用户的身份执行命令。 示例：sudo apt update (在 Ubuntu/Debian 上以 root 权限更新软件包列表)。 5. 网络命令 ping\n作用：测试与另一台主机之间的网络连接。 示例：ping baidu.com curl\n作用：一个强大的命令行工具，用于传输数据，常用于测试 HTTP 请求。 示例：curl https://api.example.com/data wget\n作用：用于从网络上下载文件。 示例：wget https://example.com/large_file.zip ip\n作用：显示和管理路由、网络设备、策略路由和隧道（正在取代 ifconfig）。 常用用法： ip addr show 或 ip a：查看 IP 地址。 ip route show：查看路由表。 netstat (或 ss)\n作用：查看网络连接、路由表、接口统计等。 常用选项：netstat -tulnp (显示 TCP/UDP 的监听端口及对应的程序名)。 现代替代：ss -tulnp (功能类似 netstat，但更高效)。 6. 压缩和归档 tar\n作用：打包和解包 .tar 文件，经常与 gzip 或 bzip2 配合使用。 常用选项： tar -cvf archive.tar /path/to/dir：打包 (-c 创建, -v 显示过程, -f 指定文件名)。 tar -xvf archive.tar：解包。 tar -czvf archive.tar.gz /path/to/dir：打包并用 gzip 压缩 (-z)。 tar -xzvf archive.tar.gz：解压 gzip 压缩包。 tar -cjvf archive.tar.bz2 /path/to/dir：打包并用 bzip2 压缩 (-j)。 tar -xjvf archive.tar.bz2：解压 bzip2 压缩包。 gzip\n作用：压缩文件（生成 .gz 文件）。 示例：gzip file.txt (会生成 file.txt.gz 并删除原文件)。 解压：gunzip file.txt.gz zip / unzip\n作用：用于处理 .zip 格式的压缩文件。 示例： zip -r archive.zip directory/ unzip archive.zip 7. 其他常用命令 man (manual)\n作用：查看命令的帮助手册。 示例：man ls (查看 ls 命令的用法)。 history\n作用：显示在 shell 中执行过的历史命令。 echo\n作用：在终端打印输出文本或变量。 示例：echo \u0026quot;Hello World\u0026quot; | (管道符)\n作用：将一个命令的输出作为另一个命令的输入。 示例：ps aux | grep \u0026quot;chrome\u0026quot; (将 ps 的输出交给 grep 来过滤)。 \u0026gt; 和 \u0026gt;\u0026gt; (重定向)\n作用：将命令的输出重定向到文件。 \u0026gt;：覆盖写入。ls -l \u0026gt; file_list.txt \u0026gt;\u0026gt;：追加写入。echo \u0026quot;New log entry\u0026quot; \u0026gt;\u0026gt; app.log 掌握这些命令是高效使用 Linux 系统的基础。\n",
"tags":null,
"categories":null
},{
"title":"Go 场景题模版",
"permalink": "http://localhost:1313/posts/scenario/%E5%9C%BA%E6%99%AF%E9%A2%98%E6%A8%A1%E7%89%88/",
"summary": "Go 场景题训练手册 — 题目版 作者：cp yang 说明：分为 初级 / 中级 / 高级 / 实战 Debug 四个章节。每题为面试常见场景题（用于练习）\n🟢 初级场景题（语言特性与陷阱） 切片在函数参数传递时，什么时候会影响外部数据？请举例并解释。 for range vs for i := 0; i \u0026lt; len(slice); i++，在修改元素和效率上有什么区别？ map 初始化的正确写法有哪些？哪些写法会导致 panic？ defer 的执行顺序是什么？return 与 defer 的执行顺序如何？ append 扩容时如何影响底层数组？如何避免不必要的复制？ string 与 []byte 转换在高频场景下的性能问题如何优化？ 实现一个线程安全的简单 map（支持 Get/Set/Delete）。 🟡 中级场景题（并发与控制） 如何使用 sync.WaitGroup 控制并发任务？请给出示例，并说明常见错误。 设计一个固定大小的 goroutine 池（worker pool），能提交任务并等待完成。 设计一个生产者-消费者模型，支持多生产者、多消费者，并能优雅退出。 实现两个 goroutine 交替打印 1~100（A 打印 1，B 打印 2，依次交替）。 如何限制并发数量（例如同时最多 10 个任务）？给出实现。 使用 context 实现任务超时与取消，给出示例。 🔴 高级场景题（系统设计与性能） 设计一个本地缓存系统，支持 TTL、并发安全和定期清理。写出核心接口与实现要点。 设计并实现一个 LRU 缓存（map + 双向链表），要求并发安全。 设计一个简易消息队列（支持发布/订阅、可持久化思路说明）。写出关键数据结构与伪码。 如何设计一个高并发的秒杀系统以防止超卖？给出架构思路与关键代码片段（Redis/本地预减库存等）。 设计一个限流组件（令牌桶），实现接口并说明在微服务网关如何使用。 ⚙️ 实战 Debug 场景题（排障与优化） 程序出现大量 goroutine 泄漏（数量不断增长），你如何排查？列出排查步骤与 pprof 使用方法。 出现死锁（程序卡住），如何定位和修复？给出示例代码及修改建议。 程序内存暴涨并触发 GC 压力，如何分析原因并给出优化方案？ 高并发下锁竞争严重（通过 Mutex 看到 QPS 降低），如何诊断并优化？ 使用 pprof 找到热点 CPU 占用点后，你会如何改进代码？给出一个简单示例。 ",
"content": "Go 场景题训练手册 — 题目版 作者：cp yang 说明：分为 初级 / 中级 / 高级 / 实战 Debug 四个章节。每题为面试常见场景题（用于练习）\n🟢 初级场景题（语言特性与陷阱） 切片在函数参数传递时，什么时候会影响外部数据？请举例并解释。 for range vs for i := 0; i \u0026lt; len(slice); i++，在修改元素和效率上有什么区别？ map 初始化的正确写法有哪些？哪些写法会导致 panic？ defer 的执行顺序是什么？return 与 defer 的执行顺序如何？ append 扩容时如何影响底层数组？如何避免不必要的复制？ string 与 []byte 转换在高频场景下的性能问题如何优化？ 实现一个线程安全的简单 map（支持 Get/Set/Delete）。 🟡 中级场景题（并发与控制） 如何使用 sync.WaitGroup 控制并发任务？请给出示例，并说明常见错误。 设计一个固定大小的 goroutine 池（worker pool），能提交任务并等待完成。 设计一个生产者-消费者模型，支持多生产者、多消费者，并能优雅退出。 实现两个 goroutine 交替打印 1~100（A 打印 1，B 打印 2，依次交替）。 如何限制并发数量（例如同时最多 10 个任务）？给出实现。 使用 context 实现任务超时与取消，给出示例。 🔴 高级场景题（系统设计与性能） 设计一个本地缓存系统，支持 TTL、并发安全和定期清理。写出核心接口与实现要点。 设计并实现一个 LRU 缓存（map + 双向链表），要求并发安全。 设计一个简易消息队列（支持发布/订阅、可持久化思路说明）。写出关键数据结构与伪码。 如何设计一个高并发的秒杀系统以防止超卖？给出架构思路与关键代码片段（Redis/本地预减库存等）。 设计一个限流组件（令牌桶），实现接口并说明在微服务网关如何使用。 ⚙️ 实战 Debug 场景题（排障与优化） 程序出现大量 goroutine 泄漏（数量不断增长），你如何排查？列出排查步骤与 pprof 使用方法。 出现死锁（程序卡住），如何定位和修复？给出示例代码及修改建议。 程序内存暴涨并触发 GC 压力，如何分析原因并给出优化方案？ 高并发下锁竞争严重（通过 Mutex 看到 QPS 降低），如何诊断并优化？ 使用 pprof 找到热点 CPU 占用点后，你会如何改进代码？给出一个简单示例。 ",
"tags":null,
"categories":null
},{
"title":"Go 场景题模版 — 答案版",
"permalink": "http://localhost:1313/posts/scenario/%E5%9C%BA%E6%99%AF%E9%A2%98%E6%A8%A1%E7%89%88-%E7%AD%94%E6%A1%88/",
"summary": " 🟢 初级场景题（语言特性与陷阱） 1. 切片在函数参数传递时，什么时候会影响外部数据？ 思路： 切片是三元组（指针、len、cap）。传参时会拷贝这三项，但底层数组仍然共享。只有当 append 导致扩容（新的底层数组分配）或修改通过索引直接写入时，外部可见。\n直接 s[i] = x 会影响外部； s = append(s, x) 当 cap 不足时会分配新数组，外部不会看到新元素。 示例代码：\npackage main import \u0026#34;fmt\u0026#34; func appendMaybe(s []int) []int { s = append(s, 100) // 若 cap 不足，这里会分配新底层数组 return s } func modify(s []int) { if len(s) \u0026gt; 0 { s[0] = 999 // 修改共享底层数组 } } func main() { a := make([]int, 1, 1) a[0] = 1 b := appendMaybe(a) fmt.Println(\u0026#34;a:\u0026#34;, a) // 如果扩容发生，a 不包含 100 fmt.Println(\u0026#34;b:\u0026#34;, b) c := make([]int, 1, 2) c[0] = 1 d := appendMaybe(c) fmt.Println(\u0026#34;c:\u0026#34;, c) // cap 足够，c 会看到 append 的结果 (如果 append reuses) fmt.Println(\u0026#34;d:\u0026#34;, d) modify(a) fmt.Println(\u0026#34;a after modify:\u0026#34;, a) // 被修改 } 2. for range vs for i := 0; i \u0026lt; len(slice); i++ 思路： for range 会在每次迭代时把元素拷贝到新的变量（v），因此直接修改 v 不会影响切片。索引访问 slice[i] 直接访问底层数组可以修改原值。性能上两者差异很小，除非元素为大结构体，range 会拷贝整个结构体。\n",
"content": " 🟢 初级场景题（语言特性与陷阱） 1. 切片在函数参数传递时，什么时候会影响外部数据？ 思路： 切片是三元组（指针、len、cap）。传参时会拷贝这三项，但底层数组仍然共享。只有当 append 导致扩容（新的底层数组分配）或修改通过索引直接写入时，外部可见。\n直接 s[i] = x 会影响外部； s = append(s, x) 当 cap 不足时会分配新数组，外部不会看到新元素。 示例代码：\npackage main import \u0026#34;fmt\u0026#34; func appendMaybe(s []int) []int { s = append(s, 100) // 若 cap 不足，这里会分配新底层数组 return s } func modify(s []int) { if len(s) \u0026gt; 0 { s[0] = 999 // 修改共享底层数组 } } func main() { a := make([]int, 1, 1) a[0] = 1 b := appendMaybe(a) fmt.Println(\u0026#34;a:\u0026#34;, a) // 如果扩容发生，a 不包含 100 fmt.Println(\u0026#34;b:\u0026#34;, b) c := make([]int, 1, 2) c[0] = 1 d := appendMaybe(c) fmt.Println(\u0026#34;c:\u0026#34;, c) // cap 足够，c 会看到 append 的结果 (如果 append reuses) fmt.Println(\u0026#34;d:\u0026#34;, d) modify(a) fmt.Println(\u0026#34;a after modify:\u0026#34;, a) // 被修改 } 2. for range vs for i := 0; i \u0026lt; len(slice); i++ 思路： for range 会在每次迭代时把元素拷贝到新的变量（v），因此直接修改 v 不会影响切片。索引访问 slice[i] 直接访问底层数组可以修改原值。性能上两者差异很小，除非元素为大结构体，range 会拷贝整个结构体。\n示例：\npackage main import \u0026#34;fmt\u0026#34; type Big struct{ X [100]int } func main() { s := []Big{{}, {}} for i, v := range s { v.X[0] = 1 // 修改的是 v 的拷贝，不会影响 s[i] fmt.Println(\u0026#34;range modified v:\u0026#34;, i, v.X[0]) } for i := range s { s[i].X[0] = 2 // 直接修改底层数组 fmt.Println(\u0026#34;index modified:\u0026#34;, i, s[i].X[0]) } fmt.Println(\u0026#34;final:\u0026#34;, s[0].X[0], s[1].X[0]) } 3. map 初始化的正确写法 思路： 未初始化的 var m map[K]V 为 nil，写入会 panic。正确方式：m := make(map[string]int) 或 m := map[string]int{}。在并发场景使用 sync.Mutex 或 sync.Map。\n示例：\npackage main import \u0026#34;fmt\u0026#34; func main() { var a map[string]int // a[\u0026#34;x\u0026#34;] = 1 // panic: assignment to entry in nil map b := make(map[string]int) b[\u0026#34;x\u0026#34;] = 1 fmt.Println(b) c := map[string]int{\u0026#34;y\u0026#34;:2} fmt.Println(c) } 4. defer 的执行顺序与 return 思路： defer 按 LIFO（后进先出）顺序执行。函数返回时会先计算返回值（若有命名返回值则是赋值过程），然后执行 defer，最后真正返回。若 defer 修改了命名返回值，则返回值会变。\n示例：\npackage main import \u0026#34;fmt\u0026#34; func f() (r int) { defer func() { r += 1 // 修改命名返回值 }() return 1 // 会先将 r=1，然后执行 defer，使得 r=2，最终返回 2 } func main() { fmt.Println(f()) // 输出 2 } 5. append 扩容与避免复制 思路： 当 slice 的 len \u0026lt; cap 时 append 不会分配新数组；若需要避免复制可以提前 make 出合适的 cap 或使用 append(make([]T,0,needed), ...)。\n示例：\npackage main import \u0026#34;fmt\u0026#34; func main() { s := make([]int, 0, 5) for i := 0; i \u0026lt; 5; i++ { s = append(s, i) } fmt.Println(cap(s), s) } 6. string 与 []byte 转换优化 思路： 频繁转换会产生内存拷贝。可以使用 strings.Builder / bytes.Buffer 来构建字符串，或用 unsafe 做零拷贝转换（有风险，不推荐在面试时随意使用，需注明安全性问题）。\n示例：\npackage main import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { var b bytes.Buffer for i := 0; i \u0026lt; 1000; i++ { b.WriteString(\u0026#34;x\u0026#34;) } s := b.String() fmt.Println(len(s)) } 7. 实现一个线程安全的简单 map 思路： 使用 sync.RWMutex 提供并发安全的 Get/Set/Delete。\n示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) type SafeMap struct { mu sync.RWMutex m map[string]interface{} } func NewSafeMap() *SafeMap { return \u0026amp;SafeMap{m: make(map[string]interface{})} } func (s *SafeMap) Set(k string, v interface{}) { s.mu.Lock() defer s.mu.Unlock() s.m[k] = v } func (s *SafeMap) Get(k string) (interface{}, bool) { s.mu.RLock() defer s.mu.RUnlock() v, ok := s.m[k] return v, ok } func (s *SafeMap) Delete(k string) { s.mu.Lock() defer s.mu.Unlock() delete(s.m, k) } func main() { sm := NewSafeMap() sm.Set(\u0026#34;a\u0026#34;, 1) v, ok := sm.Get(\u0026#34;a\u0026#34;) fmt.Println(v, ok) sm.Delete(\u0026#34;a\u0026#34;) } 🟡 中级场景题（并发与控制） 1. WaitGroup 控制并发任务 思路： 使用 sync.WaitGroup 的 Add/Done/Wait。注意：Add 应在启动 goroutine 之前或在主 goroutine 中，避免竞态。Done 次数必须与 Add 对应。\n示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func worker(id int, wg *sync.WaitGroup) { defer wg.Done() time.Sleep(100 * time.Millisecond) fmt.Println(\u0026#34;worker\u0026#34;, id, \u0026#34;done\u0026#34;) } func main() { var wg sync.WaitGroup for i := 0; i \u0026lt; 5; i++ { wg.Add(1) go worker(i, \u0026amp;wg) } wg.Wait() fmt.Println(\u0026#34;all done\u0026#34;) } 2. 固定大小的 goroutine 池（worker pool） 思路： 使用任务 channel 和固定数量的 worker goroutine，提供 Submit 接口并可关闭池。\n示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) type Task func() type Pool struct { tasks chan Task wg sync.WaitGroup } func NewPool(workerCount, queueSize int) *Pool { p := \u0026amp;Pool{tasks: make(chan Task, queueSize)} p.wg.Add(workerCount) for i := 0; i \u0026lt; workerCount; i++ { go func() { defer p.wg.Done() for t := range p.tasks { t() } }() } return p } func (p *Pool) Submit(t Task) { p.tasks \u0026lt;- t } func (p *Pool) Shutdown() { close(p.tasks) p.wg.Wait() } func main() { p := NewPool(3, 10) for i := 0; i \u0026lt; 10; i++ { n := i p.Submit(func() { fmt.Println(\u0026#34;task\u0026#34;, n) }) } p.Shutdown() fmt.Println(\u0026#34;pool shutdown\u0026#34;) } 3. 生产者-消费者模型（优雅退出） 思路： 使用带缓冲 channel，生产者在关闭时关闭 channel，消费者 range channel 直到结束。或者使用 context 控制多生产者多消费者的退出。\n示例：\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func producer(ctx context.Context, ch chan\u0026lt;- int, id int) { defer fmt.Println(\u0026#34;producer\u0026#34;, id, \u0026#34;exit\u0026#34;) for i := 0; i \u0026lt; 5; i++ { select { case \u0026lt;-ctx.Done(): return case ch \u0026lt;- i: time.Sleep(10 * time.Millisecond) } } } func consumer(ctx context.Context, ch \u0026lt;-chan int, id int, wg *sync.WaitGroup) { defer wg.Done() for { select { case \u0026lt;-ctx.Done(): return case v, ok := \u0026lt;-ch: if !ok { return } fmt.Println(\u0026#34;consumer\u0026#34;, id, \u0026#34;got\u0026#34;, v) } } } func main() { ctx, cancel := context.WithCancel(context.Background()) defer cancel() ch := make(chan int, 10) var wg sync.WaitGroup // start consumers for i := 0; i \u0026lt; 3; i++ { wg.Add(1) go consumer(ctx, ch, i, \u0026amp;wg) } // producers for i := 0; i \u0026lt; 2; i++ { go producer(ctx, ch, i) } time.Sleep(100 * time.Millisecond) cancel() // graceful shutdown close(ch) wg.Wait() fmt.Println(\u0026#34;all done\u0026#34;) } //完整版本 package main import ( \u0026#34;context\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;sync/atomic\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;time\u0026#34; ) // TaskFunc 是要执行的任务函数 type TaskFunc func(ctx context.Context) error var ( ErrQueueFull = errors.New(\u0026#34;task queue is full\u0026#34;) ErrStopped = errors.New(\u0026#34;manager stopped; not accepting tasks\u0026#34;) ) // Manager 管理生产者/消费者 type Manager struct { queue chan *taskWrapper workers int maxRetries int retryBase time.Duration // 基础重试延迟（会指数增长） ratePerSec int // 0 表示不做速率限制 // 内部控制 closed uint32 // atomic flag: 1 表示已关闭（不再接受任务） wg sync.WaitGroup // context 用于取消正在执行的任务（当需要立即停止） ctx context.Context cancel context.CancelFunc // rate limiting token channel（当 ratePerSec\u0026gt;0 时使用） tokens chan struct{} // 统计 enqueued uint64 queuedFail uint64 processed uint64 failed uint64 retried uint64 // 可选的错误回调 OnError func(taskID string, err error) } // taskWrapper 包装任务，便于附带 id/info type taskWrapper struct { id string fn TaskFunc } // NewManager 创建 Manager // queueSize: 队列缓冲长度 // workers: 消费者数量 // maxRetries: 每个任务重试次数（0 表示不重试） // retryBase: 基础重试间隔，例如 200*time.Millisecond // ratePerSec: 每秒最大处理数（0 表示不限制） func NewManager(queueSize, workers, maxRetries int, retryBase time.Duration, ratePerSec int) *Manager { ctx, cancel := context.WithCancel(context.Background()) m := \u0026amp;Manager{ queue: make(chan *taskWrapper, queueSize), workers: workers, maxRetries: maxRetries, retryBase: retryBase, ratePerSec: ratePerSec, ctx: ctx, cancel: cancel, } if ratePerSec \u0026gt; 0 { m.tokens = make(chan struct{}, ratePerSec) // 容量为每秒令牌上限 interval := time.Second / time.Duration(ratePerSec) if interval \u0026lt;= 0 { interval = time.Millisecond } go func() { tk := time.NewTicker(interval) defer tk.Stop() for { select { case \u0026lt;-m.ctx.Done(): return case \u0026lt;-tk.C: // 非阻塞发送 token（保持上限） select { case m.tokens \u0026lt;- struct{}{}: default: } } } }() } return m } // Start 启动所有 worker func (m *Manager) Start() { for i := 0; i \u0026lt; m.workers; i++ { m.wg.Add(1) go m.worker(i) } } // Enqueue 尝试把任务放入队列（非阻塞风格） // 如果队列满会返回 ErrQueueFull // 如果 manager 已停止则返回 ErrStopped func (m *Manager) Enqueue(id string, fn TaskFunc) error { if atomic.LoadUint32(\u0026amp;m.closed) == 1 { atomic.AddUint64(\u0026amp;m.queuedFail, 1) return ErrStopped } select { case m.queue \u0026lt;- \u0026amp;taskWrapper{id: id, fn: fn}: atomic.AddUint64(\u0026amp;m.enqueued, 1) return nil default: atomic.AddUint64(\u0026amp;m.queuedFail, 1) return ErrQueueFull } } // worker 是每个消费者 goroutine 的主循环 func (m *Manager) worker(idx int) { defer m.wg.Done() for tw := range m.queue { // 如果 tokens 不为 nil，则做速率限制 if m.tokens != nil { select { case \u0026lt;-m.ctx.Done(): return case \u0026lt;-m.tokens: // got token } } m.processTask(tw) } // 当 queue 被 close，range 结束，worker 退出 } // processTask 执行单个任务，包含重试与 panic 恢复 func (m *Manager) processTask(tw *taskWrapper) { // recover panic, 记录为失败 defer func() { if r := recover(); r != nil { err := fmt.Errorf(\u0026#34;panic: %v\u0026#34;, r) atomic.AddUint64(\u0026amp;m.failed, 1) if m.OnError != nil { m.OnError(tw.id, err) } } }() var attempt int for { attempt++ // 如果全局 cancel，被立即取消 -\u0026gt; 放弃或视为失败 select { case \u0026lt;-m.ctx.Done(): atomic.AddUint64(\u0026amp;m.failed, 1) if m.OnError != nil { m.OnError(tw.id, fmt.Errorf(\u0026#34;task cancelled\u0026#34;)) } return default: } // 执行任务 err := tw.fn(m.ctx) if err == nil { atomic.AddUint64(\u0026amp;m.processed, 1) return } // 失败处理 atomic.AddUint64(\u0026amp;m.retried, 1) if attempt \u0026gt; m.maxRetries { atomic.AddUint64(\u0026amp;m.failed, 1) if m.OnError != nil { m.OnError(tw.id, err) } return } // 指数退避 + 抖动 backoff := m.retryBase * (1 \u0026lt;\u0026lt; (attempt - 1)) // 添加少量随机抖动 jitter := time.Duration(rand.Int63n(int64(backoff)/2+1)) sleep := backoff + jitter // 但如果 ctx 被 cancel，提前返回 select { case \u0026lt;-time.After(sleep): // 再试 case \u0026lt;-m.ctx.Done(): atomic.AddUint64(\u0026amp;m.failed, 1) if m.OnError != nil { m.OnError(tw.id, fmt.Errorf(\u0026#34;task cancelled during backoff\u0026#34;)) } return } } } // Shutdown 优雅关闭：停止接受新任务、关闭队列并等待 worker 完成（直到超时） // 如果 graceful=false，则立即 cancel 所有正在运行的任务并立即关闭 func (m *Manager) Shutdown(graceful bool, timeout time.Duration) error { // 先设置 closed 标志，阻止新的入队 if !atomic.CompareAndSwapUint32(\u0026amp;m.closed, 0, 1) { // already closed } if !graceful { // 立即取消正在运行的任务 m.cancel() // close queue to wake workers (they will exit when range ends) close(m.queue) // wait for workers done := make(chan struct{}) go func() { m.wg.Wait() close(done) }() select { case \u0026lt;-done: return nil case \u0026lt;-time.After(timeout): return errors.New(\u0026#34;timeout waiting for shutdown\u0026#34;) } } // graceful: 关闭队列，等待队列处理完（workers range 结束） close(m.queue) // 等待 workers 完成或超时 done := make(chan struct{}) go func() { m.wg.Wait() close(done) }() select { case \u0026lt;-done: return nil case \u0026lt;-time.After(timeout): // 如果超时，可以选择 cancel 正在运行的任务 m.cancel() return errors.New(\u0026#34;timeout waiting for graceful shutdown; cancelled running tasks\u0026#34;) } } // Stats 返回当前统计信息 type Stats struct { Enqueued uint64 EnqueueFail uint64 Processed uint64 Failed uint64 Retries uint64 QueueLen int } func (m *Manager) Stats() Stats { return Stats{ Enqueued: atomic.LoadUint64(\u0026amp;m.enqueued), EnqueueFail: atomic.LoadUint64(\u0026amp;m.queuedFail), Processed: atomic.LoadUint64(\u0026amp;m.processed), Failed: atomic.LoadUint64(\u0026amp;m.failed), Retries: atomic.LoadUint64(\u0026amp;m.retried), QueueLen: len(m.queue), } } // ------------------- 演示 main ------------------- func main() { // 随机数种子（用于 jitter） rand.Seed(time.Now().UnixNano()) // 创建 manager：队列 100，5 个 worker，每任务最多 3 次重试，基本退避 200ms，速率每秒 20 m := NewManager(100, 5, 3, 200*time.Millisecond, 20) m.OnError = func(id string, err error) { log.Printf(\u0026#34;[OnError] task %s error: %v\\n\u0026#34;, id, err) } m.Start() // 捕获系统信号用于优雅退出 sigCh := make(chan os.Signal, 1) signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM) // 模拟生产者（并发产生任务） producers := 3 var prodWg sync.WaitGroup prodWg.Add(producers) totalTasks := 1000 taskCounter := uint64(0) for p := 0; p \u0026lt; producers; p++ { go func(pid int) { defer prodWg.Done() for { n := atomic.AddUint64(\u0026amp;taskCounter, 1) if int(n) \u0026gt; totalTasks { return } id := fmt.Sprintf(\u0026#34;task-%d-p%d\u0026#34;, n, pid) // 任务：随机成功或失败，失败会触发重试 err := m.Enqueue(id, func(ctx context.Context) error { // 模拟处理时间 select { case \u0026lt;-time.After(time.Duration(rand.Intn(200)) * time.Millisecond): case \u0026lt;-ctx.Done(): return ctx.Err() } // 随机失败概率 if rand.Intn(100) \u0026lt; 20 { return fmt.Errorf(\u0026#34;random failure for %s\u0026#34;, id) } // 做点事情... //fmt.Println(\u0026#34;processed\u0026#34;, id) return nil }) if err == ErrQueueFull { // 简单：重试入队一次再放弃（真实生产可以更复杂） time.Sleep(50 * time.Millisecond) _ = m.Enqueue(id, func(ctx context.Context) error { time.Sleep(10 * time.Millisecond) return nil }) } } }(p) } // 等待生产者完成或者接收到退出信号 go func() { prodWg.Wait() // 所有任务已产生，关闭 manager（graceful） log.Println(\u0026#34;all producers done; initiating graceful shutdown\u0026#34;) if err := m.Shutdown(true, 30*time.Second); err != nil { log.Println(\u0026#34;graceful shutdown error:\u0026#34;, err) } }() // 监听退出信号，用户可以 Ctrl+C 提前停止（立即 cancel） select { case s := \u0026lt;-sigCh: log.Printf(\u0026#34;signal %v received: stopping immediately\\n\u0026#34;, s) _ = m.Shutdown(false, 5*time.Second) } // 打印统计 fmt.Println(\u0026#34;final stats:\u0026#34;, m.Stats()) } 4. 两个 goroutine 交替打印 1~100 思路： 使用两个无缓冲 channel 交替通知，或使用 sync.Cond。下面示例使用 channel。\n示例：\npackage main import \u0026#34;fmt\u0026#34; // 交替打印1-100 func DoubleChanPrint() { chan1 := make(chan struct{}) chan2 := make(chan struct{}) wg := sync.WaitGroup{} wg.Add(2) go func() { defer wg.Done() for i := 1; i \u0026lt; 100; i += 2 { \u0026lt;-chan1 fmt.Println(\u0026#34;chan1 : \u0026#34;, i) chan2 \u0026lt;- struct{}{} } }() go func() { defer wg.Done() for i := 2; i \u0026lt;= 100; i += 2 { \u0026lt;-chan2 fmt.Println(\u0026#34;chan2 : \u0026#34;, i) if i \u0026lt; 100 { chan1 \u0026lt;- struct{}{} } } }() chan1 \u0026lt;- struct{}{} wg.Wait() close(chan1) close(chan2) } func DoubleChanPrint2() { chan1 := make(chan int) // 用于发送奇数 (1, 3, 5...) chan2 := make(chan int) // 用于发送偶数 (2, 4, 6...) wg := sync.WaitGroup{} wg.Add(2) go func() { defer wg.Done() for v := range chan1 { // 接收奇数，发送偶数 fmt.Println(\u0026#34;chan1 : \u0026#34;, v) // 打印奇数 if v \u0026lt; 99 { chan2 \u0026lt;- v + 1 } else { // v == 99，发送100后，就可以关闭chan2了 chan2 \u0026lt;- v + 1 // 发送 100 close(chan2) } } }() go func() { defer wg.Done() for v := range chan2 { // 接收偶数，发送奇数 fmt.Println(\u0026#34;chan2 : \u0026#34;, v) // 打印偶数 if v \u0026lt; 100 { // v == 100时，是最后一个数字，不应该再发送了 chan1 \u0026lt;- v + 1 } else { // v == 100, 是最后一个数字，什么都不用做， // 只是等待 chan2 被关闭后，循环自然结束。 close(chan1) } } // chan2 被关闭后，循环结束，执行 defer wg.Done() }() chan1 \u0026lt;- 1 // 启动 wg.Wait() //close(chan1) } 5. 限制并发数量（比如最多 10 个任务） 思路： 使用带缓冲的信号量 channel 或者 sync.WaitGroup + 有限 worker pool。\n示例（信号量）：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { sem := make(chan struct{}, 10) // 最大 10 并发 var wg sync.WaitGroup for i := 0; i \u0026lt; 50; i++ { wg.Add(1) sem \u0026lt;- struct{}{} go func(n int) { defer wg.Done() defer func() { \u0026lt;-sem }() time.Sleep(50 * time.Millisecond) fmt.Println(\u0026#34;task\u0026#34;, n) }(i) } wg.Wait() fmt.Println(\u0026#34;all tasks done\u0026#34;) } 6. context 控制任务超时与取消 思路： 使用 context.WithTimeout 或 WithCancel，在 goroutine 内选择 ctx.Done()。\n示例：\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func do(ctx context.Context) { select { case \u0026lt;-time.After(2 * time.Second): fmt.Println(\u0026#34;work done\u0026#34;) case \u0026lt;-ctx.Done(): fmt.Println(\u0026#34;cancelled:\u0026#34;, ctx.Err()) } } func main() { ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second) defer cancel() do(ctx) } 🔴 高级场景题（系统设计与性能） 1. 本地缓存系统（TTL + 并发安全 + 清理） 思路： map 存储 key -\u0026gt; {value, expireAt}，使用 RWMutex 保护。启动后台 goroutine 周期性清理过期项。提供 Get/Set/Delete 接口。\n示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) type item struct { value interface{} expireAt int64 } type Cache struct { mu sync.RWMutex m map[string]*item stop chan struct{} wg sync.WaitGroup } func NewCache() *Cache { c := \u0026amp;Cache{m: make(map[string]*item), stop: make(chan struct{})} c.wg.Add(1) go c.periodicClean(1 * time.Second) return c } func (c *Cache) Set(k string, v interface{}, ttl time.Duration) { c.mu.Lock() defer c.mu.Unlock() c.m[k] = \u0026amp;item{value: v, expireAt: time.Now().Add(ttl).UnixNano()} } func (c *Cache) Get(k string) (interface{}, bool) { c.mu.RLock() it, ok := c.m[k] c.mu.RUnlock() if !ok { return nil, false } if time.Now().UnixNano() \u0026gt; it.expireAt { c.mu.Lock() delete(c.m, k) c.mu.Unlock() return nil, false } return it.value, true } func (c *Cache) periodicClean(interval time.Duration) { defer c.wg.Done() ticker := time.NewTicker(interval) defer ticker.Stop() for { select { case \u0026lt;-ticker.C: now := time.Now().UnixNano() c.mu.Lock() for k, v := range c.m { if now \u0026gt; v.expireAt { delete(c.m, k) } } c.mu.Unlock() case \u0026lt;-c.stop: return } } } func (c *Cache) Close() { close(c.stop) c.wg.Wait() } func main() { c := NewCache() c.Set(\u0026#34;a\u0026#34;, 1, 2*time.Second) v, ok := c.Get(\u0026#34;a\u0026#34;) fmt.Println(v, ok) time.Sleep(3 * time.Second) v, ok = c.Get(\u0026#34;a\u0026#34;) fmt.Println(v, ok) c.Close() } 2. LRU 缓存（map + 双向链表，线程安全） 思路： 用 map 保存 key-\u0026gt;node，双向链表维护访问顺序。Get 将节点移到头部；Set 插入并在超容量时移除尾部。加锁保证并发安全。\n示例：\npackage main func main() { } // 实现lru type Node struct { key, val int prev, next *Node } type LRUCache struct { capacity int head, tail *Node cache map[int]*Node } func Constructor(capacity int) LRUCache { lru := LRUCache{ capacity: capacity, head: \u0026amp;Node{}, tail: \u0026amp;Node{}, cache: make(map[int]*Node, capacity+1), } lru.head.next = lru.tail lru.tail.prev = lru.head return lru } func (l LRUCache) Get(key int) int { if node, ok := l.cache[key]; ok { l.MoveToHead(node) return node.val } return -1 } func (l LRUCache) Put(key int, value int) { if node, ok := l.cache[key]; ok { node.val = value l.MoveToHead(node) } else { node := \u0026amp;Node{key, value, nil, nil} l.cache[key] = node l.AddNodeToHead(node) if len(l.cache) \u0026gt; l.capacity { node := l.RemoveTail() delete(l.cache, node.key) } } } func (l LRUCache) MoveToHead(node *Node) { l.RemoveNode(node) l.AddNodeToHead(node) } func (l LRUCache) RemoveNode(node *Node) { node.prev.next = node.next node.next.prev = node.prev } func (l LRUCache) AddNodeToHead(node *Node) { node.prev = l.head node.next = l.head.next l.head.next.prev = node l.head.next = node } func (l LRUCache) RemoveTail() *Node { node := l.tail.prev l.RemoveNode(node) return node } 3. 简易消息队列（发布/订阅） 思路： 使用 channel + map[channel] 为每个订阅者提供接收通道。持久化需要额外将消息写入磁盘/数据库并做确认机制。\n示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) type Broker struct { mu sync.RWMutex subs map[string][]chan string } func NewBroker() *Broker { return \u0026amp;Broker{subs: make(map[string][]chan string)} } func (b *Broker) Subscribe(topic string) chan string { ch := make(chan string, 10) b.mu.Lock() b.subs[topic] = append(b.subs[topic], ch) b.mu.Unlock() return ch } func (b *Broker) Publish(topic, msg string) { b.mu.RLock() subs := b.subs[topic] b.mu.RUnlock() for _, ch := range subs { select { case ch \u0026lt;- msg: default: // drop or buffer full handling } } } func (b *Broker) Unsubscribe(topic string, ch chan string) { b.mu.Lock() defer b.mu.Unlock() subs := b.subs[topic] for i, c := range subs { if c == ch { b.subs[topic] = append(subs[:i], subs[i+1:]...) close(c) break } } } func main() { b := NewBroker() ch := b.Subscribe(\u0026#34;t1\u0026#34;) go func() { for m := range ch { fmt.Println(\u0026#34;recv\u0026#34;, m) } }() b.Publish(\u0026#34;t1\u0026#34;, \u0026#34;hello\u0026#34;) b.Unsubscribe(\u0026#34;t1\u0026#34;, ch) } 4. 秒杀系统防超卖（关键思路） 思路： 在高并发下避免超卖：使用 Redis 做库存预减（Lua 脚本保证原子性），引入本地内存售罄标记 + 消息队列异步下单，打散写库压力。\n关键 Lua 伪码：\n-- KEYS[1] stock key -- ARGV[1] amount local stock = tonumber(redis.call(\u0026#39;get\u0026#39;, KEYS[1]) or \u0026#39;0\u0026#39;) if stock \u0026lt;= 0 then return 0 end if stock \u0026lt; tonumber(ARGV[1]) then return 0 end redis.call(\u0026#39;decrby\u0026#39;, KEYS[1], ARGV[1]) return 1 Go 示例调用（简化）：\n// 省略 redis 客户端初始化，示例伪码 script := `...` // 上面的 lua res, err := redisClient.Eval(ctx, script, []string{\u0026#34;stock:1\u0026#34;}, 1).Result() if err != nil { /* handle */ } if res.(int64) == 1 { // push order info to MQ for async processing } 5. 限流组件（令牌桶） 思路： 用 goroutine 持续按速率向 channel 放 token，业务处理前尝试取 token，取不到则拒绝或等待。\n示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) type TokenBucket struct { tokens chan struct{} } func NewTokenBucket(rate int, capacity int) *TokenBucket { tb := \u0026amp;TokenBucket{tokens: make(chan struct{}, capacity)} ticker := time.NewTicker(time.Second / time.Duration(rate)) // 初始时先装满 for i := 0; i \u0026lt; capacity; i++ { tb.tokens \u0026lt;- struct{}{} } go func() { for range ticker.C { select { case tb.tokens \u0026lt;- struct{}{}: default: } } }() return tb } func (tb *TokenBucket) Allow() bool { select { case \u0026lt;-tb.tokens: return true default: return false } } func main() { tb := NewTokenBucket(5, 10) // 每秒 5 个，桶容量 10 for i := 0; i \u0026lt; 20; i++ { if tb.Allow() { fmt.Println(\u0026#34;allowed\u0026#34;, i) } else { fmt.Println(\u0026#34;rejected\u0026#34;, i) } time.Sleep(100 * time.Millisecond) } } ⚙️ 实战 Debug 场景题（排障与优化） 1. goroutine 泄漏排查 思路： 使用 pprof 获取 goroutine 堆栈，定位阻塞点（例如 channel 阻塞、select 没有 default 等）。检查所有 goroutine 启动位置并确保有退出路径或 context 控制。\npprof 示例：\n// 在程序 main 中引入 net/http/pprof import _ \u0026#34;net/http/pprof\u0026#34; import \u0026#34;net/http\u0026#34; go func() { http.ListenAndServe(\u0026#34;localhost:6060\u0026#34;, nil) }() // 然后在终端使用: go tool pprof http://localhost:6060/debug/pprof/goroutine 2. 死锁定位与修复 示例死锁代码：\npackage main import \u0026#34;sync\u0026#34; func main() { var mu sync.Mutex mu.Lock() // do something mu.Lock() // deadlock: same goroutine locks twice } 修复： 不要在同一 goroutine 重复加普通 Mutex，或改用 sync.RWMutex/设计避免重入场景，或使用可重入锁（需要自行实现）。\n3. 内存暴涨分析与优化 思路： 用 pprof 的 heap 分析哪个对象占用内存最多；检查切片/缓存是否无限制增长，检查 goroutine 堆栈是否过多导致占用。优化：限制缓存大小、复用对象（sync.Pool）、避免大对象拷贝。\n4. 锁竞争诊断与优化 思路： 用 pprof 的 mutex profile 或 runtime/trace 找到热点锁，分析是短临界区还是长临界区，考虑分段锁、减少锁持有时间、使用读写锁或 lock-free 结构。\n5. pprof 找到热点后改进示例 示例： 假设热点在字符串拼接，优化前用 + 频繁拼接，优化后使用 strings.Builder：\n// before: using + inside loop -\u0026gt; lots of allocations // after: import \u0026#34;strings\u0026#34; var b strings.Builder for _, s := range parts { b.WriteString(s) } res := b.String() ",
"tags":null,
"categories":null
},{
"title":"限流熔断降级",
"permalink": "http://localhost:1313/posts/microservice/%E9%99%90%E6%B5%81%E7%86%94%E6%96%AD%E9%99%8D%E7%BA%A7/",
"summary": " 「熔断、限流、降级」 它们都属于服务稳定性设计（Service Resilience）的一部分。\n下面我给你一个“面试官喜欢听”的回答框架，从概念 → 场景 → 实现 → 举例 四步讲清楚， 适合百度这种系统架构导向的岗位 👇\n🧩 一、三者区别和联系（高层答法） 一句话记忆：\n限流：控制请求量，不让系统被压垮。 熔断：发现下游挂了，别再请求它。 降级：资源紧张时，主动牺牲部分功能，保证核心可用。 面试开头可以这样讲：\n“在微服务架构下，我们通常通过限流、熔断、降级三种机制保障系统的稳定性。 三者的核心目标都是防止服务雪崩，只是介入的时机不同：\n限流在请求入口处防止流量打爆； 熔断在调用链中断开异常依赖； 降级则在系统压力大时主动丢弃非核心功能。” ⚙️ 二、限流（Rate Limiting） 📘 概念 限制系统单位时间内可处理的请求数。\n📍常见算法 固定窗口（Fixed Window） 滑动窗口（Sliding Window） 漏桶算法（Leaky Bucket） 令牌桶算法（Token Bucket）✅ 常用 令牌桶算法原理：系统按照固定速率生成令牌，请求只有拿到令牌才能执行，否则拒绝或排队。\n🛠️ 实现方式 单机限流：用 golang.org/x/time/rate（Go官方限流包） 分布式限流：用 Redis 实现（Lua脚本保证原子性） 网关层限流：在 API Gateway（如 Kong、Nginx、Kratos Gateway）配置规则 💬 举例 “比如我在上一个项目中，为防止短信接口被刷，我们在 Nginx 层按 IP + URI 做限流，用令牌桶算法控制速率为 10 req/s，多余的直接返回 429 Too Many Requests。”\n",
"content": " 「熔断、限流、降级」 它们都属于服务稳定性设计（Service Resilience）的一部分。\n下面我给你一个“面试官喜欢听”的回答框架，从概念 → 场景 → 实现 → 举例 四步讲清楚， 适合百度这种系统架构导向的岗位 👇\n🧩 一、三者区别和联系（高层答法） 一句话记忆：\n限流：控制请求量，不让系统被压垮。 熔断：发现下游挂了，别再请求它。 降级：资源紧张时，主动牺牲部分功能，保证核心可用。 面试开头可以这样讲：\n“在微服务架构下，我们通常通过限流、熔断、降级三种机制保障系统的稳定性。 三者的核心目标都是防止服务雪崩，只是介入的时机不同：\n限流在请求入口处防止流量打爆； 熔断在调用链中断开异常依赖； 降级则在系统压力大时主动丢弃非核心功能。” ⚙️ 二、限流（Rate Limiting） 📘 概念 限制系统单位时间内可处理的请求数。\n📍常见算法 固定窗口（Fixed Window） 滑动窗口（Sliding Window） 漏桶算法（Leaky Bucket） 令牌桶算法（Token Bucket）✅ 常用 令牌桶算法原理：系统按照固定速率生成令牌，请求只有拿到令牌才能执行，否则拒绝或排队。\n🛠️ 实现方式 单机限流：用 golang.org/x/time/rate（Go官方限流包） 分布式限流：用 Redis 实现（Lua脚本保证原子性） 网关层限流：在 API Gateway（如 Kong、Nginx、Kratos Gateway）配置规则 💬 举例 “比如我在上一个项目中，为防止短信接口被刷，我们在 Nginx 层按 IP + URI 做限流，用令牌桶算法控制速率为 10 req/s，多余的直接返回 429 Too Many Requests。”\n⚡ 三、熔断（Circuit Breaker） 📘 概念 当调用下游服务持续失败时，自动中断调用一段时间，防止整个系统被拖垮。\n📍实现机制 通常包含三个状态：\nClosed（闭合）：正常请求 Open（打开）：达到失败阈值后，直接拒绝请求（避免雪崩） Half-Open（半开）：等待一部分请求探测下游是否恢复 熔断器会记录失败次数和超时率，当超过阈值时进入 Open 状态；一段时间后再尝试“探测请求”恢复。\n🛠️ 实现方式 Go中可用：sony/gobreaker、Resilience4j（Java风格） Kratos中：在客户端中间件配置熔断策略 分布式场景：Prometheus + Alertmanager 做熔断触发 💬 举例 “比如调用AI生成服务时，如果QPS激增，下游生成模块响应超时率超过30%，我们触发熔断，暂时返回兜底提示‘系统繁忙’，等过一段时间再半开探测。”\n🪫 四、降级（Degrade / Fallback） 📘 概念 在系统高负载、下游故障或熔断时，主动关闭部分非核心功能，以保障主流程可用。\n📍典型场景 推荐系统只返回缓存内容（不实时召回） 搜索接口只展示主结果，不展示相关推荐 AIGC接口超时则直接提示“任务排队中” 🛠️ 实现方式 静态降级：直接返回默认值或缓存结果 动态降级：通过配置中心（如 Apollo、Nacos）动态调整策略 智能降级：结合熔断 + 流量监控自动触发 💬 举例 “比如在AIGC任务高峰期，我们检测到生成服务CPU飙升，会主动将生成图片功能降级为文本描述生成，让核心任务不中断。”\n🔄 五、三者关系总结（面试加分总结） “三者常常配合使用：\n限流保护入口； 熔断隔离故障； 降级兜底体验。 \u0026gt; 我们会通过监控（Prometheus + Grafana）动态调整这些策略，实现自动化稳定性控制。” 🧠 面试官延伸问法（提前准备） 问题 回答方向 熔断触发后怎么恢复？ 有个“半开”状态，通过少量探测请求判断是否恢复 限流算法中哪个能应对突发流量？ 令牌桶比漏桶更灵活，能短时突发 如何分布式限流？ Redis + Lua脚本保证原子操作 降级后如何恢复？ 可通过配置中心动态开关或根据监控指标恢复 熔断/限流指标怎么监控？ QPS、失败率、P99延迟、error ratio、CPU load ✅ 总结 “在微服务架构中，我通常会通过限流、熔断和降级三种手段保障系统稳定性： 限流主要在入口层控制流量，比如用令牌桶算法限制请求速率； 熔断用于调用下游接口时防止雪崩，比如连续失败率超过30%就暂时中断调用； 降级则在系统压力大或依赖异常时返回缓存或默认值，保证主流程可用。 这三者配合监控体系一起使用，可以有效提升系统的韧性和自恢复能力。”\n进阶 🎯 问题核心：「微服务中的熔断、限流、降级机制」 这是后端中非常高频的中高级面试题，尤其是百度、字节、美团等大厂常问。 他们主要想考你三点：\n你是否理解三者的区别与联系。 你是否知道业界常见的实现方式。 你能否结合实际项目场景举例说明。 一、先区分概念（简短但清晰） 机制 作用 触发条件 目标 限流 控制并发量或请求速率 QPS 超过阈值 防止系统被压垮 熔断 阻止对下游服务的访问 下游响应慢/错误率高 防止雪崩效应 降级 主动减少功能或返回兜底数据 下游异常/高峰压力 保证核心功能可用 一句话总结：\n限流是“防洪坝”，熔断是“保险丝”，降级是“备用方案”。\n二、原理与实现方式 1️⃣ 限流 常见算法\n固定窗口：每秒最多 N 次请求。 滑动窗口：更平滑控制。 令牌桶 / 漏桶算法：控制速率 + 允许突发。 实现\n服务内（如 Go 项目中用 golang.org/x/time/rate） 或借助中间件（如 Nginx、Envoy、Kong、Sentinel） 举例\nlimiter := rate.NewLimiter(10, 20) // 每秒 10 次，最大突发 20 if !limiter.Allow() { return errors.New(\u0026#34;rate limit exceeded\u0026#34;) } 2️⃣ 熔断 核心思想：当依赖服务长时间失败，就“断开电路”，直接返回错误或走降级逻辑。\n状态机模型：\nClosed（闭合）：正常调用； Open（断开）：拒绝请求； Half-Open（半开）：尝试恢复； 实现方式\n使用库：afex/hystrix-go、go-resilience、Sentinel Go 在网关层实现（如 Nacos、Envoy 结合熔断策略） 示例\ncb := gobreaker.NewCircuitBreaker(gobreaker.Settings{ Name: \u0026#34;user-service\u0026#34;, Timeout: 5 * time.Second, ReadyToTrip: func(counts gobreaker.Counts) bool { return counts.ConsecutiveFailures \u0026gt; 5 }, }) result, err := cb.Execute(func() (interface{}, error) { return callUserService() }) 3️⃣ 降级 场景\n依赖超时或熔断时 → 使用缓存 / 兜底逻辑。 高峰时主动关闭非核心功能。 策略\n静态降级（直接返回默认值） 缓存降级（使用上次成功数据） 异步降级（写入 MQ 后异步处理） 示例\nuser, err := getUserFromRemote() if err != nil { // 降级方案：返回缓存或默认数据 user = cache.Get(\u0026#34;user_backup\u0026#34;) } 三、答题模板（面试时这样说） 我们在微服务中一般会通过「限流、熔断、降级」三种手段来保证系统的稳定性。\n限流用于防止瞬时高并发压垮系统，我在项目中通常用令牌桶算法（Go 中的 rate.Limiter）来控制接口的 QPS。\n熔断主要是防止下游雪崩，当某个依赖服务错误率高或响应慢时，通过像 gobreaker 这样的库自动打开熔断器，直接返回快速失败。\n降级则是提供兜底方案，比如下游不可用时，我们会返回缓存数据或提示“系统繁忙”，以保证核心路径可用。\n实际项目中我们也会结合监控（Prometheus + Grafana）和报警来动态调整这些策略。\n四、进阶加分点 限流在入口层（网关）做全局控制，熔断和降级在服务层做细粒度控制。 监控链路：Prometheus → Grafana → Alertmanager。 熔断与限流策略通常是动态配置（通过 Apollo/Nacos 配置中心热更新）。 ",
"tags":null,
"categories":null
},{
"title":"Init",
"permalink": "http://localhost:1313/posts/go/init/",
"summary": "✅ 一、init() 是什么 init() 是 Go 的特殊函数，用于在包被加载时自动执行初始化逻辑。 它不需要显式调用，也不能被其他代码调用。\n✅ 二、init() 的基本特性 特性 说明 触发时机 在包被第一次导入时自动执行（只执行一次） 调用方式 Go runtime 自动调用，不能手动调用 参数 无参数 返回值 无返回值 作用范围 每个包可以定义多个 init() 函数 执行顺序 按照导入依赖关系和源码出现顺序执行 ✅ 三、最基本的例子 package main import \u0026#34;fmt\u0026#34; func init() { fmt.Println(\u0026#34;init() called\u0026#34;) } func main() { fmt.Println(\u0026#34;main() called\u0026#34;) } 输出：\ninit() called main() called ✅ init() 总是在 main() 之前执行。\n✅ 四、包初始化顺序（重点） Go 程序启动时会按如下顺序执行：\n导入依赖包 初始化依赖包的常量和变量 执行依赖包的 init() 函数 执行当前包的常量、变量初始化 执行当前包的 init() 函数 执行 main.main() 示例： // file: a.go package a import \u0026#34;fmt\u0026#34; var V = initVar() func initVar() int { fmt.Println(\u0026#34;a.initVar()\u0026#34;) return 42 } func init() { fmt.Println(\u0026#34;a.init()\u0026#34;) } // file: main.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;example/a\u0026#34; ) func init() { fmt.Println(\u0026#34;main.init()\u0026#34;) } func main() { fmt.Println(\u0026#34;main.main()\u0026#34;, a.V) } 输出：\n",
"content": "✅ 一、init() 是什么 init() 是 Go 的特殊函数，用于在包被加载时自动执行初始化逻辑。 它不需要显式调用，也不能被其他代码调用。\n✅ 二、init() 的基本特性 特性 说明 触发时机 在包被第一次导入时自动执行（只执行一次） 调用方式 Go runtime 自动调用，不能手动调用 参数 无参数 返回值 无返回值 作用范围 每个包可以定义多个 init() 函数 执行顺序 按照导入依赖关系和源码出现顺序执行 ✅ 三、最基本的例子 package main import \u0026#34;fmt\u0026#34; func init() { fmt.Println(\u0026#34;init() called\u0026#34;) } func main() { fmt.Println(\u0026#34;main() called\u0026#34;) } 输出：\ninit() called main() called ✅ init() 总是在 main() 之前执行。\n✅ 四、包初始化顺序（重点） Go 程序启动时会按如下顺序执行：\n导入依赖包 初始化依赖包的常量和变量 执行依赖包的 init() 函数 执行当前包的常量、变量初始化 执行当前包的 init() 函数 执行 main.main() 示例： // file: a.go package a import \u0026#34;fmt\u0026#34; var V = initVar() func initVar() int { fmt.Println(\u0026#34;a.initVar()\u0026#34;) return 42 } func init() { fmt.Println(\u0026#34;a.init()\u0026#34;) } // file: main.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;example/a\u0026#34; ) func init() { fmt.Println(\u0026#34;main.init()\u0026#34;) } func main() { fmt.Println(\u0026#34;main.main()\u0026#34;, a.V) } 输出：\na.initVar() a.init() main.init() main.main() 42 先初始化包 a，再初始化 main。 包的变量初始化在 init() 之前。\n✅ 五、多个 init() 的执行顺序 你可以在同一个包里写多个 init()，例如：\npackage main import \u0026#34;fmt\u0026#34; func init() { fmt.Println(\u0026#34;init 1\u0026#34;) } func init() { fmt.Println(\u0026#34;init 2\u0026#34;) } func main() { fmt.Println(\u0026#34;main\u0026#34;) } 输出：\ninit 1 init 2 main 顺序由源码中的出现顺序决定。\n✅ 六、多个包的 init() 执行顺序 假设项目结构：\nmain.go pkg/ ├─ a.go └─ b.go pkg/a.go package pkg import \u0026#34;fmt\u0026#34; func init() { fmt.Println(\u0026#34;pkg.a.init()\u0026#34;) } pkg/b.go package pkg import \u0026#34;fmt\u0026#34; func init() { fmt.Println(\u0026#34;pkg.b.init()\u0026#34;) } main.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;example/pkg\u0026#34; ) func init() { fmt.Println(\u0026#34;main.init()\u0026#34;) } func main() { fmt.Println(\u0026#34;main.main()\u0026#34;) } 输出：\npkg.a.init() pkg.b.init() main.init() main.main() 同一个包内，按文件名（字母顺序）和声明顺序执行； 被导入包总是先于导入者执行。\n✅ 七、常见用途 使用场景 示例 注册驱动 数据库驱动包常用： _ \u0026quot;github.com/go-sql-driver/mysql\u0026quot; 初始化配置 从配置文件加载环境变量 注册插件 如 init() 中调用 plugin.Register() 启动日志系统 初始化日志输出格式 初始化全局变量 比如缓存、映射表、连接池 ✅ 八、init() vs main() 对比项 init() main() 调用方式 自动 手动（程序入口） 每包执行次数 一次 一次（仅 main 包） 返回值 无 有 执行时机 程序加载阶段 程序运行阶段 主要用途 初始化 业务逻辑执行 ✅ 九、注意事项（容易踩坑） ⚠️ 注意 说明 不可依赖执行顺序跨包调用 init 顺序受依赖关系影响，不适合做复杂逻辑 不建议复杂逻辑 保持轻量：用于初始化，不要写耗时操作 不要 panic 如果 init() panic，会导致整个程序无法启动 包的 init 只执行一次 即使多次 import，同一个包只初始化一次 ✅ 十、最佳实践建议 ✅ 适合做：\n注册（plugin、driver、handler） 初始化全局状态（一次性） 配置加载或环境检测 🚫 不适合做：\n网络请求、复杂运算 启动 goroutine 动态依赖其他包执行顺序 🧩 Bonus：_ 匿名导入与 init() import _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; 虽然没有显式使用 mysql 包，但：\n包仍然会被编译； 其 init() 会执行； 用于注册 MySQL 驱动。 ✅ 总结 特性 说明 执行时机 包加载阶段 执行次数 每包一次 调用方式 自动调用 执行顺序 依赖顺序 → 源码顺序 参数和返回 无 常见用途 注册、初始化、加载配置 注意事项 不要写耗时逻辑，不要依赖跨包顺序 ",
"tags":null,
"categories":null
},{
"title":"Defer",
"permalink": "http://localhost:1313/posts/go/defer/",
"summary": "✅ 一、defer 的基本作用 defer 用来延迟执行一段函数调用，直到当前函数返回时才执行（无论是正常返回还是遇到 panic）。\n示例： func main() { fmt.Println(\u0026#34;A\u0026#34;) defer fmt.Println(\u0026#34;B\u0026#34;) fmt.Println(\u0026#34;C\u0026#34;) } 输出：\nA C B 👉 defer 的调用会在函数退出时执行。\n✅ 二、多个 defer 的执行顺序：后进先出 (LIFO) func main() { defer fmt.Println(\u0026#34;1\u0026#34;) defer fmt.Println(\u0026#34;2\u0026#34;) defer fmt.Println(\u0026#34;3\u0026#34;) } 输出：\n3 2 1 就像栈一样，最后注册的 defer 最先执行。\n✅ 三、参数求值时机：defer 定义时就求值 这是一个非常重要的细节！\nfunc main() { x := 10 defer fmt.Println(\u0026#34;defer:\u0026#34;, x) x = 20 fmt.Println(\u0026#34;x =\u0026#34;, x) } 输出：\nx = 20 defer: 10 🔹 原因： defer 的参数会在注册 defer 时立刻求值，而不是在执行时求值。\n✅ 四、闭包 defer：引用外部变量时会实时读取 func main() { x := 10 defer func() { fmt.Println(\u0026#34;defer:\u0026#34;, x) }() x = 20 fmt.Println(\u0026#34;x =\u0026#34;, x) } 输出：\n",
"content": "✅ 一、defer 的基本作用 defer 用来延迟执行一段函数调用，直到当前函数返回时才执行（无论是正常返回还是遇到 panic）。\n示例： func main() { fmt.Println(\u0026#34;A\u0026#34;) defer fmt.Println(\u0026#34;B\u0026#34;) fmt.Println(\u0026#34;C\u0026#34;) } 输出：\nA C B 👉 defer 的调用会在函数退出时执行。\n✅ 二、多个 defer 的执行顺序：后进先出 (LIFO) func main() { defer fmt.Println(\u0026#34;1\u0026#34;) defer fmt.Println(\u0026#34;2\u0026#34;) defer fmt.Println(\u0026#34;3\u0026#34;) } 输出：\n3 2 1 就像栈一样，最后注册的 defer 最先执行。\n✅ 三、参数求值时机：defer 定义时就求值 这是一个非常重要的细节！\nfunc main() { x := 10 defer fmt.Println(\u0026#34;defer:\u0026#34;, x) x = 20 fmt.Println(\u0026#34;x =\u0026#34;, x) } 输出：\nx = 20 defer: 10 🔹 原因： defer 的参数会在注册 defer 时立刻求值，而不是在执行时求值。\n✅ 四、闭包 defer：引用外部变量时会实时读取 func main() { x := 10 defer func() { fmt.Println(\u0026#34;defer:\u0026#34;, x) }() x = 20 fmt.Println(\u0026#34;x =\u0026#34;, x) } 输出：\nx = 20 defer: 20 👉 因为这里 defer 延迟的是匿名函数，它持有 x 的引用（闭包），所以执行时读到的是最新值。\n✅ 五、defer 与返回值的关系 情况1：命名返回值（可被修改） func demo() (x int) { defer func() { x++ // 修改命名返回值 }() return 1 } func main() { fmt.Println(demo()) // 输出 2 } 解释：\nreturn 1 会先给 x = 1 然后执行 defer 最后返回修改后的 x = 2 情况2：非命名返回值（不会修改） func demo() int { x := 1 defer func() { x++ }() return x } func main() { fmt.Println(demo()) // 输出 1 } 返回值不是命名返回值，defer 里修改 x 不影响返回。\n✅ 六、defer 即使遇到 panic 也会执行 func main() { defer fmt.Println(\u0026#34;defer executed\u0026#34;) panic(\u0026#34;something went wrong\u0026#34;) } 输出：\ndefer executed panic: something went wrong ✅ 七、defer 常见的使用场景 场景 示例 文件关闭 defer file.Close() 数据库连接关闭 defer db.Close() 网络连接关闭 defer conn.Close() 锁释放 mu.Lock(); defer mu.Unlock() panic 恢复 defer func(){ if err := recover(); err != nil {...} }() 性能统计 start := time.Now(); defer func(){ fmt.Println(time.Since(start)) }() ⚠️ 八、性能注意事项 defer 在 Go 1.14 之后性能已显著提升，但仍有一些注意点：\n场景 建议 高频循环内调用 defer ❌ 尽量避免（可手动调用） 普通函数中使用 1~3 个 defer ✅ 完全没问题 Go 1.14+ ✅ defer 性能几乎等价于手动调用 ✅ 九、函数执行顺序总结（超清版） func example() (result int) { defer fmt.Println(\u0026#34;1\u0026#34;) defer func() { fmt.Println(\u0026#34;2, result =\u0026#34;, result) }() defer func(r int) { fmt.Println(\u0026#34;3, r =\u0026#34;, r) }(result) result = 100 return } 输出：\n3, r = 0 2, result = 100 1 执行逻辑：\ndefer 参数求值顺序：立即执行（r = 0） return 执行：赋值 result = 100 按 LIFO 顺序执行 defer 函数返回 ✅ 十、总结 特性 说明 执行时机 函数返回前执行（正常返回或 panic） 执行顺序 后进先出（LIFO） 参数求值时机 注册时求值 支持闭包 可以访问外部变量 命名返回值可修改 是 panic 仍执行 是 性能 Go1.14+ 已大幅优化 ",
"tags":null,
"categories":null
},{
"title":"算法题解题思路",
"permalink": "http://localhost:1313/posts/datastructalgorithm/%E7%AE%97%E6%B3%95%E9%A2%98%E8%A7%A3%E9%A2%98%E6%80%9D%E8%B7%AF/",
"summary": "一、常见题型与核心解法对应表 题型类别 常用解法 关键思维 常见题例 数组 / 序列类 双指针、滑动窗口、前缀和、单调栈 定长窗口 / 不定长窗口 三数之和、最大子序和、每日温度、接雨水 排序 / 查找类 快排、归并、二分查找 有序性 + 区间分治 搜索插入位置、旋转数组最小值 动态规划（DP）类 状态转移 + 子问题划分 “前 i 个…”、“以 i 结尾…” 打家劫舍、最大子序和、单词拆分、爬楼梯 字符串类 DP、双指针、哈希 子串、回文、匹配 最长回文子串、无重复子串长度 哈希 / 集合类 map + 滑动窗口 存在性判断 两数之和、最长不重复子串 栈 / 队列类 单调栈、辅助栈、队列优化 “下一个更大元素” 有效括号、每日温度、接雨水 树 / 图类 DFS / BFS、递归 / 队列 遍历 + 状态传递 二叉树最大深度、岛屿数量、最短路径 贪心类 局部最优 → 全局最优 排序 + 选择 区间合并、跳跃游戏、分发糖果 数学类 模拟、整除、快速幂 数学规律化简 整数反转、Pow(x,n)、罗马数字转整数 二、陌生题分析框架（核心应对模板） 🧩 Step 1：先搞清问题类型 是否要求最值？\n",
"content": "一、常见题型与核心解法对应表 题型类别 常用解法 关键思维 常见题例 数组 / 序列类 双指针、滑动窗口、前缀和、单调栈 定长窗口 / 不定长窗口 三数之和、最大子序和、每日温度、接雨水 排序 / 查找类 快排、归并、二分查找 有序性 + 区间分治 搜索插入位置、旋转数组最小值 动态规划（DP）类 状态转移 + 子问题划分 “前 i 个…”、“以 i 结尾…” 打家劫舍、最大子序和、单词拆分、爬楼梯 字符串类 DP、双指针、哈希 子串、回文、匹配 最长回文子串、无重复子串长度 哈希 / 集合类 map + 滑动窗口 存在性判断 两数之和、最长不重复子串 栈 / 队列类 单调栈、辅助栈、队列优化 “下一个更大元素” 有效括号、每日温度、接雨水 树 / 图类 DFS / BFS、递归 / 队列 遍历 + 状态传递 二叉树最大深度、岛屿数量、最短路径 贪心类 局部最优 → 全局最优 排序 + 选择 区间合并、跳跃游戏、分发糖果 数学类 模拟、整除、快速幂 数学规律化简 整数反转、Pow(x,n)、罗马数字转整数 二、陌生题分析框架（核心应对模板） 🧩 Step 1：先搞清问题类型 是否要求最值？\n是 → 动态规划 / 贪心 否 → 继续往下分析 是否涉及查找 / 存在？\n是 → 哈希 / 二分 是否涉及连续区间或配对？\n是 → 双指针 / 滑动窗口 是否需要路径、层次或连通性？\n是 → DFS / BFS 是否存在“子问题依赖关系”？\n是 → 动态规划 是否涉及树或图结构？\n是 → 递归 / 队列 / 栈 是否是组合枚举类？\n是 → 回溯 / DFS 🧠 Step 2：复杂度预估 + 暴力思路 先写最直接的暴力解，再分析复杂度：\n分析项 示例 时间复杂度 O(n²) / O(n³) / O(2ⁿ) 空间复杂度 O(n) / O(1) 优化方向 排序 → 双指针； 暴力 → DP； 暴力匹配 → 哈希； 遍历 → 单调栈 暴力解是 fallback，是你思考清晰的证明。 你可以先说：\n“我先考虑暴力解 O(n²)，然后优化为双指针 O(n)。”\n🧮 Step 3：状态 / 区间划分（DP 或滑窗核心） 如果是 DP：\n明确状态：dp[i] / dp[i][j] 写转移方程：dp[i] = max/min/sum(...) 初始化边界条件 顺序遍历（由小到大） 如果是滑动窗口：\n左右指针 + 不断调整窗口 满足条件时移动左指针收缩 通常维护最大 / 最小 / 最长区间 ⚙️ Step 4：验证样例 \u0026amp; 极端情况 ✅ 基础样例（题目给的） ⚠️ 边界测试：\n空数组 / 空字符串 全部负数 / 重复值 只有一个元素 超大规模 n = 10⁵ 级别 💬 Step 5：面试时沟通策略 “我先讲下我的思考路径： 我发现这是个求最值的问题，有重叠子问题，因此考虑 DP。 我先写个暴力版本验证思路，然后再优化到 O(n)\u0026hellip;”\n这句话非常加分。 即使写不完代码，也能让面试官觉得你具备结构化思维。\n三、综合模板：陌生题应对 5 步法 步骤 问题 目标 🧩 Step 1 识别题型 判断是 DP、滑窗、DFS、贪心？ 💡 Step 2 暴力建模 明确状态、变量、边界 ⚙️ Step 3 优化思路 找重复子问题 / 单调性 / 可剪枝 🧮 Step 4 写伪代码 保证逻辑闭环，复杂度清晰 🧠 Step 5 举例验证 核查边界与正确性 🔥 示例对比：三数之和 vs 最大子序和 题目 思路归类 核心算法 关键词 三数之和 数组 + 排序 + 双指针 排序 + 去重 + 左右夹逼 排序 → 双指针 最大子序和 序列 + 求最值 动态规划 局部最优转全局最优 改进版本 「看到题 → 知道属于哪类问题 → 知道有哪些典型解法 → 知道从哪开始分析」。\n🧭 一、解题通用分析流程 步骤 思考方向 说明 ① 看输入结构 数组 / 字符串 / 链表 / 树 / 图 / 矩阵 / 特殊约束 ② 看问题类型 求最值 / 计数 / 判断存在 / 排序 / 匹配 / 路径 / 组合等 ③ 是否有“重叠子问题” 有则动态规划，没有可尝试贪心或双指针优化 ④ 是否有“单调性”或“区间性质” 有则考虑双指针 / 单调栈 / 二分 ⑤ 输出目标 返回数值 / 序列 / 索引 / 路径 / 布尔值，不同类型有不同套路 ⑥ 是否可以预处理 排序、前缀和、哈希表、状态压缩、图的预建等 ⑦ 复杂度分析 O(n²) 能不能优化到 O(n log n) 或 O(n) 🧩 二、按输入结构分类的常见算法思路 输入类型 常用算法 典型题目 数组 排序 / 双指针 / 滑动窗口 / 前缀和 / 单调栈 三数之和、接雨水、每日温度、最大子序和 字符串 双指针 / 动态规划 / 哈希计数 / KMP / 回文中心扩展 最长子串、编辑距离、单词拆分 链表 快慢指针 / 反转 / 合并 / 环检测 / 递归 反转链表、两两交换、环形链表 二叉树 DFS / BFS / 递归 / 动态规划 / 栈模拟 二叉树遍历、最大路径和、对称树 图 BFS / DFS / 拓扑排序 / Dijkstra / 并查集 岛屿数量、课程表、最短路径 矩阵 DFS / BFS / 动态规划 / 二分搜索 岛屿数量、最小路径和、搜索二维矩阵 堆/优先队列 获取第k大 / 合并区间 / 延迟删除 数据流中位数、前K个元素 哈希表 / 集合 计数 / 快速查找存在性 / 前缀匹配 两数之和、最长不重复子串 🎯 三、按问题类型分类的常见套路 问题类型 常见思路 经典例题 求最值（最大/最小） 动态规划 / 贪心 / 单调栈 / 分治 最大子序和、打家劫舍、股票买卖 求是否存在 哈希表 / 双指针 / 二分搜索 两数之和、平方数判定 求配对/组合 排序+双指针 / 回溯 / 位运算 三数之和、子集、全排列 求路径/连通性 DFS / BFS / 并查集 岛屿数量、最短路径 求排名/第K大 快排 / 堆 / 二分 第K大元素、滑动窗口最大值 区间问题 排序 + 合并 / 前缀和 / 差分数组 区间合并、子数组和等于K 状态转移（有依赖） 动态规划 打家劫舍、最长递增子序列 括号/结构匹配 栈 / 计数 有效括号、逆波兰表达式求值 回文/子串问题 双指针 / 动态规划 / 中心扩展 最长回文子串、回文分割 🧠 四、陌生题目分析模板（万能五问法） 面试时不慌，按照这个模板分析即可。\n输入结构是什么？\n数组 / 字符串 / 链表 / 树 / 图？ 问题目标是什么？\n求最值？判断存在？计数？路径？ 能否排序或预处理？\n排序后双指针 / 哈希计数 / 前缀和等。 是否有重叠子问题或递推关系？\n动态规划可行？状态怎么定义？ 是否能用单调性、滑动窗口或贪心？\n例如“每日温度”“接雨水”“股票买卖”都可以用单调栈。 🧩 五、题型 → 典型解法速查表 题型 核心解法 模板函数 双指针 有序数组找配对、滑动窗口、快慢指针 for i, j := 0, 0; j \u0026lt; n; j++ {} 动态规划 子问题递推、打家劫舍、背包、编辑距离 dp[i] = max(dp[i-1], dp[i-2]+nums[i]) 单调栈 下一个更大元素、每日温度、接雨水 栈中保持单调递减或递增序列 BFS 最短路径、最少步数、层序遍历 queue := [][]int{{start}} DFS 全排列、连通块、递归遍历 func dfs(i int) { ... dfs(next) ... } 哈希表 快速判断存在性、去重 m := make(map[int]bool) 二分 有序区间查找 / 最小满足条件 for l \u0026lt; r { mid := (l+r)/2 } 💡 六、举例：拿到一道题你可以这样想 比如题目：\n“三数之和，找出所有和为 0 的三元组。”\n1️⃣ 输入是 数组 → 优先考虑排序 + 双指针。 2️⃣ 问题是 求配对/组合 → 双指针是常见套路。 3️⃣ 排序后去重，左指针 l 右指针 r，根据 sum 调整。 4️⃣ 属于 “排序 + 双指针” 模板题。\n",
"tags":null,
"categories":null
},{
"title":"面试题模板",
"permalink": "http://localhost:1313/posts/sql/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%A8%A1%E6%9D%BF/",
"summary": "SQL 面试题模板（综合） 模拟数据表 在大多数面试中，面试官会假设有几个经典的数据表。我们以此为基础：\nEmployees (员工表)\nemp_id (INT, Primary Key) - 员工 ID emp_name (VARCHAR) - 员工姓名 salary (DECIMAL) - 薪水 dept_id (INT, Foreign Key) - 部门 ID Departments (部门表)\ndept_id (INT, Primary Key) - 部门 ID dept_name (VARCHAR) - 部门名称 模块一：基础查询 (SELECT, WHERE, ORDER BY) 考察点：数据筛选、排序、限制的基本功。\n[筛选] 查找 Employees 表中薪水 (salary) 高于 80000 的所有员工信息。 [多条件] 查找 \u0026lsquo;Sales\u0026rsquo; (销售) 部门中，薪水低于 60000 的员工。 [模糊查询] 查找所有姓 \u0026lsquo;王\u0026rsquo; 的员工 (使用 LIKE '王%')。 [空值处理] 查找所有尚未分配部门（dept_id 为 NULL）的员工。 [排序与限制] 查找公司薪水最高的 5 名员工的信息 (使用 ORDER BY ... DESC 和 LIMIT ...)。 模块二：聚合与分组 (GROUP BY, HAVING) 考察点：数据汇总、分组统计的能力。\n",
"content": "SQL 面试题模板（综合） 模拟数据表 在大多数面试中，面试官会假设有几个经典的数据表。我们以此为基础：\nEmployees (员工表)\nemp_id (INT, Primary Key) - 员工 ID emp_name (VARCHAR) - 员工姓名 salary (DECIMAL) - 薪水 dept_id (INT, Foreign Key) - 部门 ID Departments (部门表)\ndept_id (INT, Primary Key) - 部门 ID dept_name (VARCHAR) - 部门名称 模块一：基础查询 (SELECT, WHERE, ORDER BY) 考察点：数据筛选、排序、限制的基本功。\n[筛选] 查找 Employees 表中薪水 (salary) 高于 80000 的所有员工信息。 [多条件] 查找 \u0026lsquo;Sales\u0026rsquo; (销售) 部门中，薪水低于 60000 的员工。 [模糊查询] 查找所有姓 \u0026lsquo;王\u0026rsquo; 的员工 (使用 LIKE '王%')。 [空值处理] 查找所有尚未分配部门（dept_id 为 NULL）的员工。 [排序与限制] 查找公司薪水最高的 5 名员工的信息 (使用 ORDER BY ... DESC 和 LIMIT ...)。 模块二：聚合与分组 (GROUP BY, HAVING) 考察点：数据汇总、分组统计的能力。\n[基础聚合] 计算 Employees 表中的总员工数、平均薪水和最高薪水。 [分组] 统计每个部门（dept_id）有多少名员工？ [HAVING 筛选] 找出平均薪水超过 70000 的部门。 [必考概念] WHERE 和 HAVING 的区别是什么？ WHERE 在 GROUP BY 之前执行，用于筛选原始行。 HAVING 在 GROUP BY 之后执行，用于筛选聚合后的分组。 [去重] COUNT(col) 和 COUNT(DISTINCT col) 有什么区别？ 模块三：连接查询 (JOIN) 考察点：处理多表关系的能力，这是 SQL 的核心。\n[INNER JOIN] 查找所有员工及其对应的部门名称。 [LEFT JOIN] 查找所有部门，以及这些部门下的员工。要求：即使某个部门没有员工，也要显示该部门名称。 [必考概念] INNER JOIN 和 LEFT JOIN 的区别是什么？ INNER JOIN (内连接) 只返回两个表中都能匹配上的行。 LEFT JOIN (左连接) 返回左表的所有行，以及右表中能匹配上的行（匹配不上的用 NULL 填充）。 [RIGHT/FULL JOIN] RIGHT JOIN 和 FULL OUTER JOIN 分别在什么场景下使用？（RIGHT JOIN 几乎等同于反向的 LEFT JOIN，FULL JOIN 返回两个表的所有行，无论是否匹配）。 [自连接 Self-Join] (假设 Employees 表中还有一列 manager_id 指向 emp_id) 如何查找每个员工及其直属经理的姓名？ 模块四：子查询 (Subquery) 考察点：复杂查询的构建能力，将一个查询的结果作为另一个查询的输入。\n[WHERE 子查询] 查找薪水高于公司平均薪水的员工。 [IN / NOT IN] 查找所有在 \u0026lsquo;Engineering\u0026rsquo; (工程) 部门工作的员工信息（假设你只知道部门名叫 \u0026lsquo;Engineering\u0026rsquo;，不知道 dept_id）。 [NOT EXISTS] 查找所有没有员工的部门。 [相关子查询] 查找每个部门中薪水最高的员工。 (解法 1: 相关子查询) SELECT * FROM Employees e1 WHERE e1.salary = (SELECT MAX(salary) FROM Employees e2 WHERE e2.dept_id = e1.dept_id) (解法 2: 窗口函数，见模块五) 模块五：窗口函数 (Window Functions) 考察点：现代 SQL 的高级分析能力，常用于排名和Top-N问题。（这是拉开差距的关键）\n[排名] 查找每个部门中薪水最高的 3 名员工。 [必考概念] ROW_NUMBER(), RANK(), DENSE_RANK() 的区别是什么？ ROW_NUMBER(): 1, 2, 3, 4 (不并列) RANK(): 1, 2, 2, 4 (并列跳号) DENSE_RANK(): 1, 2, 2, 3 (并列不跳号) SELECT * FROM ( SELECT emp_id, name, dept_id, salary, ROW_NUMBER() OVER (PARTITION BY dept_id ORDER BY salary DESC) AS rn FROM employees ) t WHERE rn \u0026lt;= 3; # RANK()（并列跳号） SELECT * FROM ( SELECT emp_id, name, dept_id, salary, RANK() OVER (PARTITION BY dept_id ORDER BY salary DESC) AS rk FROM employees ) t WHERE rk \u0026lt;= 3; # DENSE_RANK()（并列不跳号） SELECT * FROM ( SELECT emp_id, name, dept_id, salary, DENSE_RANK() OVER (PARTITION BY dept_id ORDER BY salary DESC) AS drk FROM employees ) t WHERE drk \u0026lt;= 3; [PARTITION BY] 如何在不使用 GROUP BY 的情况下，计算每个员工的薪水占其所在部门总薪水的百分比？ SELECT emp_id, name, dept_id, salary, ROUND(salary / SUM(salary) OVER (PARTITION BY dept_id) * 100, 2) AS salary_pct FROM employees; [LEAD / LAG] (假设有 Orders 订单表) 如何计算每笔订单与该客户上一笔订单之间的时间差？ SELECT user_id, order_id, order_time, LAG(order_time) OVER (PARTITION BY user_id ORDER BY order_time) AS prev_order_time, TIMESTAMPDIFF(HOUR, LAG(order_time) OVER (PARTITION BY user_id ORDER BY order_time), order_time) AS diff_hours FROM orders; 🧠 小结：现代 SQL 三大「高级分析」功能 功能 关键函数 常见考点 示例 排名 ROW_NUMBER, RANK, DENSE_RANK Top-N、去重排名 “每部门前3高薪” 分组分析 PARTITION BY + 聚合 百分比、占比 “薪水占部门总薪比” 序列分析 LAG, LEAD 时间差、涨跌趋势 “每次订单间隔” 模块六：数据操作与定义 (DML/DDL) 考察点：是否具备修改数据和表结构的能力。\n[INSERT] 如何向 Employees 表中添加一名新员工？ [UPDATE] 如何给 \u0026lsquo;Sales\u0026rsquo; 部门的所有员工加薪 10%？ [DELETE] 如何删除 dept_id 为 5 的所有员工？ [必考概念] DELETE, TRUNCATE, DROP 有什么区别？ DELETE: DML, 逐行删除, 可回滚, 触发触发器。 TRUNCATE: DDL, 删除所有行（通常是释放数据页）, 不可回滚（或回滚复杂）, 速度快。 DROP: DDL, 直接删除整个表结构和数据。 [ALTER] 如何向 Employees 表添加一个 hire_date (DATE 类型) 的新列？ 模块七：事务与性能 (Transaction \u0026amp; Optimization) 考察点：对数据库原理和性能调优的理解。\n[事务] 什么是数据库事务？ [ACID] 什么是 ACID？（原子性、一致性、隔离性、持久性） [索引] 什么是索引？为什么要使用索引？ [追问] 索引的优点和缺点是什么？（优点：查询快；缺点：写操作变慢、占用空间） [追问] 在 Employees 表的 salary 列上创建索引是否合适？（通常不合适，因为 \u0026ldquo;基数\u0026rdquo; (Cardinality) 可能不高，且范围查询多。在 emp_name 或 dept_id 上可能更合适）。 [追问] 什么是 \u0026ldquo;覆盖索引\u0026rdquo; (Covering Index)？ [EXPLAIN] 你如何分析一个慢查询？（使用 EXPLAIN 或 EXPLAIN ANALYZE 查看执行计划，检查是否使用了索引、是否进行了全表扫描等）。 ",
"tags":null,
"categories":null
},{
"title":"常见算法模板",
"permalink": "http://localhost:1313/posts/datastructalgorithm/%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/",
"summary": " 常见算法模板 第一部分：核心算法思想 1. 二分查找 (Binary Search) 适用于有序序列的查找。\n// 基础版本：查找特定值 func binarySearch(nums []int, target int) int { left, right := 0, len(nums)-1 for left \u0026lt;= right { mid := left + (right-left)/2 // 防溢出 if nums[mid] == target { return mid } else if nums[mid] \u0026lt; target { left = mid + 1 } else { right = mid - 1 } } return -1 // 未找到 } // 变体：查找左侧边界（第一个 \u0026gt;= target 的位置） func lowerBound(nums []int, target int) int { left, right := 0, len(nums) // 注意 right 的取值 for left \u0026lt; right { mid := left + (right-left)/2 if nums[mid] \u0026gt;= target { right = mid } else { left = mid + 1 } } return left } 2. 双指针 (Two Pointers) 快慢指针 常用于链表（判断环、找中点）或数组（原地修改）。\n",
"content": " 常见算法模板 第一部分：核心算法思想 1. 二分查找 (Binary Search) 适用于有序序列的查找。\n// 基础版本：查找特定值 func binarySearch(nums []int, target int) int { left, right := 0, len(nums)-1 for left \u0026lt;= right { mid := left + (right-left)/2 // 防溢出 if nums[mid] == target { return mid } else if nums[mid] \u0026lt; target { left = mid + 1 } else { right = mid - 1 } } return -1 // 未找到 } // 变体：查找左侧边界（第一个 \u0026gt;= target 的位置） func lowerBound(nums []int, target int) int { left, right := 0, len(nums) // 注意 right 的取值 for left \u0026lt; right { mid := left + (right-left)/2 if nums[mid] \u0026gt;= target { right = mid } else { left = mid + 1 } } return left } 2. 双指针 (Two Pointers) 快慢指针 常用于链表（判断环、找中点）或数组（原地修改）。\n// 链表环检测（已在下方链表部分提供） func hasCycle(head *ListNode) bool { slow, fast := head, head for fast != nil \u0026amp;\u0026amp; fast.Next != nil { slow = slow.Next fast = fast.Next.Next if slow == fast { return true } } return false } 双指针（左右指针） 常用于有序数组，从两端向中间逼近。\n// 示例：有序数组的两数之和 func twoSumSorted(nums []int, target int) []int { left, right := 0, len(nums)-1 for left \u0026lt; right { sum := nums[left] + nums[right] if sum == target { return []int{left, right} } else if sum \u0026lt; target { left++ } else { right-- } } return []int{-1, -1} // 未找到 } func twoSumSortedV2(nums []int, target int) []int { m := make return []int{-1, -1} // 未找到 } 3. 滑动窗口 (Sliding Window) 用于解决子数组/子字符串问题。维护一个 [left, right) 区间的窗口。\n// 示例：寻找最小覆盖子串（伪代码框架） func minWindow(s, t string) string { need := make(map[byte]int) window := make(map[byte]int) for i := range t { need[t[i]]++ } left, right := 0, 0 valid := 0 // 窗口中满足 need 条件的字符个数 // 结果起始索引和长度 start, minLen := 0, len(s)+1 for right \u0026lt; len(s) { // c 是将移入窗口的字符 c := s[right] right++ // ... 进行窗口内数据更新 ... if _, ok := need[c]; ok { window[c]++ if window[c] == need[c] { valid++ } } // 判断左侧窗口是否要收缩 for valid == len(need) { // 在这里更新最小覆盖子串 if right-left \u0026lt; minLen { start = left minLen = right - left } // d 是将移出窗口的字符 d := s[left] left++ // ... 进行窗口内数据更新 ... if _, ok := need[d]; ok { if window[d] == need[d] { valid-- } window[d]-- } } } if minLen == len(s)+1 { return \u0026#34;\u0026#34; } return s[start : start+minLen] } 4. 回溯算法 (Backtracking) / DFS 用于解决组合、排列、子集、N皇后等问题。本质是深度优先搜索（DFS）。\n// 示例：全排列 func permute(nums []int) [][]int { res := [][]int{} path := []int{} used := make(map[int]bool) // 记录路径上已使用的元素 var backtrack func() backtrack = func() { // 结束条件 if len(path) == len(nums) { temp := make([]int, len(path)) copy(temp, path) res = append(res, temp) return } for i := 0; i \u0026lt; len(nums); i++ { // 剪枝：已使用过的元素 if used[i] { continue } // 做选择 path = append(path, nums[i]) used[i] = true // 进入下一层决策 backtrack() // 撤销选择 path = path[:len(path)-1] used[i] = false } } backtrack() return res } 5. 广度优先搜索 (BFS) 常用于寻找最短路径、层序遍历等。核心是队列。\n// 示例：二叉树层序遍历（已在下方二叉树部分提供） // 示例：图的最短路径（伪代码） func bfsShortestPath(start, end *GraphNode) int { queue := []*GraphNode{start} visited := make(map[*GraphNode]bool) visited[start] = true level := 0 // 距离 for len(queue) \u0026gt; 0 { size := len(queue) for i := 0; i \u0026lt; size; i++ { node := queue[0] queue = queue[1:] if node == end { return level } for _, neighbor := range node.Neighbors { if !visited[neighbor] { visited[neighbor] = true queue = append(queue, neighbor) } } } level++ } return -1 // 不可达 } 6. 动态规划 (Dynamic Programming) 核心思想：定义状态、找出状态转移方程、确定 base case。\n// 示例：爬楼梯 // 状态定义：dp[i] 表示爬到第 i 阶楼梯的方法数 // 状态转移：dp[i] = dp[i-1] + dp[i-2] // Base Case: dp[0] = 1, dp[1] = 1 (或 dp[1]=1, dp[2]=2) func climbStairs(n int) int { if n \u0026lt;= 1 { return 1 } dp := make([]int, n+1) dp[0] = 1 dp[1] = 1 for i := 2; i \u0026lt;= n; i++ { dp[i] = dp[i-1] + dp[i-2] } return dp[n] } // 空间优化（滚动数组） func climbStairsOptimized(n int) int { if n \u0026lt;= 1 { return 1 } prev2, prev1 := 1, 1 // 对应 dp[i-2] 和 dp[i-1] for i := 2; i \u0026lt;= n; i++ { curr := prev1 + prev2 // dp[i] prev2 = prev1 prev1 = curr } return prev1 } 第二部分：数据结构相关模板 (这部分是您上次提供的内容，我将其整合到此处)\n7. 链表算法 (需要 ListNode 结构定义)\ntype ListNode struct { Val int Next *ListNode } 反转链表 func reverseList(head *ListNode) *ListNode { var prev *ListNode for head != nil { next := head.Next head.Next = prev prev = head head = next } return prev } 合并两个有序链表 func mergeTwoLists(l1, l2 *ListNode) *ListNode { dummy := \u0026amp;ListNode{} cur := dummy for l1 != nil \u0026amp;\u0026amp; l2 != nil { if l1.Val \u0026lt; l2.Val { cur.Next = l1 l1 = l1.Next } else { cur.Next = l2 l2 = l2.Next } cur = cur.Next } if l1 != nil { cur.Next = l1 } if l2 != nil { cur.Next = l2 } return dummy.Next } 链表中环的检测（快慢指针应用） func hasCycle(head *ListNode) bool { slow, fast := head, head for fast != nil \u0026amp;\u0026amp; fast.Next != nil { slow = slow.Next fast = fast.Next.Next if slow == fast { return true } } return false } 8. 二叉树遍历 (需要 TreeNode 结构定义)\ntype TreeNode struct { Val int Left *TreeNode Right *TreeNode } 前序遍历（递归） import \u0026#34;fmt\u0026#34; func preorder(root *TreeNode) { if root == nil { return } fmt.Println(root.Val) preorder(root.Left) preorder(root.Right) } 中序遍历（递归） import \u0026#34;fmt\u0026#34; func inorder(root *TreeNode) { if root == nil { return } inorder(root.Left) fmt.Println(root.Val) inorder(root.Right) } 后序遍历（递归） import \u0026#34;fmt\u0026#34; func postorder(root *TreeNode) { if root == nil { return } postorder(root.Left) postorder(root.Right) fmt.Println(root.Val) } 层序遍历（BFS 应用） func levelOrder(root *TreeNode) [][]int { if root == nil { return nil } queue := []*TreeNode{root} res := [][]int{} for len(queue) \u0026gt; 0 { level := []int{} levelSize := len(queue) // 固定当前层的节点数 for i := 0; i \u0026lt; levelSize; i++ { node := queue[0] queue = queue[1:] level = append(level, node.Val) if node.Left != nil { queue = append(queue, node.Left) } if node.Right != nil { queue = append(queue, node.Right) } } res = append(res, level) } return res } 9. 图遍历 (假定 Graph 是邻接表 map[int][]int 或 [][]int)\nDFS 遍历 import \u0026#34;fmt\u0026#34; func dfs(graph Graph, node int, visited map[int]bool) { if visited[node] { return } visited[node] = true fmt.Println(node) for _, nei := range graph[node] { dfs(graph, nei, visited) } } BFS 遍历 func bfs(graph Graph, start int) []int { visited := make(map[int]bool) queue := []int{start} res := []int{} for len(queue) \u0026gt; 0 { node := queue[0] queue = queue[1:] if visited[node] { continue } visited[node] = true res = append(res, node) for _, nei := range graph[node] { if !visited[nei] { queue = append(queue, nei) } } } return res } 10. 并查集 (Union-Find) type UnionFind struct { Parent []int Rank []int // 或 Size } func NewUnionFind(n int) *UnionFind { parent := make([]int, n) rank := make([]int, n) for i := 0; i \u0026lt; n; i++ { parent[i] = i rank[i] = 1 } return \u0026amp;UnionFind{Parent: parent, Rank: rank} } func (uf *UnionFind) Find(x int) int { if uf.Parent[x] != x { uf.Parent[x] = uf.Find(uf.Parent[x]) // 路径压缩 } return uf.Parent[x] } func (uf *UnionFind) Union(x, y int) bool { rootX := uf.Find(x) rootY := uf.Find(y) if rootX == rootY { return false // 已在同一集合 } // 按秩合并 if uf.Rank[rootX] \u0026lt; uf.Rank[rootY] { uf.Parent[rootX] = rootY } else if uf.Rank[rootX] \u0026gt; uf.Rank[rootY] { uf.Parent[rootY] = rootX } else { uf.Parent[rootY] = rootX uf.Rank[rootX]++ } return true } 11. 堆操作 (container/heap) import \u0026#34;container/heap\u0026#34; // 示例：小顶堆 type Item struct { Val int } type IntHeap []Item func (h IntHeap) Len() int { return len(h) } func (h IntHeap) Less(i, j int) bool { return h[i].Val \u0026lt; h[j].Val } // 小顶堆 func (h IntHeap) Swap(i, j int) { h[i], h[j] = h[j], h[i] } func (h *IntHeap) Push(x any) { *h = append(*h, x.(Item)) } func (h *IntHeap) Pop() any { old := *h n := len(old) x := old[n-1] *h = old[:n-1] return x } /* // 使用示例： h := \u0026amp;IntHeap{Item{Val: 2}, Item{Val: 1}, Item{Val: 5}} heap.Init(h) heap.Push(h, Item{Val: 3}) fmt.Printf(\u0026#34;min: %d\\n\u0026#34;, (*h)[0].Val) for h.Len() \u0026gt; 0 { fmt.Printf(\u0026#34;%d \\n\u0026#34;, heap.Pop(h).(Item).Val) } */ 12. Trie (前缀树) type TrieNode struct { Children map[rune]*TrieNode IsEnd bool } func NewTrieNode() *TrieNode { return \u0026amp;TrieNode{Children: make(map[rune]*TrieNode)} } type Trie struct { Root *TrieNode } func Constructor() Trie { return Trie{Root: NewTrieNode()} } func (t *Trie) Insert(word string) { node := t.Root for _, ch := range word { if node.Children[ch] == nil { node.Children[ch] = NewTrieNode() } node = node.Children[ch] } node.IsEnd = true } func (t *Trie) Search(word string) bool { node := t.Root for _, ch := range word { if node.Children[ch] == nil { return false } node = node.Children[ch] } return node.IsEnd } 13. LRU 缓存 使用 container/list 和 map 实现。\nimport \u0026#34;container/list\u0026#34; type LRUCache struct { capacity int cache map[int]*list.Element // 存储 key 到 list 节点的映射 list *list.List // 双向链表 } // 链表中存储的元素 type pair struct { key, value int } func ConstructorLRU(capacity int) LRUCache { return LRUCache{ capacity: capacity, cache: make(map[int]*list.Element), list: list.New(), } } func (c *LRUCache) Get(key int) int { if node, ok := c.cache[key]; ok { // 访问到了，移到队头 c.list.MoveToFront(node) return node.Value.(pair).value } return -1 } func (c *LRUCache) Put(key, value int) { if node, ok := c.cache[key]; ok { // 已存在，更新值并移到队头 c.list.MoveToFront(node) node.Value = pair{key, value} return } // 不存在，是新元素 if c.list.Len() == c.capacity { // 满了，淘汰队尾元素 back := c.list.Back() if back != nil { c.list.Remove(back) delete(c.cache, back.Value.(pair).key) } } // 插入新节点到队头 node := c.list.PushFront(pair{key, value}) c.cache[key] = node } 14. 栈与队列操作 （使用切片 []int 实现）\n// 栈 (Stack) type Stack struct { data []int } func (s *Stack) Push(x int) { s.data = append(s.data, x) } func (s *Stack) Pop() int { n := len(s.data) if n == 0 { return -1 } val := s.data[n-1] s.data = s.data[:n-1] return val } func (s *Stack) Top() int { if len(s.data) == 0 { return -1 } return s.data[len(s.data)-1] } // 队列 (Queue) type Queue struct { data []int } func (q *Queue) Enqueue(x int) { q.data = append(q.data, x) } func (q *Queue) Dequeue() int { if len(q.data) == 0 { return -1 } val := q.data[0] q.data = q.data[1:] return val } 其他的(高级总结) 一、数组 \u0026amp; 字符串\n双指针 滑动窗口 前缀和 \u0026amp; 差分 KMP / 字符匹配（可选） Trie 字典树 二、查找 \u0026amp; 排序\n快排 / 归并 二分查找 堆 / 优先队列（TopK） 三、栈 \u0026amp; 队列\n单调栈（下一个更大元素 / 盛水 / 每日温度） BFS/DFS（含多源 BFS \u0026amp; 分层 BFS） 拓扑排序 四、链表\n翻转 / 合并 / 环检测 / K 个一组反转 五、哈希 \u0026amp; 集合\n两数之和 LRU 跳表（可选） 六、树 \u0026amp; 图\n最近公共祖先 LCA（倍增法） 最大路径和 树的深度 / 直径 并查集解决连通性 图最短路径 Dijkstra（带权） BFS 最短路径（无权） 七、回溯 \u0026amp; 递归\n全排列 / 组合 / 子集 N 皇后 剪枝技巧 八、动态规划 DP\n斐波那契 / 台阶 背包（01/完全/多重） 最大子数组和 打家劫舍系列 单词拆分 状态压缩 DP（重要补充） 九、数学\n快速幂 最大公约数 / 最小公倍数 组合数 / 逆元（如果涉及笔试） ",
"tags":null,
"categories":null
},{
"title":"进程间通信",
"permalink": "http://localhost:1313/posts/cs/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/",
"summary": "",
"content": "",
"tags":null,
"categories":null
},{
"title":"常用数据结构",
"permalink": "http://localhost:1313/posts/datastructalgorithm/%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/",
"summary": "常用数据结构定义 1. 链表（Linked List） type ListNode struct { Val int Next *ListNode } 2. 双向链表（Doubly Linked List） type DListNode struct { Val int Prev *DListNode Next *DListNode } 3. 栈（Stack） type Stack struct { data []int } 4. 队列（Queue） type Queue struct { data []int } 5. 二叉树（Binary Tree） type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 6. N叉树（N-ary Tree） type NTreeNode struct { Val int Children []*NTreeNode } 7. 图（Graph） type GraphNode struct { Val int Neighbors []*GraphNode } 8. 哈希表（HashMap） m := make(map[string]int) 9. 堆（Heap / Priority Queue） type Item struct { Val int } type IntHeap []Item 10. 矩阵（Matrix） matrix := [][]int{ {1, 2, 3}, {4, 5, 6}, {7, 8, 9}, } 11. Trie（前缀树） type TrieNode struct { Children map[rune]*TrieNode IsEnd bool } type Trie struct { Root *TrieNode } 12. 并查集（Union-Find） type UnionFind struct { Parent []int Rank []int } 13. LRU 缓存（Least Recently Used Cache） type pair struct { key, value int } type LRUCache struct { capacity int cache map[int]*list.Element list *list.List } 进阶 图 🧠 一、图的基本概念 图由：\n",
"content": "常用数据结构定义 1. 链表（Linked List） type ListNode struct { Val int Next *ListNode } 2. 双向链表（Doubly Linked List） type DListNode struct { Val int Prev *DListNode Next *DListNode } 3. 栈（Stack） type Stack struct { data []int } 4. 队列（Queue） type Queue struct { data []int } 5. 二叉树（Binary Tree） type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 6. N叉树（N-ary Tree） type NTreeNode struct { Val int Children []*NTreeNode } 7. 图（Graph） type GraphNode struct { Val int Neighbors []*GraphNode } 8. 哈希表（HashMap） m := make(map[string]int) 9. 堆（Heap / Priority Queue） type Item struct { Val int } type IntHeap []Item 10. 矩阵（Matrix） matrix := [][]int{ {1, 2, 3}, {4, 5, 6}, {7, 8, 9}, } 11. Trie（前缀树） type TrieNode struct { Children map[rune]*TrieNode IsEnd bool } type Trie struct { Root *TrieNode } 12. 并查集（Union-Find） type UnionFind struct { Parent []int Rank []int } 13. LRU 缓存（Least Recently Used Cache） type pair struct { key, value int } type LRUCache struct { capacity int cache map[int]*list.Element list *list.List } 进阶 图 🧠 一、图的基本概念 图由：\n顶点（Vertex）：节点（如城市、用户、网页等） 边（Edge）：节点之间的连接关系（如航线、好友关系、链接） 根据边的方向，可以分为：\n类型 说明 举例 无向图 边没有方向 好友关系（A↔B） 有向图 边有方向 关注关系（A→B） 边还可以有：\n权重（Weight）：表示距离、费用、强度等（比如航班距离、传输时间） 🧩 二、图的存储方式（两种核心结构） 1️⃣ 邻接矩阵（Adjacency Matrix） 用一个二维数组 matrix[i][j] 表示是否存在边。\n例如：\n0 1 2 A B C 边：\nA → B B → C A → C 则邻接矩阵为：\nA B C A [0, 1, 1] B [0, 0, 1] C [0, 0, 0] 👉 适合稠密图（边多），判断连接快（O(1)），但占内存大（O(n²)）。\n2️⃣ 邻接表（Adjacency List） 每个节点维护一个“邻居列表”。\n例如同样的图：\nA: [B, C] B: [C] C: [] 👉 适合稀疏图（边少），存储效率高。\n🧰 三、Go 中的表示方式 ✅ 邻接表（推荐方式） type Graph struct { edges map[string][]string } func NewGraph() *Graph { return \u0026amp;Graph{edges: make(map[string][]string)} } func (g *Graph) AddEdge(from, to string) { g.edges[from] = append(g.edges[from], to) } 使用示例：\nfunc main() { g := NewGraph() g.AddEdge(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;) g.AddEdge(\u0026#34;A\u0026#34;, \u0026#34;C\u0026#34;) g.AddEdge(\u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;) fmt.Println(g.edges) // map[A:[B C] B:[C]] } ✅ 带权图（Weighted Graph） type Graph struct { edges map[string]map[string]int } func NewGraph() *Graph { return \u0026amp;Graph{edges: make(map[string]map[string]int)} } func (g *Graph) AddEdge(from, to string, weight int) { if g.edges[from] == nil { g.edges[from] = make(map[string]int) } g.edges[from][to] = weight } 使用示例：\nfunc main() { g := NewGraph() g.AddEdge(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, 5) g.AddEdge(\u0026#34;A\u0026#34;, \u0026#34;C\u0026#34;, 2) g.AddEdge(\u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, 1) fmt.Println(g.edges) // map[A:map[B:5 C:2] B:map[C:1]] } 🔍 四、图的遍历（基础模板） DFS 深度优先搜索（递归） func (g *Graph) DFS(start string, visited map[string]bool) { if visited[start] { return } visited[start] = true fmt.Println(\u0026#34;visit:\u0026#34;, start) for _, neighbor := range g.edges[start] { g.DFS(neighbor, visited) } } BFS 广度优先搜索（队列） func (g *Graph) BFS(start string) { visited := make(map[string]bool) queue := []string{start} visited[start] = true for len(queue) \u0026gt; 0 { node := queue[0] queue = queue[1:] fmt.Println(\u0026#34;visit:\u0026#34;, node) for _, neighbor := range g.edges[node] { if !visited[neighbor] { visited[neighbor] = true queue = append(queue, neighbor) } } } } 🌍 五、常见应用类型 问题 使用算法 说明 判断是否连通 DFS / BFS 岛屿数量、朋友圈 最短路径 BFS / Dijkstra 最短路径问题 检测环 DFS / 拓扑排序 任务依赖检测 拓扑排序 Kahn算法 / DFS 编译依赖、任务执行顺序 最小生成树 Kruskal / Prim 网络布线、最小代价连接 强连通分量 Tarjan算法 社交圈、子系统分组 💡 小结 存储方式 优点 缺点 适用场景 邻接矩阵 判断连接快 占空间大 稠密图 邻接表 节省空间 判断慢 稀疏图（常见） ",
"tags":null,
"categories":null
},{
"title":"打卡计划表",
"permalink": "http://localhost:1313/posts/datastructalgorithm/%E6%89%93%E5%8D%A1%E8%AE%A1%E5%88%92%E8%A1%A8/",
"summary": "开启打卡计划 日期 题目 模板 二刷结果 迁移练习 备注 10/16 15. 三数之和 双指针 ✅ 三数差值最接近 完整复盘，写模板笔记 10/17 11. 盛最多水的容器 双指针 ✅ 股票最大利润 计时 25 分钟 10/18 3. 无重复字符的最长子串 滑动窗口 ✅ 最长允许1重复字符 模拟面试说思路 10/19 1. 两数之和 哈希 ✅ 三数之和、路径求和 强化迁移能力 10/20 20. 有效括号 栈 ✅ HTML标签验证 二刷完成 10/21 739. 每日温度 单调栈 ✅ 下一个更小元素 二刷 + 迁移 10/22 206. 反转链表 链表 ✅ k组反转、回文链表 模板笔记 10/23 141. 环形链表 链表 ✅ 相交链表检测 二刷完成 10/24 53. 最大子序和 动态规划 ✅ 股票最大利润 计时练习 10/25 198. 打家劫舍 动态规划 ✅ 环形打家劫舍 二刷完成 10/26 139. 单词拆分 动态规划 ✅ 所有拆分方式 写迁移笔记 10/27 33. 搜索旋转排序数组 二分 搜索峰值 计时练习 10/28 200. 岛屿数量 DFS/BFS 封闭区域计数 二刷 + 迁移 10/29 104. 二叉树最大深度 树 判断平衡二叉树 模板笔记 10/30 236. 最近公共祖先 树 N叉树版本 二刷完成 ",
"content": "开启打卡计划 日期 题目 模板 二刷结果 迁移练习 备注 10/16 15. 三数之和 双指针 ✅ 三数差值最接近 完整复盘，写模板笔记 10/17 11. 盛最多水的容器 双指针 ✅ 股票最大利润 计时 25 分钟 10/18 3. 无重复字符的最长子串 滑动窗口 ✅ 最长允许1重复字符 模拟面试说思路 10/19 1. 两数之和 哈希 ✅ 三数之和、路径求和 强化迁移能力 10/20 20. 有效括号 栈 ✅ HTML标签验证 二刷完成 10/21 739. 每日温度 单调栈 ✅ 下一个更小元素 二刷 + 迁移 10/22 206. 反转链表 链表 ✅ k组反转、回文链表 模板笔记 10/23 141. 环形链表 链表 ✅ 相交链表检测 二刷完成 10/24 53. 最大子序和 动态规划 ✅ 股票最大利润 计时练习 10/25 198. 打家劫舍 动态规划 ✅ 环形打家劫舍 二刷完成 10/26 139. 单词拆分 动态规划 ✅ 所有拆分方式 写迁移笔记 10/27 33. 搜索旋转排序数组 二分 搜索峰值 计时练习 10/28 200. 岛屿数量 DFS/BFS 封闭区域计数 二刷 + 迁移 10/29 104. 二叉树最大深度 树 判断平衡二叉树 模板笔记 10/30 236. 最近公共祖先 树 N叉树版本 二刷完成 ",
"tags":null,
"categories":null
},{
"title":"刷题方法",
"permalink": "http://localhost:1313/posts/datastructalgorithm/%E5%88%B7%E9%A2%98%E6%96%B9%E6%B3%95/",
"summary": "个人感悟和前言 刷了很多题（其实也不是很多，但却是每天坚持半小时坚持了一年多了）， 但是老是面试的时候做不出来，或者要花很长时间才能做出来。我都产生自我怀疑了，我觉得是时候换个方式了。 我问了gpt,它给了我很多建议，接下来我会按照下面的方式重新规划我的学习方法\n以下大多数参考了gpt\n具体的做法 核心目标 一、核心目标 用最少的题，建立最大迁移力。 熟练识别模板，能举一反三。 面试时 3 分钟内能讲清思路。 重点在模式识别 + 模板迁移，不追数量。 二、15 道最值得复盘的模板题 类别 LeetCode题目 核心模板 可迁移方向 双指针 15. 三数之和 排序 + 去重 + 左右夹逼 k数之和 / 差值最接近 / 删除一个字符变回文 双指针 11. 盛最多水的容器 左右夹逼取最大面积 股票买卖、最优区间类问题 滑动窗口 3. 无重复字符的最长子串 扩展窗口 + 收缩窗口 最小覆盖子串、最长K个不同字符子串 哈希 1. 两数之和 哈希反查 三数之和、四数之和、路径求和 栈 20. 有效的括号 栈匹配 HTML标签验证、栈逆序 单调栈 739. 每日温度 单调递减栈 下一个更大元素、柱状图最大矩形 链表 206. 反转链表 指针前后反转 k组反转、回文链表检测 链表 141. 环形链表 快慢指针 相交链表检测、寻找环入口 动态规划 53. 最大子序和 dp[i] = max(nums[i], dp[i-1]+nums[i]) 股票最大利润、子数组和问题 动态规划 198. 打家劫舍 dp[i] = max(dp[i-1], dp[i-2]+nums[i]) 环形打家劫舍、爬楼梯变体 动态规划 139. 单词拆分 dp[i] = dp[j] \u0026amp;\u0026amp; wordDict[j:i] 句子拼接、分割字符串最少次数 二分查找 33. 搜索旋转排序数组 二分判定区间有序性 搜索峰值、最小差距值 DFS/BFS 200. 岛屿数量 遍历连通块 图遍历、封闭区域数量、朋友圈问题 树 104. 二叉树最大深度 递归 DFS 平衡二叉树、路径和 树 236. 最近公共祖先 后序递归 目录树路径、最小公共节点类问题 三、偏题迁移示例 原题模板 面试偏题举例 迁移思路 无重复字符的最长子串 最多允许一个重复字符的最长子串 滑动窗口 + 计数增加一层判断 三数之和 找出所有和为目标值的三元组 排序 + 去重 + 双指针，只改目标值逻辑 有效括号 字符串里只有 \u0026lt; \u0026gt;，规则不同 替换匹配规则即可，核心仍是栈 每日温度 求每个元素右边第一个比它小的元素 单调递增栈，方向反转 打家劫舍 环形排列的房屋 拆成两种情况：不偷第一 vs 不偷最后 单词拆分 计算所有可行的拆分方式 dp[i] 的基础上计数或回溯 二叉树最大深度 判断是否平衡二叉树 在返回深度的同时判断差值 最近公共祖先 N 叉树版本 递归逻辑相同，遍历子节点代替左右子树 四、陌生题分析框架（面试必备） 求最值 → 贪心 / 动态规划 求存在 → 哈希 / 二分 求路径 / 连通 → DFS / BFS 求配对 / 区间 → 双指针 / 滑动窗口 暴力解 \u0026amp; 复杂度 先写最直接暴力解，作为 fallback 考虑优化方向（排序 / 哈希 / 双指针） 是否有重复子问题 有 → 动态规划 没有 → 贪心或暴力优化 输入结构 数组 → 排序 / 双指针 矩阵 → DFS / BFS 树 / 图 → 递归 / 队列 写伪代码 先讲思路，代码只是形式 面试官更关注分析能力 五、复盘计划（3 周周期） 周数 目标 内容 第1周 模板巩固 前8题（数组、链表、哈希、栈）二刷，写模板笔记 第2周 动态规划 \u0026amp; 树 后7题二刷，形成 dp / 树模板总结 第3周 偏题迁移训练 每天抽一道陌生题，用陌生题分析框架解题，重点练思路，不追完美 六、Go 开发者模板代码示例 // 双指针模板 func twoSum(nums []int, target int) []int { m := make(map[int]int) for i, v := range nums { if j, ok := m[target-v]; ok { return []int{j, i} } m[v] = i } return nil } // 滑动窗口模板 func lengthOfLongestSubstring(s string) int { window := make(map[byte]int) left, right, res := 0, 0, 0 for right \u0026lt; len(s) { c := s[right] right++ window[c]++ for window[c] \u0026gt; 1 { d := s[left] left++ window[d]-- } if res \u0026lt; right-left { res = right - left } } return res } // map 初始化 m := make(map[int]int) // set 用法 set := map[int]bool{} set[x] = true if set[y] { ... } // priority queue 模板 type Item struct{ value, priority int } type PQ []Item func (pq PQ) Len() int { return len(pq) } func (pq PQ) Less(i, j int) bool { return pq[i].priority \u0026lt; pq[j].priority } func (pq PQ) Swap(i, j int) { pq[i], pq[j] = pq[j], pq[i] } func (pq *PQ) Push(x any) { *pq = append(*pq, x.(Item)) } func (pq *PQ) Pop() any { old := *pq n := len(old) x := old[n-1] *pq = old[:n-1] return x } 七、最终目标 不靠“记题”，靠“识别结构 + 套模板 + 临场分析”。 偏题也能快速迁移思路，不慌张。 面试时有底气，3 分钟就能讲清解题思路。 ",
"content": "个人感悟和前言 刷了很多题（其实也不是很多，但却是每天坚持半小时坚持了一年多了）， 但是老是面试的时候做不出来，或者要花很长时间才能做出来。我都产生自我怀疑了，我觉得是时候换个方式了。 我问了gpt,它给了我很多建议，接下来我会按照下面的方式重新规划我的学习方法\n以下大多数参考了gpt\n具体的做法 核心目标 一、核心目标 用最少的题，建立最大迁移力。 熟练识别模板，能举一反三。 面试时 3 分钟内能讲清思路。 重点在模式识别 + 模板迁移，不追数量。 二、15 道最值得复盘的模板题 类别 LeetCode题目 核心模板 可迁移方向 双指针 15. 三数之和 排序 + 去重 + 左右夹逼 k数之和 / 差值最接近 / 删除一个字符变回文 双指针 11. 盛最多水的容器 左右夹逼取最大面积 股票买卖、最优区间类问题 滑动窗口 3. 无重复字符的最长子串 扩展窗口 + 收缩窗口 最小覆盖子串、最长K个不同字符子串 哈希 1. 两数之和 哈希反查 三数之和、四数之和、路径求和 栈 20. 有效的括号 栈匹配 HTML标签验证、栈逆序 单调栈 739. 每日温度 单调递减栈 下一个更大元素、柱状图最大矩形 链表 206. 反转链表 指针前后反转 k组反转、回文链表检测 链表 141. 环形链表 快慢指针 相交链表检测、寻找环入口 动态规划 53. 最大子序和 dp[i] = max(nums[i], dp[i-1]+nums[i]) 股票最大利润、子数组和问题 动态规划 198. 打家劫舍 dp[i] = max(dp[i-1], dp[i-2]+nums[i]) 环形打家劫舍、爬楼梯变体 动态规划 139. 单词拆分 dp[i] = dp[j] \u0026amp;\u0026amp; wordDict[j:i] 句子拼接、分割字符串最少次数 二分查找 33. 搜索旋转排序数组 二分判定区间有序性 搜索峰值、最小差距值 DFS/BFS 200. 岛屿数量 遍历连通块 图遍历、封闭区域数量、朋友圈问题 树 104. 二叉树最大深度 递归 DFS 平衡二叉树、路径和 树 236. 最近公共祖先 后序递归 目录树路径、最小公共节点类问题 三、偏题迁移示例 原题模板 面试偏题举例 迁移思路 无重复字符的最长子串 最多允许一个重复字符的最长子串 滑动窗口 + 计数增加一层判断 三数之和 找出所有和为目标值的三元组 排序 + 去重 + 双指针，只改目标值逻辑 有效括号 字符串里只有 \u0026lt; \u0026gt;，规则不同 替换匹配规则即可，核心仍是栈 每日温度 求每个元素右边第一个比它小的元素 单调递增栈，方向反转 打家劫舍 环形排列的房屋 拆成两种情况：不偷第一 vs 不偷最后 单词拆分 计算所有可行的拆分方式 dp[i] 的基础上计数或回溯 二叉树最大深度 判断是否平衡二叉树 在返回深度的同时判断差值 最近公共祖先 N 叉树版本 递归逻辑相同，遍历子节点代替左右子树 四、陌生题分析框架（面试必备） 求最值 → 贪心 / 动态规划 求存在 → 哈希 / 二分 求路径 / 连通 → DFS / BFS 求配对 / 区间 → 双指针 / 滑动窗口 暴力解 \u0026amp; 复杂度 先写最直接暴力解，作为 fallback 考虑优化方向（排序 / 哈希 / 双指针） 是否有重复子问题 有 → 动态规划 没有 → 贪心或暴力优化 输入结构 数组 → 排序 / 双指针 矩阵 → DFS / BFS 树 / 图 → 递归 / 队列 写伪代码 先讲思路，代码只是形式 面试官更关注分析能力 五、复盘计划（3 周周期） 周数 目标 内容 第1周 模板巩固 前8题（数组、链表、哈希、栈）二刷，写模板笔记 第2周 动态规划 \u0026amp; 树 后7题二刷，形成 dp / 树模板总结 第3周 偏题迁移训练 每天抽一道陌生题，用陌生题分析框架解题，重点练思路，不追完美 六、Go 开发者模板代码示例 // 双指针模板 func twoSum(nums []int, target int) []int { m := make(map[int]int) for i, v := range nums { if j, ok := m[target-v]; ok { return []int{j, i} } m[v] = i } return nil } // 滑动窗口模板 func lengthOfLongestSubstring(s string) int { window := make(map[byte]int) left, right, res := 0, 0, 0 for right \u0026lt; len(s) { c := s[right] right++ window[c]++ for window[c] \u0026gt; 1 { d := s[left] left++ window[d]-- } if res \u0026lt; right-left { res = right - left } } return res } // map 初始化 m := make(map[int]int) // set 用法 set := map[int]bool{} set[x] = true if set[y] { ... } // priority queue 模板 type Item struct{ value, priority int } type PQ []Item func (pq PQ) Len() int { return len(pq) } func (pq PQ) Less(i, j int) bool { return pq[i].priority \u0026lt; pq[j].priority } func (pq PQ) Swap(i, j int) { pq[i], pq[j] = pq[j], pq[i] } func (pq *PQ) Push(x any) { *pq = append(*pq, x.(Item)) } func (pq *PQ) Pop() any { old := *pq n := len(old) x := old[n-1] *pq = old[:n-1] return x } 七、最终目标 不靠“记题”，靠“识别结构 + 套模板 + 临场分析”。 偏题也能快速迁移思路，不慌张。 面试时有底气，3 分钟就能讲清解题思路。 ",
"tags":null,
"categories":null
},{
"title":"如何判断网络状况",
"permalink": "http://localhost:1313/posts/scenario/%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E7%BD%91%E7%BB%9C%E7%8A%B6%E5%86%B5/",
"summary": "",
"content": "",
"tags":null,
"categories":null
},{
"title":"Sql调优",
"permalink": "http://localhost:1313/posts/scenario/sql%E8%B0%83%E4%BC%98/",
"summary": "mySql调优 参考资料 https://www.yuque.com/everglow-8bs2d/ka5fze/inbyrpn5weudx226?singleDoc# ",
"content": "mySql调优 参考资料 https://www.yuque.com/everglow-8bs2d/ka5fze/inbyrpn5weudx226?singleDoc# ",
"tags":null,
"categories":null
},{
"title":"Link_合并升序链表",
"permalink": "http://localhost:1313/posts/datastructalgorithm/link_%E5%90%88%E5%B9%B6%E5%8D%87%E5%BA%8F%E9%93%BE%E8%A1%A8/",
"summary": "package main import \u0026#34;fmt\u0026#34; func main() { //两个升序链表合并一个新的升序链表 link1 := NewLink() link1.head.next = \u0026amp;node{ value: 1, next: \u0026amp;node{next: \u0026amp;node{ value: 4, }, value: 3}, } link2 := NewLink() link2.head.next = \u0026amp;node{ value: 2, next: \u0026amp;node{next: \u0026amp;node{ value: 6, }, value: 5}, } newLink := mergerSortLink(link1, link2) fmt.Println(newLink) head := newLink.head.next for head != nil { fmt.Println(head.value) head = head.next } } func mergerSortLink(link1, link2 *Link) *Link { // 插入 newNode := \u0026amp;node{} newLink := \u0026amp;Link{ head: newNode, } head1 := link1.head.next head2 := link2.head.next for head1 != nil \u0026amp;\u0026amp; head2 != nil { if head1.value \u0026lt; head2.value { newNode.next = head1 newNode = head1 head1 = head1.next } else { newNode.next = head2 newNode = head2 head2 = head2.next } } // if head1 != nil { newNode.next = head1 } if head2 != nil { newNode.next = head2 } return newLink } type Link struct { head *node } type node struct { value int next *node } func NewLink() *Link { return \u0026amp;Link{ head: \u0026amp;node{}, } } ``` ",
"content": "package main import \u0026#34;fmt\u0026#34; func main() { //两个升序链表合并一个新的升序链表 link1 := NewLink() link1.head.next = \u0026amp;node{ value: 1, next: \u0026amp;node{next: \u0026amp;node{ value: 4, }, value: 3}, } link2 := NewLink() link2.head.next = \u0026amp;node{ value: 2, next: \u0026amp;node{next: \u0026amp;node{ value: 6, }, value: 5}, } newLink := mergerSortLink(link1, link2) fmt.Println(newLink) head := newLink.head.next for head != nil { fmt.Println(head.value) head = head.next } } func mergerSortLink(link1, link2 *Link) *Link { // 插入 newNode := \u0026amp;node{} newLink := \u0026amp;Link{ head: newNode, } head1 := link1.head.next head2 := link2.head.next for head1 != nil \u0026amp;\u0026amp; head2 != nil { if head1.value \u0026lt; head2.value { newNode.next = head1 newNode = head1 head1 = head1.next } else { newNode.next = head2 newNode = head2 head2 = head2.next } } // if head1 != nil { newNode.next = head1 } if head2 != nil { newNode.next = head2 } return newLink } type Link struct { head *node } type node struct { value int next *node } func NewLink() *Link { return \u0026amp;Link{ head: \u0026amp;node{}, } } ``` ",
"tags":null,
"categories":null
},{
"title":"Str_滑动窗口",
"permalink": "http://localhost:1313/posts/datastructalgorithm/str_%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/",
"summary": "给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { //给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。 //输入: s = \u0026#34;abcabcbb\u0026#34; //输出: 3 //解释: 因为无重复字符的最长子串是 \u0026#34;abc\u0026#34;，所以其长度为 3。 s := \u0026#34;abcabcbb\u0026#34; //s := \u0026#34;abcbcbb\u0026#34; res := getSubStr(s) fmt.Println(res) } func getSubStr(s string) int { res, left := 0, 0 check := make(map[byte]int) n := len(s) for right := 0; right \u0026lt; n; right++ { if index, ok := check[s[right]]; ok \u0026amp;\u0026amp; index \u0026gt;= left { left = index + 1 } check[s[right]] = right res = Max(res, right-left+1) } return res } func Max(a, b int) int { if a \u0026gt; b { return a } return b } ``` ",
"content": "给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { //给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。 //输入: s = \u0026#34;abcabcbb\u0026#34; //输出: 3 //解释: 因为无重复字符的最长子串是 \u0026#34;abc\u0026#34;，所以其长度为 3。 s := \u0026#34;abcabcbb\u0026#34; //s := \u0026#34;abcbcbb\u0026#34; res := getSubStr(s) fmt.Println(res) } func getSubStr(s string) int { res, left := 0, 0 check := make(map[byte]int) n := len(s) for right := 0; right \u0026lt; n; right++ { if index, ok := check[s[right]]; ok \u0026amp;\u0026amp; index \u0026gt;= left { left = index + 1 } check[s[right]] = right res = Max(res, right-left+1) } return res } func Max(a, b int) int { if a \u0026gt; b { return a } return b } ``` ",
"tags":null,
"categories":null
},{
"title":"GMP",
"permalink": "http://localhost:1313/posts/go/gmp/",
"summary": "什么是GMP 概念 GMP是go的协程调度模型，go代码的程序有运行时runtime进行调度，go可以通过运行时进行内存的分配，通过channel进行协程间通信，通过go关键字创建协程。 而GMP正是协程调度的核心。\nG代表go的goroutine,协程是用户态的轻量级线程，创建销毁的成本非常小，只需要大约2kb，而线程则需要2m,所以go的协程非常适合处理IO密集型任务。 M代表系统级线程，go的协程并不真正执行代码，它需要将协程调度到和内核绑定的系统级线程上进行实际的运行。 P代表逻辑处理单元，包含了待运行的协程和一些上下文。p又可以分为本地队列和全局队列。 调度过程 go的程序通过runtime创建协程\n将协程放到本地队列p p和m绑定 m在操作系统上执行 核心调度时机 用户态态阻塞，比如channel、mutex，这个时候p会和m脱离，p会放入到待运行队列，或者重新绑定其他m 内核态阻塞，比如发生了系统调用，io操作等，m会被标记成阻塞状态，go会重新创建后者唤醒一个m，保证并发度 其他核心概念 ruetime.GOMAXPROCS() 优化手段 进阶（gpt版本） GMP 调度的完整流程、设计思想，以及它如何解决了关键问题（如阻塞、抢占）。\n一、 什么是 GMP 模型？（高层概括） 面试官问“说下GMP”，你可以先给一个高层定义，点出它的核心设计思想：解耦和复用。\n回答范例：\nGMP 是 Go 语言运行时的核心调度模型，它是一个用户态的、M:N 的并发调度器。\nM:N 指的是它将 M 个 Goroutine（G）调度到 N 个操作系统线程（M）上执行。 它的核心设计思想是解耦： G（Goroutine）： 代表一个并发任务。它非常轻量（初始栈 2KB），由 Go Runtime 管理，切换成本远低于线程。 M（Machine）： 代表一个操作系统线程。它是真正执行计算的“工人”。 P（Processor）： 代表一个逻辑处理器，或者说是“CPU 核心”。P 是 G 和 M 之间的“上下文”或“调度器”。M 必须持有 P 才能执行 G。 GMP 模型的精妙之处在于 P，它作为中间层，实现了 Goroutine 和 OS 线程的解耦。这带来了两大好处：\n高效复用（M:N）： M（线程）的数量可以远小于 G（任务）的数量。Go 默认让 P 的数量（GOMAXPROCS）等于 CPU 核心数，使得 M:N 调度能充分利用多核，同时避免了大量线程切换的开销。 智能调度： 通过 P 的本地队列和 P 之间的工作窃取 (Work Stealing) 机制，实现了高效的负载均衡。 二、 GMP 调度的核心流程（面试重点） 这部分是面试的“深水区”，你需要清晰地描述 G、M、P 是如何协同工作的。\n",
"content": "什么是GMP 概念 GMP是go的协程调度模型，go代码的程序有运行时runtime进行调度，go可以通过运行时进行内存的分配，通过channel进行协程间通信，通过go关键字创建协程。 而GMP正是协程调度的核心。\nG代表go的goroutine,协程是用户态的轻量级线程，创建销毁的成本非常小，只需要大约2kb，而线程则需要2m,所以go的协程非常适合处理IO密集型任务。 M代表系统级线程，go的协程并不真正执行代码，它需要将协程调度到和内核绑定的系统级线程上进行实际的运行。 P代表逻辑处理单元，包含了待运行的协程和一些上下文。p又可以分为本地队列和全局队列。 调度过程 go的程序通过runtime创建协程\n将协程放到本地队列p p和m绑定 m在操作系统上执行 核心调度时机 用户态态阻塞，比如channel、mutex，这个时候p会和m脱离，p会放入到待运行队列，或者重新绑定其他m 内核态阻塞，比如发生了系统调用，io操作等，m会被标记成阻塞状态，go会重新创建后者唤醒一个m，保证并发度 其他核心概念 ruetime.GOMAXPROCS() 优化手段 进阶（gpt版本） GMP 调度的完整流程、设计思想，以及它如何解决了关键问题（如阻塞、抢占）。\n一、 什么是 GMP 模型？（高层概括） 面试官问“说下GMP”，你可以先给一个高层定义，点出它的核心设计思想：解耦和复用。\n回答范例：\nGMP 是 Go 语言运行时的核心调度模型，它是一个用户态的、M:N 的并发调度器。\nM:N 指的是它将 M 个 Goroutine（G）调度到 N 个操作系统线程（M）上执行。 它的核心设计思想是解耦： G（Goroutine）： 代表一个并发任务。它非常轻量（初始栈 2KB），由 Go Runtime 管理，切换成本远低于线程。 M（Machine）： 代表一个操作系统线程。它是真正执行计算的“工人”。 P（Processor）： 代表一个逻辑处理器，或者说是“CPU 核心”。P 是 G 和 M 之间的“上下文”或“调度器”。M 必须持有 P 才能执行 G。 GMP 模型的精妙之处在于 P，它作为中间层，实现了 Goroutine 和 OS 线程的解耦。这带来了两大好处：\n高效复用（M:N）： M（线程）的数量可以远小于 G（任务）的数量。Go 默认让 P 的数量（GOMAXPROCS）等于 CPU 核心数，使得 M:N 调度能充分利用多核，同时避免了大量线程切换的开销。 智能调度： 通过 P 的本地队列和 P 之间的工作窃取 (Work Stealing) 机制，实现了高效的负载均衡。 二、 GMP 调度的核心流程（面试重点） 这部分是面试的“深水区”，你需要清晰地描述 G、M、P 是如何协同工作的。\n1. 正常执行与创建 (Happy Path) 启动： Go Runtime 会创建 GOMAXPROCS 个 P。 绑定： 一个 M 必须获取一个 P 才能开始执行。 找任务： M 会从它绑定的 P 的本地可运行队列（LRQ, Local Run Queue） 中弹出一个 G。 执行： M 执行这个 G。 go func()： 当一个 G 执行 go func() 创建新 G 时，这个新 G 优先被放入当前 P 的 LRQ。如果 LRQ 满了，才会溢出到全局队列（GRQ, Global Run Queue）。 2. 工作窃取 (Work Stealing)（解决P饥饿） 面试官追问： “如果一个 P 的本地队列空了，它绑定的 M 会做什么？”\n回答： 这会触发工作窃取（Work Stealing）：\n当前 M（持有 P1）发现 P1 的 LRQ 为空。 M 不会休眠，它会代表 P1 去随机地“偷”另一个 P（比如 P2）的 LRQ。 它会尝试从 P2 的 LRQ 队尾（注意：是队尾，保证公平性）偷走一半的 G 放到 P1 的 LRQ 中。 如果偷不到（所有 P 都空了），它会尝试从 GRQ 获取任务。 如果 GRQ 也为空，M 最终会放弃 P，M 自身进入休眠（自旋等待或挂起），P 被标记为空闲。 设计思想： 工作窃取是 GMP 实现高吞吐和负载均衡的关键。它让 M 始终保持“忙碌”，避免了 CPU 资源的浪费。\n3. 阻塞处理 (Syscall)（GMP最精妙的设计之一） 面试官高频追问： “如果一个 G 发生了阻塞的系统调用（比如 CGO 或文件 IO），会发生什么？会阻塞 M 吗？”\n回答： 这是 GMP 模型的关键优势。Go 将系统调用分为阻塞型和非阻塞型（如网络 IO，由 netpoller 内部处理，G 会被挂起，M 不阻塞）。\n对于阻塞型系统调用 (Blocking Syscall)：\nG（G1）在 M1 上执行，即将发生阻塞。 Go Runtime 会检测到这个阻塞。 关键操作：M1 会与 P 解绑 (M-P detachment)。 M1 会带着 G1 一起进入阻塞状态（等待 syscall 返回）。 Runtime 会立即唤醒或创建一个新的 M（M2） 来接管这个 P。 M2 绑定 P，然后继续从 P 的 LRQ 中取出下一个 G（G2）来执行。 结果： 只有 M1 和 G1 被阻塞了，而 P（代表的 CPU 核心）没有被阻塞，它立刻被 M2 复用去执行其他 G。\n追问： “当 G1 的 syscall 返回后呢？”\nG1 变为可运行状态。 M1 会尝试**“手持”**（Hand Off）G1： 如果能立即找到一个空闲的 P，M1 就绑定 P 并继续执行 G1。 如果找不到空闲的 P，M1 会将 G1 放入 GRQ，然后 M1 自身进入休眠。 设计思想： 这种 M-P 解绑机制，保证了 GOMAXPROCS 个 P（即 CPU 核心）始终在满负荷工作，不会因为个别 G 的阻塞而导致整个 M 链条（P）的闲置。\n4. 抢占调度（解决G饥饿） 面试官追问： “如果一个 G 恶意执行 for {} 死循环，它会占满 P 吗？其他 G 怎么办？”\n回答： Go 调度器是抢占式的。如果一个 G 运行时间过长（目前是 10ms），调度器会强制它让出 CPU。Go 1.14 以后实现了基于信号的异步抢占，解决了早期协作式抢占的痛点。\n协作式抢占（旧，但仍在用）： Go 编译器会在函数调用的入口处插入“栈检查”指令。这个检查不仅看栈是否溢出，也检查全局的“抢占标记”。如果发现自己需要被抢占，G 会主动让出（切换到 G0 调度栈）。\n缺点： 如果 G 执行一个没有函数调用的纯计算 for {}，协作式抢占会失效。 异步抢占（Go 1.14+，基于信号）：\nGo Runtime 有一个系统监控线程（sysmon）。 sysmon 会监控所有 P 上的 G 是否运行时间过长（\u0026gt;10ms）。 如果发现 G1 运行超时，sysmon 会向运行 G1 的 M 发送一个 SIGURG 信号。 M 接收到信号后，会中断 G1 的执行，将 G1 的状态改为 runnable 并将其插入 GRQ（使其排到队尾，防止其立即再次执行）。 M 随后从 P 的 LRQ 中寻找下一个 G 来执行。 设计思想： 异步抢占保证了调度器的公平性，防止了恶意或有 Bug 的 G 饿死其他 G。\n5. 挂起与恢复 “被挂起的 G 不运行了，那它放到哪里去了？”\n正好是 Go 调度器（GMP 模型）里最关键的“阻塞与等待队列机制”之一。 我们来完整拆解。\n🧩 一、前提：G（goroutine）的生命周期阶段 在 Go 的运行时系统中，每个 goroutine（G）有一个状态（gstatus）， 其中几个关键状态如下 👇\n状态名 含义 _Grunnable 就绪态，可被调度执行 _Grunning 正在执行 _Gwaiting 等待中（被挂起） _Gsyscall 处于系统调用中（M 阻塞） _Gdead 已退出或未初始化 🧠 二、当 G 被挂起时，会发生什么？ 当一个 goroutine 因为 channel、mutex、select、cond 等原因阻塞 时：\n1️⃣ runtime 检测到它不能继续执行 2️⃣ 把 G 的状态从 _Grunning 改为 _Gwaiting 3️⃣ 将它加入相应的 等待队列（wait queue） 4️⃣ 当前 M 继续执行其他可运行的 G（不 handoff P）\n📦 三、挂起的 G 被放到哪里？ 这取决于它被什么阻塞。 我们可以看几个常见场景：\n✅ 场景 1：Channel 阻塞 ch := make(chan int) \u0026lt;-ch // 无数据可读，被挂起 执行 \u0026lt;-ch 时：\nruntime 发现 channel 没有可读数据； 当前 G（比如 G1）被放入 ch.recvq 等待队列； G1 状态置为 _Gwaiting； 调度器立即让出 M 执行其他 G。 📦 存放位置：chan.recvq（链表或队列结构）\n当另一个 G2 向 channel 发送数据时：\nruntime 会从 recvq 中取出一个等待的 G； 把它状态改回 _Grunnable； 放入 P 的本地可运行队列（runq）； 等待被调度执行。 ✅ 场景 2：Mutex 阻塞 var mu sync.Mutex mu.Lock() mu.Lock() // 第二次阻塞 第一个 G1 获得锁； 第二个 G2 调用 Lock() 时发现锁被占用； runtime 把 G2 挂入 mutex 的等待队列（sudog 结构）； G2 状态 _Gwaiting； 当前 M 去执行别的 G。 📦 存放位置：锁的等待队列（sudog）\n当 G1 调用 Unlock() 时：\nruntime 会唤醒一个等待的 G（从 sudog 拿出）； 改状态为 _Grunnable； 放入当前 P 的 run queue。 ✅ 场景 3：Cond 阻塞（类似 WaitGroup） cond.L.Lock() cond.Wait() // 阻塞 runtime 把当前 G 放入 cond 的等待队列； 改为 _Gwaiting； unlock 互斥锁； 当前 M 继续执行其他 G。 📦 存放位置：Cond 的等待队列\n当 Signal() 或 Broadcast() 调用：\nruntime 取出等待的 G； 改状态 _Grunnable； 放入 run queue。 ✅ 场景 4：select 阻塞（多个 channel 都没就绪） select { case \u0026lt;-ch1: case \u0026lt;-ch2: default: // 不会阻塞 } 如果所有 case 都阻塞：\nruntime 把 G 加入所有相关 channel 的等待队列； 当任意一个 channel 就绪时，唤醒它； 其他等待位置的 entry 会被清理。 📦 存放位置：多个 channel 的等待队列（sudog 链表）\n⚙️ 四、唤醒过程（被挂起的 G 重新运行） 当对应事件（如数据到达、锁释放）发生时：\n1️⃣ runtime 把等待队列中的 G 拿出来； 2️⃣ 改状态 _Grunnable； 3️⃣ 放入 P 的本地 run queue 或全局 run queue； 4️⃣ 被某个 M 执行。\n🧩 示意：\n被挂起的 G ——\u0026gt; 等待队列 ——\u0026gt; 事件触发唤醒 ——\u0026gt; run queue ——\u0026gt; M 执行 🔍 五、总结图示 ┌────────────────────────────┐ │ P (Processor) │ │ │ │ 本地 run queue │ │ [G2][G3][G4] │ └───────────▲────────────────┘ │ ┌──────┴──────┐ │ 阻塞事件 │ │ (chan/mutex)│ └──────┬──────┘ │ 挂起的 G1 状态: _Gwaiting 存放于等待队列 唤醒后：\nwait queue → G1 状态变为 _Grunnable → 放入 P.runq → 等待调度执行 ✅ 六、总结一句话 被挂起的 G 不会运行，它被放入对应资源的等待队列（chan、mutex、cond 等）。 等待资源可用时，runtime 把它唤醒、改为 _Grunnable，放回 P 的 run queue 等待执行。 整个过程 M 与 P 不解绑（不会 handoff），M 会去跑其他 G。\n",
"tags":null,
"categories":null
},{
"title":"如何保证数据录入不混乱",
"permalink": "http://localhost:1313/posts/scenario/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E5%BD%95%E5%85%A5%E4%B8%8D%E6%B7%B7%E4%B9%B1/",
"summary": "如何保证数据录入不混乱 数据并发 可以采用go的sync.mutex/数据库的锁/分布式锁来实现并发访问控制，在单机服务下，可以采用go的互斥锁保护临界资源。在分布式场景下，并发量不高的情况下，采用 数据库的行锁，行锁从逻辑上可以分为悲观锁和乐观锁，悲观锁通过直接for update 语句加互斥锁，在本次事务未提交之前，其他事务都不能读写当前的临界资源。乐观锁可以使用版本号， 先查询版本号，在写入数据的时候再次验证版本号，如果相同再更新。\n",
"content": "如何保证数据录入不混乱 数据并发 可以采用go的sync.mutex/数据库的锁/分布式锁来实现并发访问控制，在单机服务下，可以采用go的互斥锁保护临界资源。在分布式场景下，并发量不高的情况下，采用 数据库的行锁，行锁从逻辑上可以分为悲观锁和乐观锁，悲观锁通过直接for update 语句加互斥锁，在本次事务未提交之前，其他事务都不能读写当前的临界资源。乐观锁可以使用版本号， 先查询版本号，在写入数据的时候再次验证版本号，如果相同再更新。\n",
"tags":null,
"categories":null
},{
"title":"一次mysql的执行过程",
"permalink": "http://localhost:1313/posts/database/%E4%B8%80%E6%AC%A1mysql%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/",
"summary": "一次mysql的执行过程 连接器 客户端需要先和服务器连接，检查帐号密码、权限，建立连接。 分析器 将客户端发送过来的sql语句进行分析，分为词法分析，将关键词提取出来，进行语法分析，检查是否有 语法错误，最后对语句进行语义分析。 优化器 根据用户的sql 执行查询计划，选择成本和时间最小的方案执行。 执行器 向存储引擎发送请求，执行具体的sql执行 ",
"content": "一次mysql的执行过程 连接器 客户端需要先和服务器连接，检查帐号密码、权限，建立连接。 分析器 将客户端发送过来的sql语句进行分析，分为词法分析，将关键词提取出来，进行语法分析，检查是否有 语法错误，最后对语句进行语义分析。 优化器 根据用户的sql 执行查询计划，选择成本和时间最小的方案执行。 执行器 向存储引擎发送请求，执行具体的sql执行 ",
"tags":null,
"categories":null
},{
"title":"Mysql_分组统计排序",
"permalink": "http://localhost:1313/posts/interview_code/mysql_%E5%88%86%E7%BB%84%E7%BB%9F%E8%AE%A1%E6%8E%92%E5%BA%8F/",
"summary": "记录一些面试遇到的题目\nCREATE TABLE students ( id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(50), age INT, sex CHAR(1), class VARCHAR(50) ); INSERT INTO students (name, age, sex, class) VALUES (\u0026#39;沉默王二\u0026#39;, 18, \u0026#39;女\u0026#39;, \u0026#39;三年二班\u0026#39;), (\u0026#39;沉默王一\u0026#39;, 20, \u0026#39;男\u0026#39;, \u0026#39;三年二班\u0026#39;), (\u0026#39;沉默王三\u0026#39;, 19, \u0026#39;男\u0026#39;, \u0026#39;三年三班\u0026#39;), (\u0026#39;沉默王四\u0026#39;, 17, \u0026#39;男\u0026#39;, \u0026#39;三年三班\u0026#39;), (\u0026#39;沉默王五\u0026#39;, 20, \u0026#39;女\u0026#39;, \u0026#39;三年四班\u0026#39;), (\u0026#39;沉默王六\u0026#39;, 21, \u0026#39;男\u0026#39;, \u0026#39;三年四班\u0026#39;), (\u0026#39;沉默王七\u0026#39;, 18, \u0026#39;女\u0026#39;, \u0026#39;三年四班\u0026#39;); select * from students s1 join ( select id, row_number() over (partition by class order by age) as rank_num from students ) s2 on s2.id = s1.id where s2.rank_num \u0026lt;= 2 ",
"content": "记录一些面试遇到的题目\nCREATE TABLE students ( id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(50), age INT, sex CHAR(1), class VARCHAR(50) ); INSERT INTO students (name, age, sex, class) VALUES (\u0026#39;沉默王二\u0026#39;, 18, \u0026#39;女\u0026#39;, \u0026#39;三年二班\u0026#39;), (\u0026#39;沉默王一\u0026#39;, 20, \u0026#39;男\u0026#39;, \u0026#39;三年二班\u0026#39;), (\u0026#39;沉默王三\u0026#39;, 19, \u0026#39;男\u0026#39;, \u0026#39;三年三班\u0026#39;), (\u0026#39;沉默王四\u0026#39;, 17, \u0026#39;男\u0026#39;, \u0026#39;三年三班\u0026#39;), (\u0026#39;沉默王五\u0026#39;, 20, \u0026#39;女\u0026#39;, \u0026#39;三年四班\u0026#39;), (\u0026#39;沉默王六\u0026#39;, 21, \u0026#39;男\u0026#39;, \u0026#39;三年四班\u0026#39;), (\u0026#39;沉默王七\u0026#39;, 18, \u0026#39;女\u0026#39;, \u0026#39;三年四班\u0026#39;); select * from students s1 join ( select id, row_number() over (partition by class order by age) as rank_num from students ) s2 on s2.id = s1.id where s2.rank_num \u0026lt;= 2 ",
"tags":null,
"categories":null
},{
"title":"数组交集",
"permalink": "http://localhost:1313/posts/datastructalgorithm/slice_%E6%95%B0%E7%BB%84%E4%BA%A4%E9%9B%86/",
"summary": " package main import \u0026#34;fmt\u0026#34; func main() { //4.1 实现一个函数，可以计算返回多个切片元素交集，如入参[1,2,3],[2,3,4] 返回 [2,3] arrays := make([][]int, 0) arrays = append(arrays, []int{1, 2, 3}) arrays = append(arrays, []int{2, 3, 4}) arrays = append(arrays, []int{3, 4}) res := calMerge(arrays...) fmt.Println(res) } func calMerge(arrays ...[]int) []int { // 数组先去重，就不实现了 check := make(map[int]int) for i := 0; i \u0026lt; len(arrays); i++ { for j := 0; j \u0026lt; len(arrays[i]); j++ { check[arrays[i][j]] += 1 } } newArray := make([]int, 0) for k, val := range check { if val \u0026gt;= len(arrays) { newArray = append(newArray, k) } } return newArray } ",
"content": " package main import \u0026#34;fmt\u0026#34; func main() { //4.1 实现一个函数，可以计算返回多个切片元素交集，如入参[1,2,3],[2,3,4] 返回 [2,3] arrays := make([][]int, 0) arrays = append(arrays, []int{1, 2, 3}) arrays = append(arrays, []int{2, 3, 4}) arrays = append(arrays, []int{3, 4}) res := calMerge(arrays...) fmt.Println(res) } func calMerge(arrays ...[]int) []int { // 数组先去重，就不实现了 check := make(map[int]int) for i := 0; i \u0026lt; len(arrays); i++ { for j := 0; j \u0026lt; len(arrays[i]); j++ { check[arrays[i][j]] += 1 } } newArray := make([]int, 0) for k, val := range check { if val \u0026gt;= len(arrays) { newArray = append(newArray, k) } } return newArray } ",
"tags":null,
"categories":null
},{
"title":"分布式锁的实现",
"permalink": "http://localhost:1313/posts/scenario/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0/",
"summary": "分布式锁的实现 分布式锁需要满足几个要点\n高性能、互斥，redis高性能，处理模型单线程天然支持互斥 原子性操作（主要是redis），高并发情况下，需要保证加锁、删除、自动续期的并发安全，所以需要原子性保证 安全释放锁、锁的删除，在并发情况下，可能出现A执行任务过长，锁已经自动过期了，B拿到锁在执行了，A执行完毕，释放锁，如果不进行锁的Val判断，会导致锁的异常释放。 自动过期/自动续期,使用set nx px 设置过期时间，使用看门狗机制实现自动续期，在释放锁的时候，使用context,cancel协程。 可重入 基于redis的实现 cache.go\npackage cache import ( \u0026#34;context\u0026#34; \u0026#34;github.com/redis/go-redis/v9\u0026#34; \u0026#34;time\u0026#34; ) type Cache interface { // 通用封装 需要解决 //（1）缓存三大问题 a 穿透 b 击穿 c 缓存雪崩 //（2）缓存不一致的问题 //（3）分布式锁 // 设置通用前缀 app_name , 数据类型 data, 模块名字 ， SetPrefix(prefix ...string) Cache Set(ctx context.Context, key, value string, short bool) error Get(ctx context.Context, key string, handler func(context.Context) (string, error)) (string, error) // 增加 删除 修改的时候调用 Flush(ctx context.Context, handler func(context.Context) error) error FlushWithConsistency(ctx context.Context, handler func(context.Context) error) error // 以下是简单封装 SimpleSet(ctx context.Context, key string, data any, expiration time.Duration) (err error) SimpleGet(ctx context.Context, key string) (data string, err error) SimpleIncr(ctx context.Context, key string) (count int64, err error) SimpleDel(ctx context.Context, keys ...string) (deletedCount int64, err error) Pipelined(ctx context.Context, callback func(redis.Pipeliner) error) (cmder []redis.Cmder, err error) // 批量删除 key 比如 app_name:* DeleteKeysByPattern(ctx context.Context, pattern string) (err error) // 集合操作 SAdd(ctx context.Context, key string, members ...string) (err error) SMembers(ctx context.Context, key string) (members []string, err error) // 过期集合 设置获取 AddMemberWithTTL(ctx context.Context, setKey, member string, ttl time.Duration) error GetValidMembers(ctx context.Context, setKey string) ([]string, error) RemoveMember(ctx context.Context, setKey string, members ...string) (int64, error) // 分布式加解锁 DistributedLock(ctx context.Context, key string, ttl time.Duration) error DistributedUnlock(ctx context.Context, key string) error } redis.go\n",
"content": "分布式锁的实现 分布式锁需要满足几个要点\n高性能、互斥，redis高性能，处理模型单线程天然支持互斥 原子性操作（主要是redis），高并发情况下，需要保证加锁、删除、自动续期的并发安全，所以需要原子性保证 安全释放锁、锁的删除，在并发情况下，可能出现A执行任务过长，锁已经自动过期了，B拿到锁在执行了，A执行完毕，释放锁，如果不进行锁的Val判断，会导致锁的异常释放。 自动过期/自动续期,使用set nx px 设置过期时间，使用看门狗机制实现自动续期，在释放锁的时候，使用context,cancel协程。 可重入 基于redis的实现 cache.go\npackage cache import ( \u0026#34;context\u0026#34; \u0026#34;github.com/redis/go-redis/v9\u0026#34; \u0026#34;time\u0026#34; ) type Cache interface { // 通用封装 需要解决 //（1）缓存三大问题 a 穿透 b 击穿 c 缓存雪崩 //（2）缓存不一致的问题 //（3）分布式锁 // 设置通用前缀 app_name , 数据类型 data, 模块名字 ， SetPrefix(prefix ...string) Cache Set(ctx context.Context, key, value string, short bool) error Get(ctx context.Context, key string, handler func(context.Context) (string, error)) (string, error) // 增加 删除 修改的时候调用 Flush(ctx context.Context, handler func(context.Context) error) error FlushWithConsistency(ctx context.Context, handler func(context.Context) error) error // 以下是简单封装 SimpleSet(ctx context.Context, key string, data any, expiration time.Duration) (err error) SimpleGet(ctx context.Context, key string) (data string, err error) SimpleIncr(ctx context.Context, key string) (count int64, err error) SimpleDel(ctx context.Context, keys ...string) (deletedCount int64, err error) Pipelined(ctx context.Context, callback func(redis.Pipeliner) error) (cmder []redis.Cmder, err error) // 批量删除 key 比如 app_name:* DeleteKeysByPattern(ctx context.Context, pattern string) (err error) // 集合操作 SAdd(ctx context.Context, key string, members ...string) (err error) SMembers(ctx context.Context, key string) (members []string, err error) // 过期集合 设置获取 AddMemberWithTTL(ctx context.Context, setKey, member string, ttl time.Duration) error GetValidMembers(ctx context.Context, setKey string) ([]string, error) RemoveMember(ctx context.Context, setKey string, members ...string) (int64, error) // 分布式加解锁 DistributedLock(ctx context.Context, key string, ttl time.Duration) error DistributedUnlock(ctx context.Context, key string) error } redis.go\npackage cache import ( \u0026#34;codeup.aliyun.com/619b3cb12f595dbd1b9b0b3e/go/common.git/log\u0026#34; \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/go-kratos/kratos/v2/errors\u0026#34; \u0026#34;github.com/redis/go-redis/v9\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) type RedisCache struct { Redis redis.UniversalClient Prefix []string RootPrefix []string Locks map[string]*Lock // key: 业务锁名, value: Lock实例 } func (c *RedisCache) DistributedLock(ctx context.Context, key string, ttl time.Duration) error { if c.Locks == nil { c.Locks = make(map[string]*Lock) } lockKey := c.getKey(key) lock := NewLock(c.Redis, lockKey) err := lock.Lock(ctx, ttl) if err != nil { return err } c.Locks[lockKey] = lock return nil } func (c *RedisCache) DistributedUnlock(ctx context.Context, key string) error { if c.Locks == nil { return fmt.Errorf(\u0026#34;no lock map found\u0026#34;) } lockKey := c.getKey(key) lock, ok := c.Locks[lockKey] if !ok || lock == nil { return fmt.Errorf(\u0026#34;no lock found for key: %s\u0026#34;, lockKey) } err := lock.UnLock(ctx) if err != nil { return err } delete(c.Locks, lockKey) return nil } func (c *RedisCache) SetPrefix(prefix ...string) Cache { return \u0026amp;RedisCache{ Redis: c.Redis, Prefix: prefix, RootPrefix: c.RootPrefix, Locks: c.Locks, } } func (c *RedisCache) Set(ctx context.Context, key, value string, short bool) error { // 默认五分钟 如果空数据 设置 1 分钟 // set random expiration avoid a large number of keys expire at the same time seconds := rand.New(rand.NewSource(time.Now().UnixNano())).Int63n(300) + 300 if short { // 防止缓存穿透 // if record not found, set a short expiration seconds = 60 + rand.New(rand.NewSource(time.Now().UnixNano())).Int63n(60) } return c.Redis.Set(ctx, c.getKey(key), value, time.Duration(seconds)*time.Second).Err() } func (c *RedisCache) Get(ctx context.Context, key string, handler func(context.Context) (string, error)) (result string, err error) { // 分布式锁解决 缓存击穿 currentKey := c.getKey(key) result, err = c.Redis.Get(ctx, currentKey).Result() if err == nil { return } // 加锁 去 数据库 读 数据 lock := NewLock(c.Redis, currentKey) err = c.GetLock(ctx, lock, currentKey) if err != nil { return \u0026#34;\u0026#34;, err } defer lock.UnLock(ctx) // 双重检测 result, err = c.Redis.Get(ctx, currentKey).Result() if err == nil { return } // result, err = handler(ctx) if err != nil { return \u0026#34;\u0026#34;, err } // 数据回填 if result == \u0026#34;\u0026#34; { err = c.Set(ctx, key, result, true) } else { err = c.Set(ctx, key, result, false) } if err != nil { return \u0026#34;\u0026#34;, err } return } func (c *RedisCache) GetLock(ctx context.Context, lock *Lock, key string) (err error) { // 自旋 1s retry := 0 for retry \u0026lt; 20 { err = lock.Lock(ctx, 5*time.Second) if err == nil { return } time.Sleep(50 * time.Millisecond) retry++ if err := ctx.Err(); err != nil { return err } } return errors.Errorf(500, \u0026#34;not get lock\u0026#34;, \u0026#34;\u0026#34;) } func (c *RedisCache) Flush(ctx context.Context, handler func(context.Context) error) error { err := c.DeleteKeysByPattern(ctx, c.getKey(\u0026#34;*\u0026#34;)) if err != nil { return err } return handler(ctx) } func (c *RedisCache) getKey(key string) string { temp := append(c.RootPrefix, c.Prefix...) if key != \u0026#34;\u0026#34; { temp = append(temp, key) } return strings.Join(temp, \u0026#34;:\u0026#34;) } // FlushWithConsistency 缓存双删 func (c *RedisCache) FlushWithConsistency(ctx context.Context, handler func(context.Context) error) (err error) { err = c.DeleteKeysByPattern(ctx, c.getKey(\u0026#34;*\u0026#34;)) if err != nil { return err } err = handler(ctx) if err != nil { return err } go func() { ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second) defer cancel() time.Sleep(1 * time.Second) err = c.DeleteKeysByPattern(ctx, c.getKey(\u0026#34;*\u0026#34;)) if err != nil { log.Info(err.Error()) } }() return } func NewRedisCache(redis redis.UniversalClient, prefix string) Cache { return \u0026amp;RedisCache{ Redis: redis, Prefix: []string{prefix}, RootPrefix: []string{prefix}, } } func (c *RedisCache) Pipelined(ctx context.Context, callback func(redis.Pipeliner) error) (cmder []redis.Cmder, err error) { return c.Redis.Pipelined(ctx, callback) } func (c *RedisCache) DeleteKeysByPattern(ctx context.Context, pattern string) (err error) { iter := c.Redis.Scan(ctx, 0, pattern, 0).Iterator() // 删除计数器 deleted := 0 // 分批删除键以避免一次删除太多键 var keys []string pipe := c.Redis.Pipeline() for iter.Next(ctx) { keys = append(keys, iter.Val()) // 每积累100个键执行一次删除操作 if len(keys) \u0026gt;= 100 { for _, k := range keys { pipe.Unlink(ctx, k) } _, err := pipe.Exec(ctx) if err != nil { return err } deleted += len(keys) keys = []string{} } } // 删除剩余的键 if len(keys) \u0026gt; 0 { for _, k := range keys { pipe.Unlink(ctx, k) } _, err := pipe.Exec(ctx) if err != nil { return err } deleted += len(keys) } // 检查迭代过程中是否有错误 if err := iter.Err(); err != nil { return err } log.Info(\u0026#34;成功删除 %d 个匹配 \u0026#39;%s\u0026#39; 的键\\n\u0026#34;, deleted, pattern) return nil } func (c *RedisCache) RemoveMember(ctx context.Context, setKey string, members ...string) (int64, error) { // 返回成功删除的成员数量 return c.Redis.ZRem(ctx, setKey, members).Result() } func (c *RedisCache) AddMemberWithTTL(ctx context.Context, setKey, member string, ttl time.Duration) error { expireTs := time.Now().Add(ttl).Unix() // 过期时间戳（秒） // ZADD myzset expireTs member if err := c.Redis.ZAdd(ctx, setKey, redis.Z{ Score: float64(expireTs), Member: member, }).Err(); err != nil { return err } return nil } func (c *RedisCache) GetValidMembers(ctx context.Context, setKey string) ([]string, error) { now := time.Now().Unix() // 只取 score \u0026gt; now 的成员 members, err := c.Redis.ZRangeByScore(ctx, setKey, \u0026amp;redis.ZRangeBy{ Min: fmt.Sprintf(\u0026#34;(%d\u0026#34;, now), // (now 表示严格大于 now Max: \u0026#34;+inf\u0026#34;, }).Result() if err != nil { return nil, err } go func() { subCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() err := c.CleanupExpired(subCtx, setKey) if err != nil { log.Info(err) } }() return members, nil } func (c *RedisCache) CleanupExpired(ctx context.Context, setKey string) error { now := time.Now().Unix() // 删除所有 score ≤ now 的成员 _, err := c.Redis.ZRemRangeByScore(ctx, setKey, \u0026#34;-inf\u0026#34;, fmt.Sprintf(\u0026#34;%d\u0026#34;, now)).Result() return err } func (c *RedisCache) SAdd(ctx context.Context, key string, members ...string) (err error) { return c.Redis.SAdd(ctx, key, members).Err() } func (c *RedisCache) SMembers(ctx context.Context, key string) (members []string, err error) { return c.Redis.SMembers(ctx, key).Result() } func (c *RedisCache) SimpleDel(ctx context.Context, keys ...string) (deletedCount int64, err error) { // 7. Del: 删除键 return c.Redis.Del(ctx, keys...).Result() } func (c *RedisCache) SimpleIncr(ctx context.Context, key string) (count int64, err error) { // 6. Incr: 对数字进行原子递增 return c.Redis.Incr(ctx, key).Result() } func (c *RedisCache) SimpleSet(ctx context.Context, key string, data any, expiration time.Duration) (err error) { // 2. Set: 设置键值对 (key: \u0026#34;mykey\u0026#34;, value: \u0026#34;hello Redis\u0026#34;)，没有过期时间 return c.Redis.Set(ctx, key, data, expiration).Err() } func (c *RedisCache) SimpleGet(ctx context.Context, key string) (data string, err error) { // 4. Get: 获取键的值 data, err = c.Redis.Get(ctx, key).Result() if errors.Is(err, redis.Nil) || err != nil { return \u0026#34;\u0026#34;, err } else { return data, nil } } redislock.go\npackage cache import ( //\u0026#34;codeup.aliyun.com/619b3cb12f595dbd1b9b0b3e/go/common.git/id\u0026#34; \u0026#34;codeup.aliyun.com/619b3cb12f595dbd1b9b0b3e/go/common.git/log\u0026#34; \u0026#34;context\u0026#34; \u0026#34;github.com/google/uuid\u0026#34; \u0026#34;github.com/pkg/errors\u0026#34; \u0026#34;github.com/redis/go-redis/v9\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) // 实现分布式锁 // 几个 要点 // 互斥 redis 天然支持 // 1.set nx px 设置过期时间 5.0之后可以一条命令设置 // 2.释放锁的时候需要判断，线程卡住，自动过期，其他线程加锁，你再删除九五删除了 // 3.需要 lua 脚本 执行删除操作 因为判断和删除是2个操作 。 判断和删除的过程中，锁过期，刚好其他线程上锁， // 就会导致误删除。 // 4.可重入（看具体业务）、 自动续期（看门狗） type Lock struct { client redis.UniversalClient key string uuID string MaxTtl int wg *sync.WaitGroup cancel context.CancelFunc } func NewLock(client redis.UniversalClient, key string) *Lock { //sf := id.NewSonyflake() uuID := uuid.NewString() return \u0026amp;Lock{ client: client, uuID: uuID, MaxTtl: 5, key: key + \u0026#34;:lock\u0026#34;, wg: \u0026amp;sync.WaitGroup{}, } } func (l *Lock) Lock(ctx context.Context, expire time.Duration) (err error) { ok, _ := l.client.SetNX(ctx, l.key, l.uuID, expire).Result() if !ok { return errors.New(\u0026#34;lock failed\u0026#34;) } // 设置最大延期时间 // 在 Lock 方法中修正 maxTtl 的计算 maxTtl := time.Duration(l.MaxTtl) * expire ctx, cancel := context.WithCancel(ctx) l.cancel = cancel go l.startWatchdog(ctx, expire, maxTtl) return } func (l *Lock) startWatchdog(ctx context.Context, expire time.Duration, maxTtl time.Duration) { l.wg.Add(1) defer l.wg.Done() ctx, cancel := context.WithTimeout(ctx, maxTtl) defer cancel() timer := time.NewTicker(expire / 3) defer timer.Stop() for { select { case \u0026lt;-timer.C: // 延期 extensionScript := ` if redis.call(\u0026#34;GET\u0026#34;, KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;PEXPIRE\u0026#34;, KEYS[1], ARGV[2]) else return 0 end ` expireMs := int64(expire.Milliseconds()) err := l.client.Eval(ctx, extensionScript, []string{l.key}, l.uuID, expireMs).Err() if err != nil { log.Info(err.Error()) return } case \u0026lt;-ctx.Done(): return } } } func (l *Lock) UnLock(ctx context.Context) (err error) { if l.cancel == nil { return errors.New(\u0026#34;lock not held\u0026#34;) } // 释放watchdog l.cancel() l.wg.Wait() script := ` if redis.call(\u0026#34;GET\u0026#34;, KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;DEL\u0026#34;, KEYS[1]) else return 0 end ` ok, err := l.client.Eval(ctx, script, []string{l.key}, l.uuID).Result() if err != nil { return err } if ok.(int64) != 1 { return errors.New(\u0026#34;unlock failed: lock not held\u0026#34;) } return nil } ",
"tags":null,
"categories":null
},{
"title":"零拷贝",
"permalink": "http://localhost:1313/posts/cs/%E9%9B%B6%E6%8B%B7%E8%B4%9D/",
"summary": "零拷贝技术 通过sendfile 等函数减少用户态和内核态的切换，减少拷贝次数，加快文件传输速度，但只适用于原样传输的场景，比如静态文件服务器，消息队列等，比如mysql 也是磁盘加载数据，但是需要对取出来的数据做各种处理就不适合这种场景。\n",
"content": "零拷贝技术 通过sendfile 等函数减少用户态和内核态的切换，减少拷贝次数，加快文件传输速度，但只适用于原样传输的场景，比如静态文件服务器，消息队列等，比如mysql 也是磁盘加载数据，但是需要对取出来的数据做各种处理就不适合这种场景。\n",
"tags":null,
"categories":null
},{
"title":"Str_百度真题原地置换大小写",
"permalink": "http://localhost:1313/posts/datastructalgorithm/str_%E7%99%BE%E5%BA%A6%E7%9C%9F%E9%A2%98%E5%8E%9F%E5%9C%B0%E7%BD%AE%E6%8D%A2%E5%A4%A7%E5%B0%8F%E5%86%99/",
"summary": "代码实现 package test3 import ( \u0026#34;fmt\u0026#34; \u0026#34;unicode\u0026#34; ) func main() { //输入一个字符串，里面有大写字母、小写字母、数字， //处理结束后，大写字母在前，然后是小写字母，最后是数字， //要求：在原有字符串上做交换实现，不要建新的数据结构。 //mN1oO2pP3 //Nm1oO2pP3 str := []rune(\u0026#34;mN1oO2pP3\u0026#34;) // AbcafafaaFAs exchangePos(str) fmt.Println(string(str)) } func exchangePos(str []rune) { // i 找非大写字母 j 找大写字母 如果 i ！= j 交换 length := len(str) i, j := 0, 0 for i \u0026lt; length \u0026amp;\u0026amp; j \u0026lt; length { if isUper(str[j]) { //\u0026amp;\u0026amp; !isUper(rune(str[i])) if i != j { str[i], str[j] = str[j], str[i] i++ } } if isUper(str[i]) { i++ } j++ } // i 从上一次结束为止开始，找 数字， j 找小写字母 如果 i ！= j 交换 j = i //fmt.Println(string(str), i, j) for i \u0026lt; length \u0026amp;\u0026amp; j \u0026lt; length { if isLower(str[j]) { //\u0026amp;\u0026amp; !isUper(rune(str[i])) if i != j { str[i], str[j] = str[j], str[i] i++ } } if isLower(str[i]) { i++ } j++ } return } func isUper(s rune) bool { return unicode.IsUpper(s) } func isLower(s rune) bool { return unicode.IsLower(s) } 测试用例 package test3 import ( \u0026#34;testing\u0026#34; ) func TestExchangePos(t *testing.T) { cases := []struct { input string expected string }{ // 基础情况 {\u0026#34;\u0026#34;, \u0026#34;\u0026#34;}, {\u0026#34;A\u0026#34;, \u0026#34;A\u0026#34;}, {\u0026#34;a\u0026#34;, \u0026#34;a\u0026#34;}, {\u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;}, // 已经有序 {\u0026#34;ABCabc123\u0026#34;, \u0026#34;ABCabc123\u0026#34;}, // 完全逆序 {\u0026#34;123cbaCBA\u0026#34;, \u0026#34;CBAcba123\u0026#34;}, // 混合 {\u0026#34;aA1\u0026#34;, \u0026#34;Aa1\u0026#34;}, {\u0026#34;1aA\u0026#34;, \u0026#34;Aa1\u0026#34;}, {\u0026#34;Aa1Bb2Cc3\u0026#34;, \u0026#34;ABCabc123\u0026#34;}, // 两类字符 {\u0026#34;abc123\u0026#34;, \u0026#34;abc123\u0026#34;}, {\u0026#34;ABC123\u0026#34;, \u0026#34;ABC123\u0026#34;}, {\u0026#34;ABCabc\u0026#34;, \u0026#34;ABCabc\u0026#34;}, // 全部同类 {\u0026#34;ABCDEF\u0026#34;, \u0026#34;ABCDEF\u0026#34;}, {\u0026#34;abcdef\u0026#34;, \u0026#34;abcdef\u0026#34;}, {\u0026#34;123456\u0026#34;, \u0026#34;123456\u0026#34;}, // 随机混乱 {\u0026#34;Zy9Xx8Ww7\u0026#34;, \u0026#34;ZXWyxw987\u0026#34;}, {\u0026#34;mN1oO2pP3\u0026#34;, \u0026#34;NOPomp213\u0026#34;}, // 边界 {\u0026#34;A1a\u0026#34;, \u0026#34;Aa1\u0026#34;}, {\u0026#34;1A1aA1\u0026#34;, \u0026#34;AAa111\u0026#34;}, {\u0026#34;zZ9zZ9\u0026#34;, \u0026#34;ZZzz99\u0026#34;}, // 重复模式 / 长度较大 {\u0026#34;Aa1Aa1Aa1Aa1\u0026#34;, \u0026#34;AAAAaaaa1111\u0026#34;}, {\u0026#34;987ZYXcba654\u0026#34;, \u0026#34;ZYXcba987654\u0026#34;}, } for _, c := range cases { runes := []rune(c.input) exchangePos(runes) got := string(runes) if got != c.expected { t.Errorf(\u0026#34;exchangePos(%q) = %q; expected %q\u0026#34;, c.input, got, c.expected) } } } ",
"content": "代码实现 package test3 import ( \u0026#34;fmt\u0026#34; \u0026#34;unicode\u0026#34; ) func main() { //输入一个字符串，里面有大写字母、小写字母、数字， //处理结束后，大写字母在前，然后是小写字母，最后是数字， //要求：在原有字符串上做交换实现，不要建新的数据结构。 //mN1oO2pP3 //Nm1oO2pP3 str := []rune(\u0026#34;mN1oO2pP3\u0026#34;) // AbcafafaaFAs exchangePos(str) fmt.Println(string(str)) } func exchangePos(str []rune) { // i 找非大写字母 j 找大写字母 如果 i ！= j 交换 length := len(str) i, j := 0, 0 for i \u0026lt; length \u0026amp;\u0026amp; j \u0026lt; length { if isUper(str[j]) { //\u0026amp;\u0026amp; !isUper(rune(str[i])) if i != j { str[i], str[j] = str[j], str[i] i++ } } if isUper(str[i]) { i++ } j++ } // i 从上一次结束为止开始，找 数字， j 找小写字母 如果 i ！= j 交换 j = i //fmt.Println(string(str), i, j) for i \u0026lt; length \u0026amp;\u0026amp; j \u0026lt; length { if isLower(str[j]) { //\u0026amp;\u0026amp; !isUper(rune(str[i])) if i != j { str[i], str[j] = str[j], str[i] i++ } } if isLower(str[i]) { i++ } j++ } return } func isUper(s rune) bool { return unicode.IsUpper(s) } func isLower(s rune) bool { return unicode.IsLower(s) } 测试用例 package test3 import ( \u0026#34;testing\u0026#34; ) func TestExchangePos(t *testing.T) { cases := []struct { input string expected string }{ // 基础情况 {\u0026#34;\u0026#34;, \u0026#34;\u0026#34;}, {\u0026#34;A\u0026#34;, \u0026#34;A\u0026#34;}, {\u0026#34;a\u0026#34;, \u0026#34;a\u0026#34;}, {\u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;}, // 已经有序 {\u0026#34;ABCabc123\u0026#34;, \u0026#34;ABCabc123\u0026#34;}, // 完全逆序 {\u0026#34;123cbaCBA\u0026#34;, \u0026#34;CBAcba123\u0026#34;}, // 混合 {\u0026#34;aA1\u0026#34;, \u0026#34;Aa1\u0026#34;}, {\u0026#34;1aA\u0026#34;, \u0026#34;Aa1\u0026#34;}, {\u0026#34;Aa1Bb2Cc3\u0026#34;, \u0026#34;ABCabc123\u0026#34;}, // 两类字符 {\u0026#34;abc123\u0026#34;, \u0026#34;abc123\u0026#34;}, {\u0026#34;ABC123\u0026#34;, \u0026#34;ABC123\u0026#34;}, {\u0026#34;ABCabc\u0026#34;, \u0026#34;ABCabc\u0026#34;}, // 全部同类 {\u0026#34;ABCDEF\u0026#34;, \u0026#34;ABCDEF\u0026#34;}, {\u0026#34;abcdef\u0026#34;, \u0026#34;abcdef\u0026#34;}, {\u0026#34;123456\u0026#34;, \u0026#34;123456\u0026#34;}, // 随机混乱 {\u0026#34;Zy9Xx8Ww7\u0026#34;, \u0026#34;ZXWyxw987\u0026#34;}, {\u0026#34;mN1oO2pP3\u0026#34;, \u0026#34;NOPomp213\u0026#34;}, // 边界 {\u0026#34;A1a\u0026#34;, \u0026#34;Aa1\u0026#34;}, {\u0026#34;1A1aA1\u0026#34;, \u0026#34;AAa111\u0026#34;}, {\u0026#34;zZ9zZ9\u0026#34;, \u0026#34;ZZzz99\u0026#34;}, // 重复模式 / 长度较大 {\u0026#34;Aa1Aa1Aa1Aa1\u0026#34;, \u0026#34;AAAAaaaa1111\u0026#34;}, {\u0026#34;987ZYXcba654\u0026#34;, \u0026#34;ZYXcba987654\u0026#34;}, } for _, c := range cases { runes := []rune(c.input) exchangePos(runes) got := string(runes) if got != c.expected { t.Errorf(\u0026#34;exchangePos(%q) = %q; expected %q\u0026#34;, c.input, got, c.expected) } } } ",
"tags":null,
"categories":null
},{
"title":"Matrix_多源扩散",
"permalink": "http://localhost:1313/posts/datastructalgorithm/matrix_%E5%A4%9A%E6%BA%90%E6%89%A9%E6%95%A3/",
"summary": "package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;strings\u0026#34; ) // 题目描述 // // 存在一个mxn的二维数组，其成员取值范围为0或1，其中值为1的成员具备扩散性，每经过1S，将上下左右值为0的成员同化为1，二维数组的成员初始值都为0，将第[i,j]和[k,l]两个个位置上元素修改成1后，求矩阵的所有，元素变为1需要多长时间 // // 输入描述 // // 输入数据中的前2个数字表示这是一个mxn的矩阵，m和n不会超过1024大小; // // 中间两个数字表示一个初始扩散点位置为I,j // // 最后2个数字表示另一个扩散点位置为k,l // // 输出描述 // // 输出矩阵的所有元素变为1所需要秒数 // // 用例 func main() { input := bufio.NewScanner(os.Stdin) input.Scan() str := input.Text() strArr := strings.Split(str, \u0026#34;,\u0026#34;) m, n := Atoi(strArr[0]), Atoi(strArr[1]) pos1, pos2, pos3, pos4 := Atoi(strArr[2]), Atoi(strArr[3]), Atoi(strArr[4]), Atoi(strArr[5]) time := getMatrixBroadcastTime(m, n, pos1, pos2, pos3, pos4) fmt.Println(time) } func getMatrixBroadcastTime(m, n, pos1, pos2, pos3, pos4 int) (res int) { path := make([]string, 0) path = append(path, getPos(pos1, pos2)) path = append(path, getPos(pos3, pos4)) check := make(map[string]bool) check[getPos(pos1, pos2)] = true check[getPos(pos3, pos4)] = true count := 2 for len(path) \u0026gt; 0 { length := len(path) for i := 0; i \u0026lt; length; i++ { pos := strings.Split(path[i], \u0026#34;_\u0026#34;) x, y := Atoi(pos[0]), Atoi(pos[1]) // 上 if x-1 \u0026gt;= 0 \u0026amp;\u0026amp; check[getPos(x-1, y)] != true { path = append(path, getPos(x-1, y)) check[getPos(x-1, y)] = true count++ } // 下 if x+1 \u0026lt; m \u0026amp;\u0026amp; check[getPos(x+1, y)] != true { path = append(path, getPos(x+1, y)) check[getPos(x+1, y)] = true count++ } // 左 if y-1 \u0026gt;= 0 \u0026amp;\u0026amp; check[getPos(x, y-1)] != true { path = append(path, getPos(x, y-1)) check[getPos(x, y-1)] = true count++ } // 右 if y+1 \u0026lt; n \u0026amp;\u0026amp; check[getPos(x, y+1)] != true { path = append(path, getPos(x, y+1)) check[getPos(x, y+1)] = true count++ } } res++ if count \u0026gt;= m*n { return } } return } func getPos(x, y int) string { return fmt.Sprintf(\u0026#34;%d_%d\u0026#34;, x, y) } func Atoi(str string) int { res, _ := strconv.Atoi(str) return res } ",
"content": "package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;strings\u0026#34; ) // 题目描述 // // 存在一个mxn的二维数组，其成员取值范围为0或1，其中值为1的成员具备扩散性，每经过1S，将上下左右值为0的成员同化为1，二维数组的成员初始值都为0，将第[i,j]和[k,l]两个个位置上元素修改成1后，求矩阵的所有，元素变为1需要多长时间 // // 输入描述 // // 输入数据中的前2个数字表示这是一个mxn的矩阵，m和n不会超过1024大小; // // 中间两个数字表示一个初始扩散点位置为I,j // // 最后2个数字表示另一个扩散点位置为k,l // // 输出描述 // // 输出矩阵的所有元素变为1所需要秒数 // // 用例 func main() { input := bufio.NewScanner(os.Stdin) input.Scan() str := input.Text() strArr := strings.Split(str, \u0026#34;,\u0026#34;) m, n := Atoi(strArr[0]), Atoi(strArr[1]) pos1, pos2, pos3, pos4 := Atoi(strArr[2]), Atoi(strArr[3]), Atoi(strArr[4]), Atoi(strArr[5]) time := getMatrixBroadcastTime(m, n, pos1, pos2, pos3, pos4) fmt.Println(time) } func getMatrixBroadcastTime(m, n, pos1, pos2, pos3, pos4 int) (res int) { path := make([]string, 0) path = append(path, getPos(pos1, pos2)) path = append(path, getPos(pos3, pos4)) check := make(map[string]bool) check[getPos(pos1, pos2)] = true check[getPos(pos3, pos4)] = true count := 2 for len(path) \u0026gt; 0 { length := len(path) for i := 0; i \u0026lt; length; i++ { pos := strings.Split(path[i], \u0026#34;_\u0026#34;) x, y := Atoi(pos[0]), Atoi(pos[1]) // 上 if x-1 \u0026gt;= 0 \u0026amp;\u0026amp; check[getPos(x-1, y)] != true { path = append(path, getPos(x-1, y)) check[getPos(x-1, y)] = true count++ } // 下 if x+1 \u0026lt; m \u0026amp;\u0026amp; check[getPos(x+1, y)] != true { path = append(path, getPos(x+1, y)) check[getPos(x+1, y)] = true count++ } // 左 if y-1 \u0026gt;= 0 \u0026amp;\u0026amp; check[getPos(x, y-1)] != true { path = append(path, getPos(x, y-1)) check[getPos(x, y-1)] = true count++ } // 右 if y+1 \u0026lt; n \u0026amp;\u0026amp; check[getPos(x, y+1)] != true { path = append(path, getPos(x, y+1)) check[getPos(x, y+1)] = true count++ } } res++ if count \u0026gt;= m*n { return } } return } func getPos(x, y int) string { return fmt.Sprintf(\u0026#34;%d_%d\u0026#34;, x, y) } func Atoi(str string) int { res, _ := strconv.Atoi(str) return res } ",
"tags":null,
"categories":null
},{
"title":"Str_判断字符顺序和存在",
"permalink": "http://localhost:1313/posts/datastructalgorithm/str_%E5%88%A4%E6%96%AD%E5%AD%97%E7%AC%A6%E9%A1%BA%E5%BA%8F%E5%92%8C%E5%AD%98%E5%9C%A8/",
"summary": "package test1 import \u0026#34;sort\u0026#34; //题目 // 题目描述输入两个字符串S和L，都只包含英文小写字母。S长度\u0026lt;=100，L长度\u0026lt;=500,000。 //判定S是否是L的有效子串。判定规则：S中的每个字符在L中都能找到（可以不连续），且S在Ｌ中字符的前后顺序与S中顺序要保持一致。 //（例如，S=”ace”是L=”abcde”的一个子序列且有效字符是a、c、e，而”aec”不是有效子序列，且有效字符只有a、e） //输入输出 //输入输入两个字符串S和L，都只包含英文小写字母。S长度\u0026lt;=100，L长度\u0026lt;=500,000。 //先输入S，再输入L，每个字符串占一行。输出S串最后一个有效字符在L中的位置。 //（首位从0开始计算，无有效字符返回-1） func SubStrLasPos(str string, sub string) int { // aabcdabc 8 // abc findKey := -1 // 循环找到所有的字符在str中的位置 预处理 strPos := make(map[byte][]int) for i := 0; i \u0026lt; len(str); i++ { strPos[str[i]] = append(strPos[str[i]], i) } // limit 限制每个字符的位置 当前值比后一个值的最大位置要小才行 limit := len(str) for i := len(sub) - 1; i \u0026gt;= 0; i-- { if _, ok := strPos[sub[i]]; !ok { return -1 } else { subArr := strPos[sub[i]] //sort.SearchInts() // 如果满足子数组的位置比Limit 小 就ok key := sort.SearchInts(subArr, limit) if key == 0 { return -1 } limit = subArr[key-1] if i == len(sub)-1 { findKey = limit } } // 排序拿到最大的值 //sort.Slice(strPos[sub[i]], func(i, j int) bool { //\treturn strPos[sub[i]][i] \u0026lt; strPos[sub[i]][j] //}) } return findKey } func search(arr []int, limit int) int { low, high := 0, len(arr)-1 for low \u0026lt;= high { mid := low + (high-low)/2 if arr[mid] == limit { return mid } else if arr[mid] \u0026gt; limit { high = mid - 1 } else { low = mid + 1 } } return -1 } ",
"content": "package test1 import \u0026#34;sort\u0026#34; //题目 // 题目描述输入两个字符串S和L，都只包含英文小写字母。S长度\u0026lt;=100，L长度\u0026lt;=500,000。 //判定S是否是L的有效子串。判定规则：S中的每个字符在L中都能找到（可以不连续），且S在Ｌ中字符的前后顺序与S中顺序要保持一致。 //（例如，S=”ace”是L=”abcde”的一个子序列且有效字符是a、c、e，而”aec”不是有效子序列，且有效字符只有a、e） //输入输出 //输入输入两个字符串S和L，都只包含英文小写字母。S长度\u0026lt;=100，L长度\u0026lt;=500,000。 //先输入S，再输入L，每个字符串占一行。输出S串最后一个有效字符在L中的位置。 //（首位从0开始计算，无有效字符返回-1） func SubStrLasPos(str string, sub string) int { // aabcdabc 8 // abc findKey := -1 // 循环找到所有的字符在str中的位置 预处理 strPos := make(map[byte][]int) for i := 0; i \u0026lt; len(str); i++ { strPos[str[i]] = append(strPos[str[i]], i) } // limit 限制每个字符的位置 当前值比后一个值的最大位置要小才行 limit := len(str) for i := len(sub) - 1; i \u0026gt;= 0; i-- { if _, ok := strPos[sub[i]]; !ok { return -1 } else { subArr := strPos[sub[i]] //sort.SearchInts() // 如果满足子数组的位置比Limit 小 就ok key := sort.SearchInts(subArr, limit) if key == 0 { return -1 } limit = subArr[key-1] if i == len(sub)-1 { findKey = limit } } // 排序拿到最大的值 //sort.Slice(strPos[sub[i]], func(i, j int) bool { //\treturn strPos[sub[i]][i] \u0026lt; strPos[sub[i]][j] //}) } return findKey } func search(arr []int, limit int) int { low, high := 0, len(arr)-1 for low \u0026lt;= high { mid := low + (high-low)/2 if arr[mid] == limit { return mid } else if arr[mid] \u0026gt; limit { high = mid - 1 } else { low = mid + 1 } } return -1 } ",
"tags":null,
"categories":null
},{
"title":"过期策略与内存淘汰策略",
"permalink": "http://localhost:1313/posts/cache/%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E4%B8%8E%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/",
"summary": " 一、Redis 的键过期机制 Redis 可以对每个 key 设置一个 过期时间（TTL, Time To Live），过期后 key 会被删除。\n1. 过期策略 Redis 对 key 的过期有两种策略：\n(1) 惰性删除（Lazy Expiration） 原理：只有当 key 被访问时，Redis 才检查它是否过期。 优点：避免了不必要的 CPU 消耗。 缺点：过期 key 如果长时间不访问，会占用内存。 (2) 定期删除（Periodic Expiration） 原理：Redis 会周期性（默认每 100ms）随机检查一些带过期时间的 key，并删除过期 key。\n实现：\n每次检查 20 个 key。 如果过期数量 \u0026gt; 25%，继续检查下一批 key。 每次检查耗时不超过 1ms。 优点：可以及时回收内存。\n缺点：不能保证所有过期 key 立即删除，可能延迟。\nRedis 综合使用了惰性删除和定期删除，保证性能和及时性之间的平衡。\n2. TTL 命令 EXPIRE key seconds 设置过期时间。 EXPIREAT key timestamp 按时间戳设置过期时间。 TTL key 查看剩余时间。 PTTL key 查看毫秒级 TTL。 二、Redis 的淘汰策略（内存不足时） 当 Redis 设置了 maxmemory 限制，并且内存达到上限时，需要 淘汰旧数据。\n",
"content": " 一、Redis 的键过期机制 Redis 可以对每个 key 设置一个 过期时间（TTL, Time To Live），过期后 key 会被删除。\n1. 过期策略 Redis 对 key 的过期有两种策略：\n(1) 惰性删除（Lazy Expiration） 原理：只有当 key 被访问时，Redis 才检查它是否过期。 优点：避免了不必要的 CPU 消耗。 缺点：过期 key 如果长时间不访问，会占用内存。 (2) 定期删除（Periodic Expiration） 原理：Redis 会周期性（默认每 100ms）随机检查一些带过期时间的 key，并删除过期 key。\n实现：\n每次检查 20 个 key。 如果过期数量 \u0026gt; 25%，继续检查下一批 key。 每次检查耗时不超过 1ms。 优点：可以及时回收内存。\n缺点：不能保证所有过期 key 立即删除，可能延迟。\nRedis 综合使用了惰性删除和定期删除，保证性能和及时性之间的平衡。\n2. TTL 命令 EXPIRE key seconds 设置过期时间。 EXPIREAT key timestamp 按时间戳设置过期时间。 TTL key 查看剩余时间。 PTTL key 查看毫秒级 TTL。 二、Redis 的淘汰策略（内存不足时） 当 Redis 设置了 maxmemory 限制，并且内存达到上限时，需要 淘汰旧数据。\nRedis 支持以下几种淘汰策略：\n策略 行为 noeviction 不淘汰，直接返回错误（写命令失败） allkeys-lru 对所有 key 使用 LRU（最近最少使用）策略 volatile-lru 对设置了过期时间的 key 使用 LRU allkeys-random 随机淘汰任意 key volatile-random 随机淘汰有过期时间的 key volatile-ttl 优先淘汰 TTL 最短的 key 注意：\nallkeys 表示从所有 key 中选择。 volatile 表示只从带过期时间的 key 中选择。 1. LRU 淘汰机制 Redis 会维护一个 近似 LRU 数据结构。 实现上并不是对所有 key 完全排序，而是随机抽样（默认 5 个 key）选择最近最少使用的 key 淘汰。 时间复杂度：O(1)（近似 LRU） 2. LFU 淘汰机制（Redis 4.0+） LFU = Least Frequently Used，淘汰使用频率最低的 key。\nRedis 维护访问频率计数器，定期衰减。\n策略：\nallkeys-lfu：所有 key 使用 LFU。 volatile-lfu：仅对带 TTL 的 key 使用 LFU。 3. 随机淘汰 随机选择 key 淘汰，算法简单，但可能会淘汰热数据。 使用场景：不关心哪些数据更重要的情况。 4. TTL 淘汰 优先淘汰过期时间最短的 key。 用于对数据时效性敏感的场景。 三、Redis 内存回收总结 过期删除：\n惰性删除 + 定期删除 内存淘汰（maxmemory 达到限制）：\n配置 maxmemory-policy（如 allkeys-lru、volatile-lfu 等） 关键点：\nRedis 不会每秒扫描所有 key。 淘汰策略是 近似算法，兼顾性能和内存控制。 对性能敏感的场景，可以使用 LRU/LFU。 对过期时间敏感的场景，可以使用 TTL 策略。 ",
"tags":null,
"categories":null
},{
"title":"Go实现lru",
"permalink": "http://localhost:1313/posts/datastructalgorithm/go%E5%AE%9E%E7%8E%B0lru/",
"summary": "package main import \u0026#34;fmt\u0026#34; // func main() { // //\t//LRU //\t//实现一个 LRU 缓存，要求支持以下操作： //\t//- Get(key int)(int, bool)：如果缓存中存在该 key，返回其对应的值，否则返回 0,false。 //\t//- Put(key, value int)：将一个 key-value 对插入缓存。如果缓存已经满了，淘汰最久未使用的元素。 //\t// //\t//示例： //\t//func main() { //\t// // 构造 一个 LRU cache //\t// cache := Constructor(2) //\t// cache.Put(1, 1) //\t// cache.Put(2, 2) //\t// //\t// // 测试缓存获取 //\t// fmt.Println(cache.Get(1)) // 输出: 1 true //\t// fmt.Println(cache.Get(3)) // 输出: 0 false //\t// //\t// cache.Put(3, 3) //\t// fmt.Println(cache.Get(2)) // 输出: 0 false //\t// //\t// cache.Put(4, 4) //\t// fmt.Println(cache.Get(1)) // 输出: 0 false //\t// fmt.Println(cache.Get(3)) // 输出: 3 true //\t// fmt.Println(cache.Get(4)) // 输出: 4 true //\t//} //\t} func main() { // 构造 一个 LRU cache cache := Constructor(2) cache.Put(2, 1) cache.Put(1, 1) cache.Put(2, 3) cache.Put(4, 1) fmt.Println(cache.Get(1)) fmt.Println(cache.Get(2)) } type Node struct { next *Node pre *Node val int key int } type LRUCache struct { capacity int size int cache map[int]*Node head, tail *Node } func Constructor(capacity int) LRUCache { l := LRUCache{ capacity: capacity, cache: make(map[int]*Node, capacity), head: \u0026amp;Node{}, tail: \u0026amp;Node{}, } l.head.next = l.tail l.tail.pre = l.head return l } // 1 2 3 4 func (l *LRUCache) Get(key int) int { // 从map拿数据 if _, ok := l.cache[key]; !ok { return -1 } node := l.cache[key] l.MoveToHead(node) return node.val } func (l *LRUCache) Put(key int, val int) { if _, ok := l.cache[key]; ok { l.cache[key].val = val l.MoveToHead(l.cache[key]) } else { l.size++ node := InitNode(key, val) l.cache[key] = node l.AddToHead(node) if l.size \u0026gt; l.capacity { node := l.RemoveTail() l.size-- delete(l.cache, node.key) } } } func InitNode(key, val int) *Node { return \u0026amp;Node{ key: key, val: val, } } // 添加到头节点 func (l *LRUCache) AddToHead(newNode *Node) *Node { newNode.next = l.head.next newNode.pre = l.head l.head.next.pre = newNode l.head.next = newNode return newNode } func (l *LRUCache) RemoveNode(node *Node) { node.pre.next = node.next node.next.pre = node.pre } func (l *LRUCache) RemoveTail() *Node { node := l.tail.pre //l.tail.pre = node.pre l.RemoveNode(node) return node } func (l *LRUCache) MoveToHead(node *Node) { l.RemoveNode(node) l.AddToHead(node) } ",
"content": "package main import \u0026#34;fmt\u0026#34; // func main() { // //\t//LRU //\t//实现一个 LRU 缓存，要求支持以下操作： //\t//- Get(key int)(int, bool)：如果缓存中存在该 key，返回其对应的值，否则返回 0,false。 //\t//- Put(key, value int)：将一个 key-value 对插入缓存。如果缓存已经满了，淘汰最久未使用的元素。 //\t// //\t//示例： //\t//func main() { //\t// // 构造 一个 LRU cache //\t// cache := Constructor(2) //\t// cache.Put(1, 1) //\t// cache.Put(2, 2) //\t// //\t// // 测试缓存获取 //\t// fmt.Println(cache.Get(1)) // 输出: 1 true //\t// fmt.Println(cache.Get(3)) // 输出: 0 false //\t// //\t// cache.Put(3, 3) //\t// fmt.Println(cache.Get(2)) // 输出: 0 false //\t// //\t// cache.Put(4, 4) //\t// fmt.Println(cache.Get(1)) // 输出: 0 false //\t// fmt.Println(cache.Get(3)) // 输出: 3 true //\t// fmt.Println(cache.Get(4)) // 输出: 4 true //\t//} //\t} func main() { // 构造 一个 LRU cache cache := Constructor(2) cache.Put(2, 1) cache.Put(1, 1) cache.Put(2, 3) cache.Put(4, 1) fmt.Println(cache.Get(1)) fmt.Println(cache.Get(2)) } type Node struct { next *Node pre *Node val int key int } type LRUCache struct { capacity int size int cache map[int]*Node head, tail *Node } func Constructor(capacity int) LRUCache { l := LRUCache{ capacity: capacity, cache: make(map[int]*Node, capacity), head: \u0026amp;Node{}, tail: \u0026amp;Node{}, } l.head.next = l.tail l.tail.pre = l.head return l } // 1 2 3 4 func (l *LRUCache) Get(key int) int { // 从map拿数据 if _, ok := l.cache[key]; !ok { return -1 } node := l.cache[key] l.MoveToHead(node) return node.val } func (l *LRUCache) Put(key int, val int) { if _, ok := l.cache[key]; ok { l.cache[key].val = val l.MoveToHead(l.cache[key]) } else { l.size++ node := InitNode(key, val) l.cache[key] = node l.AddToHead(node) if l.size \u0026gt; l.capacity { node := l.RemoveTail() l.size-- delete(l.cache, node.key) } } } func InitNode(key, val int) *Node { return \u0026amp;Node{ key: key, val: val, } } // 添加到头节点 func (l *LRUCache) AddToHead(newNode *Node) *Node { newNode.next = l.head.next newNode.pre = l.head l.head.next.pre = newNode l.head.next = newNode return newNode } func (l *LRUCache) RemoveNode(node *Node) { node.pre.next = node.next node.next.pre = node.pre } func (l *LRUCache) RemoveTail() *Node { node := l.tail.pre //l.tail.pre = node.pre l.RemoveNode(node) return node } func (l *LRUCache) MoveToHead(node *Node) { l.RemoveNode(node) l.AddToHead(node) } ",
"tags":null,
"categories":null
},{
"title":"Go实现限流器",
"permalink": "http://localhost:1313/posts/datastructalgorithm/go%E5%AE%9E%E7%8E%B0%E9%99%90%E6%B5%81%E5%99%A8/",
"summary": "常见的限流方法 令牌桶,允许突发流量，控制平均速率,golang.org/x/time/rate.Limiter,最常用和推荐，性能极高。 漏桶,平滑输出流量，强制固定速率,Channel + time.Ticker,适合需要固定速率处理任务的场景。 滑动窗口,避免固定窗口的边界效应,Redis ZSET + LUA 脚本,精度高，适合分布式限流。 固定窗口,实现简单，开销小,In-memory Map + Mutex,适合对限流精度要求不高的场景。 常见实现 令牌桶 思路： 用 goroutine 持续按速率向 channel 放 token，业务处理前尝试取 token，取不到则拒绝或等待。 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) type TokenBucket struct { tokens chan struct{} } func NewTokenBucket(rate int, capacity int) *TokenBucket { tb := \u0026amp;TokenBucket{tokens: make(chan struct{}, capacity)} ticker := time.NewTicker(time.Second / time.Duration(rate)) // 初始时先装满 for i := 0; i \u0026lt; capacity; i++ { tb.tokens \u0026lt;- struct{}{} } go func() { for range ticker.C { select { case tb.tokens \u0026lt;- struct{}{}: default: } } }() return tb } func (tb *TokenBucket) Allow() bool { select { case \u0026lt;-tb.tokens: return true default: return false } } func main() { tb := NewTokenBucket(5, 10) // 每秒 5 个，桶容量 10 for i := 0; i \u0026lt; 20; i++ { if tb.Allow() { fmt.Println(\u0026#34;allowed\u0026#34;, i) } else { fmt.Println(\u0026#34;rejected\u0026#34;, i) } time.Sleep(100 * time.Millisecond) } } ",
"content": "常见的限流方法 令牌桶,允许突发流量，控制平均速率,golang.org/x/time/rate.Limiter,最常用和推荐，性能极高。 漏桶,平滑输出流量，强制固定速率,Channel + time.Ticker,适合需要固定速率处理任务的场景。 滑动窗口,避免固定窗口的边界效应,Redis ZSET + LUA 脚本,精度高，适合分布式限流。 固定窗口,实现简单，开销小,In-memory Map + Mutex,适合对限流精度要求不高的场景。 常见实现 令牌桶 思路： 用 goroutine 持续按速率向 channel 放 token，业务处理前尝试取 token，取不到则拒绝或等待。 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) type TokenBucket struct { tokens chan struct{} } func NewTokenBucket(rate int, capacity int) *TokenBucket { tb := \u0026amp;TokenBucket{tokens: make(chan struct{}, capacity)} ticker := time.NewTicker(time.Second / time.Duration(rate)) // 初始时先装满 for i := 0; i \u0026lt; capacity; i++ { tb.tokens \u0026lt;- struct{}{} } go func() { for range ticker.C { select { case tb.tokens \u0026lt;- struct{}{}: default: } } }() return tb } func (tb *TokenBucket) Allow() bool { select { case \u0026lt;-tb.tokens: return true default: return false } } func main() { tb := NewTokenBucket(5, 10) // 每秒 5 个，桶容量 10 for i := 0; i \u0026lt; 20; i++ { if tb.Allow() { fmt.Println(\u0026#34;allowed\u0026#34;, i) } else { fmt.Println(\u0026#34;rejected\u0026#34;, i) } time.Sleep(100 * time.Millisecond) } } ",
"tags":null,
"categories":null
},{
"title":"Mod",
"permalink": "http://localhost:1313/posts/go/mod/",
"summary": "go mod 加载机制 go root go的安装目录\ngo path go的源代码工作目录\ngo mod go从1.11开始，加入了 go mod。开启 go mod 之后，不需要讲所有的源代码放到gopath。\ngo 的加载机制 go 会把go mod所在的目录当成工作目录，先加载相对路径下的本地包，如果没有会去go mod文件查找，go mod 会尝试从go proxy 拉取代码，go proxy 是Google维护的go的包仓库，即使某些包的源码被删除，也还是可以从包仓库 下载，这保证了包引入的稳定性。如果go proxy没有，那么go会尝试从代码仓库拉取源码，比如github上的源码。go mod 当中 带有 // indirect的就是直接源码下载的。\n还可以使用 go mod edit -replace [old git package]@[version]=[new git package]@[version] 命令将远程代码仓库替换成本地的代码。 使用go private 设置私有化代码仓库的路径，然后配置认证就可以使用内部代码库。\n常用命令 go mod init 初始化模块，生成 go mod go mod tidy 拉取依赖，自动增删依赖，生成go.sum go mod download 将依赖预下载到本地缓存 go mod vendor 将下载的依赖缓存到 ./vendor,用于离线构建 go mod edit ",
"content": "go mod 加载机制 go root go的安装目录\ngo path go的源代码工作目录\ngo mod go从1.11开始，加入了 go mod。开启 go mod 之后，不需要讲所有的源代码放到gopath。\ngo 的加载机制 go 会把go mod所在的目录当成工作目录，先加载相对路径下的本地包，如果没有会去go mod文件查找，go mod 会尝试从go proxy 拉取代码，go proxy 是Google维护的go的包仓库，即使某些包的源码被删除，也还是可以从包仓库 下载，这保证了包引入的稳定性。如果go proxy没有，那么go会尝试从代码仓库拉取源码，比如github上的源码。go mod 当中 带有 // indirect的就是直接源码下载的。\n还可以使用 go mod edit -replace [old git package]@[version]=[new git package]@[version] 命令将远程代码仓库替换成本地的代码。 使用go private 设置私有化代码仓库的路径，然后配置认证就可以使用内部代码库。\n常用命令 go mod init 初始化模块，生成 go mod go mod tidy 拉取依赖，自动增删依赖，生成go.sum go mod download 将依赖预下载到本地缓存 go mod vendor 将下载的依赖缓存到 ./vendor,用于离线构建 go mod edit ",
"tags":null,
"categories":null
},{
"title":"Channel",
"permalink": "http://localhost:1313/posts/go/channel/",
"summary": "csp并发模型 go在协程见通信使用channel进行通信。go的协程间通信的哲学是使用消息（channel）通信，而不是共享内存。为什么呢？ 使用消息通信的好处是\n没有共享状态，避免锁和竞争问题。 通信即同步，即通信双方都必须要在通道上同步，才能完成信息交换 channel channel是一个并发安全的，FIFO的用于不同goroutine间传递数据的管道。\n底层原理 底层是一个chan结构体，里面有一个环形队列和首尾指针，以及待发送队列和待接受队列。\n使用方法和使用场景 使用场景 协程间的数据传递和交换 协程间的同步与协调 控制并发数/实现信号量 超时处理与非阻塞操作 协程的取消与退出通知 实现发布订阅的简单消息队列、简单协程池 实现限流算法（令牌桶） 需要注意的点",
"content": "csp并发模型 go在协程见通信使用channel进行通信。go的协程间通信的哲学是使用消息（channel）通信，而不是共享内存。为什么呢？ 使用消息通信的好处是\n没有共享状态，避免锁和竞争问题。 通信即同步，即通信双方都必须要在通道上同步，才能完成信息交换 channel channel是一个并发安全的，FIFO的用于不同goroutine间传递数据的管道。\n底层原理 底层是一个chan结构体，里面有一个环形队列和首尾指针，以及待发送队列和待接受队列。\n使用方法和使用场景 使用场景 协程间的数据传递和交换 协程间的同步与协调 控制并发数/实现信号量 超时处理与非阻塞操作 协程的取消与退出通知 实现发布订阅的简单消息队列、简单协程池 实现限流算法（令牌桶） 需要注意的点 ",
"tags":null,
"categories":null
},{
"title":"ddd领域驱动设计",
"permalink": "http://localhost:1313/posts/design_pattern/ddd/",
"summary": "什么是DDD? DDD是domain design driver 的简称，根本的目的是为了解决软件的复杂性的一种设计思想。传统的MVC等代码、软件架构是面向程序员工程师的，而 产品经理更多只是需求产品设计，这导致软件架构和实际的业务脱离，当业务变得复杂，软件复杂性提高之后，后续的维护升级重构会遭遇重重困难。\n关键概念 充血模型and贫血模型 贫血模型是为了引出充血模型这一概念。贫血模型是指我们通常的数据库映射只有属性，而没有表现出具体的业务属性，也就是没有 引起映射数据变化的方法，就看不出来这个映射具体的业务，DDD的建议是把能引发变化的方法都写到这个变化内，这样别人一看就知道这个 实体具体包含了哪些业务属性。\n聚合根 防腐层 我的理解 整个DDD架构里面遵循了设计原则的最佳实践，比如高内聚低耦合这个大的思想，以及一些设计原则\n单一职责,一个方法、类、模块只干一件事情 开放封闭，对扩展开放，对修改封闭 依赖倒置，依赖于接口而不是具体实现。 接口隔离，接口小而精，不是胖而杂 里氏替换，对继承的补充，一个子类要能够完全替换父类，也就是要遵循父类的约定，这样少破坏原有的约定。 迪米洛法则（最少知识原则），不要跨多个对象调用方法，不需要知道跨对象的内部细节，只调用最新的朋友节点 战术构件和战略构件 DDD是一套架构思想方法论，它为代码层面和架构层面都提供了对应的构件帮我我们设计构架。\n战术构件（代码层面） 实体 值对象 根/聚合根 repository domain 工厂 事件 战略构件（架构层面） 界限上下文（模块） 通用语言（业务和技术用同一种专业术语沟通，防止鸡同鸭讲） 上下文映射（模块之间如何关联） 实际架构示例 ┌──────────────────────────────────────────────┐ │ 战略构件 (Strategic) │ │----------------------------------------------│ │ 限界上下文 (Bounded Contexts) │ │ ├── 用户上下文 (User Context) │ │ ├── 订单上下文 (Order Context) │ │ ├── 商品上下文 (Product Context) │ │ └── 支付上下文 (Payment Context) │ │ │ │ 上下文映射 (Context Map) │ │ ├── 上下游 (Upstream/Downstream) │ │ ├── 防腐层 (ACL) │ │ ├── 合作伙伴 (Partnership) │ │ └── 开放主机服务 (OHS) │ │ │ │ 通用语言 (Ubiquitous Language) │ │ └── \u0026quot;订单\u0026quot;、\u0026quot;支付单\u0026quot;、\u0026quot;退款单\u0026quot; │ └──────────────────────────────────────────────┘ │ ▼ ┌──────────────────────────────────────────────┐ │ 战术构件 (Tactical) │ │----------------------------------------------│ │ 接口层 (Interface Layer) │ │ └── Kratos Handler (HTTP/gRPC 接口) │ │ │ │ 应用层 (Application Layer) │ │ └── 应用服务 (Application Service) │ │ → OrderUsecase │ │ │ │ 领域层 (Domain Layer) │ │ ├── 实体 (Entity) \u0026amp; 聚合根 (AggregateRoot) │ │ │ → Order, OrderItem │ │ ├── 值对象 (Value Object) │ │ │ → Money, Address │ │ ├── 领域服务 (Domain Service) │ │ │ → PaymentService │ │ ├── 工厂 (Factory) │ │ │ → NewOrder │ │ ├── 领域事件 (Domain Event) │ │ │ → OrderPaidEvent │ │ └── 仓储接口 (Repository Interface) │ │ │ │ 基础设施层 (Infrastructure Layer) │ │ └── 仓储实现 (Repository Impl, GORM) │ │ → orderRepo (MySQL) │ └──────────────────────────────────────────────┘ kratos 和DDD 架构对照 Kratos 层级 DDD 层级 作用 service/ Interface / Adapter gRPC/HTTP Handler，参数验证/响应封装，调用 UseCase biz/ Domain + Application 业务逻辑和领域规则处理，UseCase（业务服务），纯业务计算 data/ Infrastructure 数据库、缓存、第三方 SDK 封装，实现 Repository 接口，提供外部依赖能力 pkg/ Infrastructure（共享组件） 可复用 SDK 封装、工具函数、通用库，跨服务共享 参考资料 美团 领域驱动设计在互联网业务开发中的实践 ",
"content": "什么是DDD? DDD是domain design driver 的简称，根本的目的是为了解决软件的复杂性的一种设计思想。传统的MVC等代码、软件架构是面向程序员工程师的，而 产品经理更多只是需求产品设计，这导致软件架构和实际的业务脱离，当业务变得复杂，软件复杂性提高之后，后续的维护升级重构会遭遇重重困难。\n关键概念 充血模型and贫血模型 贫血模型是为了引出充血模型这一概念。贫血模型是指我们通常的数据库映射只有属性，而没有表现出具体的业务属性，也就是没有 引起映射数据变化的方法，就看不出来这个映射具体的业务，DDD的建议是把能引发变化的方法都写到这个变化内，这样别人一看就知道这个 实体具体包含了哪些业务属性。\n聚合根 防腐层 我的理解 整个DDD架构里面遵循了设计原则的最佳实践，比如高内聚低耦合这个大的思想，以及一些设计原则\n单一职责,一个方法、类、模块只干一件事情 开放封闭，对扩展开放，对修改封闭 依赖倒置，依赖于接口而不是具体实现。 接口隔离，接口小而精，不是胖而杂 里氏替换，对继承的补充，一个子类要能够完全替换父类，也就是要遵循父类的约定，这样少破坏原有的约定。 迪米洛法则（最少知识原则），不要跨多个对象调用方法，不需要知道跨对象的内部细节，只调用最新的朋友节点 战术构件和战略构件 DDD是一套架构思想方法论，它为代码层面和架构层面都提供了对应的构件帮我我们设计构架。\n战术构件（代码层面） 实体 值对象 根/聚合根 repository domain 工厂 事件 战略构件（架构层面） 界限上下文（模块） 通用语言（业务和技术用同一种专业术语沟通，防止鸡同鸭讲） 上下文映射（模块之间如何关联） 实际架构示例 ┌──────────────────────────────────────────────┐ │ 战略构件 (Strategic) │ │----------------------------------------------│ │ 限界上下文 (Bounded Contexts) │ │ ├── 用户上下文 (User Context) │ │ ├── 订单上下文 (Order Context) │ │ ├── 商品上下文 (Product Context) │ │ └── 支付上下文 (Payment Context) │ │ │ │ 上下文映射 (Context Map) │ │ ├── 上下游 (Upstream/Downstream) │ │ ├── 防腐层 (ACL) │ │ ├── 合作伙伴 (Partnership) │ │ └── 开放主机服务 (OHS) │ │ │ │ 通用语言 (Ubiquitous Language) │ │ └── \u0026quot;订单\u0026quot;、\u0026quot;支付单\u0026quot;、\u0026quot;退款单\u0026quot; │ └──────────────────────────────────────────────┘ │ ▼ ┌──────────────────────────────────────────────┐ │ 战术构件 (Tactical) │ │----------------------------------------------│ │ 接口层 (Interface Layer) │ │ └── Kratos Handler (HTTP/gRPC 接口) │ │ │ │ 应用层 (Application Layer) │ │ └── 应用服务 (Application Service) │ │ → OrderUsecase │ │ │ │ 领域层 (Domain Layer) │ │ ├── 实体 (Entity) \u0026amp; 聚合根 (AggregateRoot) │ │ │ → Order, OrderItem │ │ ├── 值对象 (Value Object) │ │ │ → Money, Address │ │ ├── 领域服务 (Domain Service) │ │ │ → PaymentService │ │ ├── 工厂 (Factory) │ │ │ → NewOrder │ │ ├── 领域事件 (Domain Event) │ │ │ → OrderPaidEvent │ │ └── 仓储接口 (Repository Interface) │ │ │ │ 基础设施层 (Infrastructure Layer) │ │ └── 仓储实现 (Repository Impl, GORM) │ │ → orderRepo (MySQL) │ └──────────────────────────────────────────────┘ kratos 和DDD 架构对照 Kratos 层级 DDD 层级 作用 service/ Interface / Adapter gRPC/HTTP Handler，参数验证/响应封装，调用 UseCase biz/ Domain + Application 业务逻辑和领域规则处理，UseCase（业务服务），纯业务计算 data/ Infrastructure 数据库、缓存、第三方 SDK 封装，实现 Repository 接口，提供外部依赖能力 pkg/ Infrastructure（共享组件） 可复用 SDK 封装、工具函数、通用库，跨服务共享 参考资料 美团 领域驱动设计在互联网业务开发中的实践 ",
"tags":null,
"categories":null
},{
"title":"初始化方法比较",
"permalink": "http://localhost:1313/posts/go/%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95%E6%AF%94%E8%BE%83/",
"summary": "make和new的初始化比较 make new 返回值 返回实例化对象本身 返回类型并清空返回实例化对象的指针 作用类型、常见用法 slice、map、channel 所有类型 内部作用机制 初始化结构体，并初始化结构体内部的相关字段机构 初始化对象，清空内存，分配内存，置为零值 为什么new slice map 得到是nil 首先 new 严格遵守返回的是初始化对象指针的原则，而new slice、map的时候，返回的就是对象的引用，只是切片和哈希的 零值就是nil,所以如果new切片和map会出现无法使用的情况。\n",
"content": "make和new的初始化比较 make new 返回值 返回实例化对象本身 返回类型并清空返回实例化对象的指针 作用类型、常见用法 slice、map、channel 所有类型 内部作用机制 初始化结构体，并初始化结构体内部的相关字段机构 初始化对象，清空内存，分配内存，置为零值 为什么new slice map 得到是nil 首先 new 严格遵守返回的是初始化对象指针的原则，而new slice、map的时候，返回的就是对象的引用，只是切片和哈希的 零值就是nil,所以如果new切片和map会出现无法使用的情况。\n",
"tags":["go","make","new","初始化"],
"categories":null
},{
"title":"内存泄漏",
"permalink": "http://localhost:1313/posts/go/%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F/",
"summary": "什么是内存泄漏 指内存资源长期得不到释放，导致内存持续增长，最终导致内存溢出\n内存泄漏的常见场景 协程的泄漏 耗时任务或者http请求一直得不到响应，又没有设置超时时间 chan未正确关闭、阻塞。range channel 发送端未关闭导致死循环。 锁未正确释放、导致协程未能释放 资源未关闭，如file、数据库、redis连接、timer定时器、channel cgo 其他的一些 内存泄漏分析工具 pprof分析协程数量，内存占用情况等\n如何针对内存泄漏进行优化 针对协程泄漏 设置超时时间 context.deadline timeout 结合select进行超时控制 正确使用channel 正确使用互斥锁，配对使用 针对channel的泄漏 配对使用 在发送方关闭channel 正确使用缓冲channel和非缓冲channel 养成关闭资源的习惯，使用defer,clear up 等工具 cgo和其他场景记得防止协程泄漏 ",
"content": "什么是内存泄漏 指内存资源长期得不到释放，导致内存持续增长，最终导致内存溢出\n内存泄漏的常见场景 协程的泄漏 耗时任务或者http请求一直得不到响应，又没有设置超时时间 chan未正确关闭、阻塞。range channel 发送端未关闭导致死循环。 锁未正确释放、导致协程未能释放 资源未关闭，如file、数据库、redis连接、timer定时器、channel cgo 其他的一些 内存泄漏分析工具 pprof分析协程数量，内存占用情况等\n如何针对内存泄漏进行优化 针对协程泄漏 设置超时时间 context.deadline timeout 结合select进行超时控制 正确使用channel 正确使用互斥锁，配对使用 针对channel的泄漏 配对使用 在发送方关闭channel 正确使用缓冲channel和非缓冲channel 养成关闭资源的习惯，使用defer,clear up 等工具 cgo和其他场景记得防止协程泄漏 ",
"tags":null,
"categories":null
},{
"title":"逃逸分析",
"permalink": "http://localhost:1313/posts/go/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/",
"summary": "什么是逃逸分析 计算机科学中对指针作用范围进行分析就叫做逃逸分析。分析变量是分配到堆上还是栈上。 分配到堆上和栈上的对比\n栈 堆 分配方式 随着函数创建自动分配 程序员手动分配 资源消耗 很小 ，大小固定 比较大，大小不固定，需要寻找到合适的大小。容易产生内存碎片 回收方式 随着函数的结束进行销毁 需要手动回收,或者根据gc算法进行回收 所以说编译器会尽可能的将变量分配到栈上， go会在静态编译阶段就确定变量到底应该分配到堆上还是栈上。 当一个变量在函数之外的地方还会被使用就会发生逃逸。\n以下几个场景会发生逃逸 返回一个变量的指针 返回一个闭包函数，闭包函数捕获了调用函数的变量 往channel发送了变量的指针 巨大的变量，编译器为了防止栈内存不够，会将其分配到堆上 引用类型的使用，比如传递slice、map、chan、interface等 如何对go的程序进行逃逸分析 使用源码go build \u0026ndash;gcflags \u0026lsquo;-m -l\u0026rsquo;分析，看变量是否发生了逃逸 还可以结合pprof对堆内存的分配进行查看，结合热点路径使用go gc flag 进行分析\n如何使用 逃逸分析需要注意的点 在不影响代码结构合理性的情况下，进行减少使用指针（变量的内存占用不大的情况下）。 不要过度设计，持续重构。也就是先实现业务，再去结合工具来进行调整 ",
"content": "什么是逃逸分析 计算机科学中对指针作用范围进行分析就叫做逃逸分析。分析变量是分配到堆上还是栈上。 分配到堆上和栈上的对比\n栈 堆 分配方式 随着函数创建自动分配 程序员手动分配 资源消耗 很小 ，大小固定 比较大，大小不固定，需要寻找到合适的大小。容易产生内存碎片 回收方式 随着函数的结束进行销毁 需要手动回收,或者根据gc算法进行回收 所以说编译器会尽可能的将变量分配到栈上， go会在静态编译阶段就确定变量到底应该分配到堆上还是栈上。 当一个变量在函数之外的地方还会被使用就会发生逃逸。\n以下几个场景会发生逃逸 返回一个变量的指针 返回一个闭包函数，闭包函数捕获了调用函数的变量 往channel发送了变量的指针 巨大的变量，编译器为了防止栈内存不够，会将其分配到堆上 引用类型的使用，比如传递slice、map、chan、interface等 如何对go的程序进行逃逸分析 使用源码go build \u0026ndash;gcflags \u0026lsquo;-m -l\u0026rsquo;分析，看变量是否发生了逃逸 还可以结合pprof对堆内存的分配进行查看，结合热点路径使用go gc flag 进行分析\n如何使用 逃逸分析需要注意的点 在不影响代码结构合理性的情况下，进行减少使用指针（变量的内存占用不大的情况下）。 不要过度设计，持续重构。也就是先实现业务，再去结合工具来进行调整 ",
"tags":null,
"categories":null
},{
"title":"Gc",
"permalink": "http://localhost:1313/posts/go/gc/",
"summary": "什么是GC gc就是内存垃圾回收。c/c++这类语言可以由程序员申请内存，分配到堆上，堆上的数据随着函数结束并不会自动被清零，需要程序员手动清理。 这会给编程增加负担和隐患。高级语言如java/go支持gc,自动分析没有被引用的变量，进行内存回收。\n常见的GC方法 引用计数法 对变量对象的引用次数进行计数，当计数为0就会被回收。它实现简单，但效率不高无法解决循环引用的问题。\n标记清除法 扫描所有对象，将有引用的进行标记。优点是实现简单，但可能出现很多内存碎片，不利于内存重新分配。\n复制法 准备2个大小一样的内存块，将存活的对象放到新的内存块。优点是解决了内存碎片问题，但内存复制比较消耗资源，还需要将引用关系进行复制。\n分代法 将对象创建的不同时间分为青年代、老年代。分代发基于一种实践思想，大多数对象的生命周期都很短。\n三色标记法 stw可以是start the world 或者 stop zhe world的缩写，他指的是stop the word 到 start the world 这个间隔的时间。在gc过程需要暂停用户 代码执行，进行内存扫描，这个stw时间越短，对程序的性能提升越高。\ngo的GC实现 go因为内存分配是采用tcmalloc分配法，所有不需要处理内存碎片问题，同时go团队更加希望的是gc操作可以和用户代码一起执行，不仅是减少 stw的时间。go采用三色标记法对内存进行回收，并采用混合屏障提升并发时的回收效率。\ntcmalloc内存分配 首先每个协程都有自己的内存分配器，由一系列递增的内存大小块组成，每次内存申请回优先在本地分配器进行申请，当内存不足会向更高一级的内存分配器进行申请。 内存分类器会定时整理内存碎片，当空闲内存超过一定数量时会进行内存回收，不足时会进行内存分配。\ngo为什么采用三色标记法 go采用tcmalloc所以对内存碎片优化的方案的gc算法并不会带来明显的性能提升 go团队的目标不仅仅是减少stw的时候，还希望回收过程可以和用户代码共同执行，提升程序性能。 定义 go的gc扫描器将所有对象分为三类，分别是：\n白色对象（可能存活的对象）：一开始所有对象都标记成白色对象，当扫描完成后，白色对象不可达 灰色对象（波面）：正在被访问器访问到的对象，他可能指向白色对象 黑色对象（确定存活）：已经被回收期扫描。 扫描过程 分为4步\n所有根对象标记为白色 将根对象放入待扫描队列，标记成灰色 扫描队列所有的灰色对象，标记成黑色，并将引用对象标记成灰色。 重复步骤三，直到待扫描的灰色对象为空，所有对象标记成黑色或者白色。白色对象不可达，进行回收。 根对象在垃圾回收术语中被称为根集合，它包含 全局对象，程序在编译阶段就能确定的存在于程序整个生命周期的对象 执行栈，每个goroutine都有自己的内存栈，会有自己的栈对象和指向堆区块的指针 寄存器，计算过程中可能指向的一些堆区块的指针 没有stw可能得问题，对象被错误删除 假设以下场景：扫描到某个节点，存在a灰色对象引用白色对象b,存在一个黑色对象c。此时现将删除a对b的引用，同时添加 c对b的引用。b本来应该被正确标记成黑色的，由于对象c为黑色不会对它进行扫描，而a又删除了对b的引用，就会造成c始终不可达 造成误删除。\n当同时满足以下2个条件时，会出现误删除：\n赋值器创建一个黑色对象对白色对象的引用 删除灰色对象对这个白色的引用 只要破坏任意条件就可以避免误删除 避免条件一，也就避免了修改对象池当中需要被删除的对象的存活状态，应该存活的对象均可达。出现条件二，删除了灰色对象对白色对象的引用 这个白色对象也应该被删除。 避免条件二，白色对象最终可以由灰色访问到，进行正常标记。就算创建了黑色对象对白色对象的引用，也可以由灰色对象触达。 屏障机制 分成2种赋值器，插入时使用灰色赋值器，删除时使用黑色赋值器\n插入屏障 当添加一新的对象引用时，会先将插入对象赋值成灰色。破坏条件一，破坏了增加了一个黑色对象对白色对象的引用。有个一个细节，由于对所有对象进行插入屏障会比较 影响性能，golang团队后来决定只对堆区的对象启用插入屏障，栈区的对象会在第一次gc完成之后stw重新扫描一次栈区。\n删除屏障 当删除一个对象时，现将对象赋值为黑色。破坏条件二，破坏了删除一个灰色对象对白色对象的引用。\n",
"content": "什么是GC gc就是内存垃圾回收。c/c++这类语言可以由程序员申请内存，分配到堆上，堆上的数据随着函数结束并不会自动被清零，需要程序员手动清理。 这会给编程增加负担和隐患。高级语言如java/go支持gc,自动分析没有被引用的变量，进行内存回收。\n常见的GC方法 引用计数法 对变量对象的引用次数进行计数，当计数为0就会被回收。它实现简单，但效率不高无法解决循环引用的问题。\n标记清除法 扫描所有对象，将有引用的进行标记。优点是实现简单，但可能出现很多内存碎片，不利于内存重新分配。\n复制法 准备2个大小一样的内存块，将存活的对象放到新的内存块。优点是解决了内存碎片问题，但内存复制比较消耗资源，还需要将引用关系进行复制。\n分代法 将对象创建的不同时间分为青年代、老年代。分代发基于一种实践思想，大多数对象的生命周期都很短。\n三色标记法 stw可以是start the world 或者 stop zhe world的缩写，他指的是stop the word 到 start the world 这个间隔的时间。在gc过程需要暂停用户 代码执行，进行内存扫描，这个stw时间越短，对程序的性能提升越高。\ngo的GC实现 go因为内存分配是采用tcmalloc分配法，所有不需要处理内存碎片问题，同时go团队更加希望的是gc操作可以和用户代码一起执行，不仅是减少 stw的时间。go采用三色标记法对内存进行回收，并采用混合屏障提升并发时的回收效率。\ntcmalloc内存分配 首先每个协程都有自己的内存分配器，由一系列递增的内存大小块组成，每次内存申请回优先在本地分配器进行申请，当内存不足会向更高一级的内存分配器进行申请。 内存分类器会定时整理内存碎片，当空闲内存超过一定数量时会进行内存回收，不足时会进行内存分配。\ngo为什么采用三色标记法 go采用tcmalloc所以对内存碎片优化的方案的gc算法并不会带来明显的性能提升 go团队的目标不仅仅是减少stw的时候，还希望回收过程可以和用户代码共同执行，提升程序性能。 定义 go的gc扫描器将所有对象分为三类，分别是：\n白色对象（可能存活的对象）：一开始所有对象都标记成白色对象，当扫描完成后，白色对象不可达 灰色对象（波面）：正在被访问器访问到的对象，他可能指向白色对象 黑色对象（确定存活）：已经被回收期扫描。 扫描过程 分为4步\n所有根对象标记为白色 将根对象放入待扫描队列，标记成灰色 扫描队列所有的灰色对象，标记成黑色，并将引用对象标记成灰色。 重复步骤三，直到待扫描的灰色对象为空，所有对象标记成黑色或者白色。白色对象不可达，进行回收。 根对象在垃圾回收术语中被称为根集合，它包含 全局对象，程序在编译阶段就能确定的存在于程序整个生命周期的对象 执行栈，每个goroutine都有自己的内存栈，会有自己的栈对象和指向堆区块的指针 寄存器，计算过程中可能指向的一些堆区块的指针 没有stw可能得问题，对象被错误删除 假设以下场景：扫描到某个节点，存在a灰色对象引用白色对象b,存在一个黑色对象c。此时现将删除a对b的引用，同时添加 c对b的引用。b本来应该被正确标记成黑色的，由于对象c为黑色不会对它进行扫描，而a又删除了对b的引用，就会造成c始终不可达 造成误删除。\n当同时满足以下2个条件时，会出现误删除：\n赋值器创建一个黑色对象对白色对象的引用 删除灰色对象对这个白色的引用 只要破坏任意条件就可以避免误删除 避免条件一，也就避免了修改对象池当中需要被删除的对象的存活状态，应该存活的对象均可达。出现条件二，删除了灰色对象对白色对象的引用 这个白色对象也应该被删除。 避免条件二，白色对象最终可以由灰色访问到，进行正常标记。就算创建了黑色对象对白色对象的引用，也可以由灰色对象触达。 屏障机制 分成2种赋值器，插入时使用灰色赋值器，删除时使用黑色赋值器\n插入屏障 当添加一新的对象引用时，会先将插入对象赋值成灰色。破坏条件一，破坏了增加了一个黑色对象对白色对象的引用。有个一个细节，由于对所有对象进行插入屏障会比较 影响性能，golang团队后来决定只对堆区的对象启用插入屏障，栈区的对象会在第一次gc完成之后stw重新扫描一次栈区。\n删除屏障 当删除一个对象时，现将对象赋值为黑色。破坏条件二，破坏了删除一个灰色对象对白色对象的引用。\n混合屏障 栈区： gc开始阶段栈区所有的对象都被遍历并标记为黑色 gc进行阶段，增加和删除的对象也都被标记成黑色 堆区：删除或添加对象都标记为灰色 分析工具和分析方法 go的垃圾回收算法是按比例，无分代，与用户代码并发执行，无内存移动并主动向操作系统归还内存的回收算法，所以需要关注的点是：\nCPU利用率 stw的时间和频率 如何针对GC进行优化 调整gc CPU使用率 逃逸分析尽可能将变量分配到栈上 ",
"tags":null,
"categories":null
},{
"title":"Map",
"permalink": "http://localhost:1313/posts/go/map/",
"summary": "go的哈希实现 通用哈希实现 哈希表是一个高效的数据结构，通过对key经过哈希函数计算的值和存储数据的数组的长度，两者求余得到在数组插入的位置。高效的查找效率 时间复杂度为O(1)。\n哈希函数 任意长度的输入有固定输出 同一输入会产生同一个输出 输入的细小改变会造成输入的完全不一样 速度快 单项不可逆 go的哈希底层实现 通过底层结构体hmap来实例化map对象，hmap 包含指向[]bucket数组的指针。bucket结构里面会存储真实的数据 以key1key2 val1value2 的形式进行排列，方便内存对齐。头部有top哈希方便bucket内部进行数据定位，底部有指向溢出bucket的指针。 当发生哈希冲突，冲突的数据会存放到溢出bucket链表。\n插入过程 首先用哈希函数对key计算，得到64位数据（64位机器上）。低B位决定数据落入哪个桶。B是log2count，也就是以2为底bucket元素的长度的对数。 高8位决定落入bucket具体的位置。如果发送哈希冲突，就把数据存入溢出桶。\n遍历过程、查找过程 遍历：从0-bucket长度随机一个数字选择bucket进行遍历。所以go的map是无序。如果bucket遍历完，溢出桶不为空，继续遍历溢出桶。 查找：哈希函数对key计算，低8位找到具体的桶。高8位拿来和bucket的top哈希进行比较，如果一致，再比较具体的key,如果相同就返回， 否则再看溢出桶是否为空，不会空对链表进行遍历。如果都没有就返回查找失败。 go的扩容过程 当哈希函数产生过多的哈希碰撞时，就会导致查询效率低下，为了减少哈希碰撞，需要对底层数组的容量扩容或者对数据进行从新排列。 当满足一下任意条件会触发扩容\n当碰撞因子\u0026gt;6.5, 碰撞因子=count(实际元素个数)/2的B次方（bucket数组总的元素长度） 当溢出桶过多时，当B \u0026lt; 15 , 当溢出桶的个数\u0026gt;B次方，触发扩容。当B\u0026gt;15时，overflow超过2的15次方。 为什么是线程不安全的 sync.map使用 sync.map如何实现的 注意事项",
"content": "go的哈希实现 通用哈希实现 哈希表是一个高效的数据结构，通过对key经过哈希函数计算的值和存储数据的数组的长度，两者求余得到在数组插入的位置。高效的查找效率 时间复杂度为O(1)。\n哈希函数 任意长度的输入有固定输出 同一输入会产生同一个输出 输入的细小改变会造成输入的完全不一样 速度快 单项不可逆 go的哈希底层实现 通过底层结构体hmap来实例化map对象，hmap 包含指向[]bucket数组的指针。bucket结构里面会存储真实的数据 以key1key2 val1value2 的形式进行排列，方便内存对齐。头部有top哈希方便bucket内部进行数据定位，底部有指向溢出bucket的指针。 当发生哈希冲突，冲突的数据会存放到溢出bucket链表。\n插入过程 首先用哈希函数对key计算，得到64位数据（64位机器上）。低B位决定数据落入哪个桶。B是log2count，也就是以2为底bucket元素的长度的对数。 高8位决定落入bucket具体的位置。如果发送哈希冲突，就把数据存入溢出桶。\n遍历过程、查找过程 遍历：从0-bucket长度随机一个数字选择bucket进行遍历。所以go的map是无序。如果bucket遍历完，溢出桶不为空，继续遍历溢出桶。 查找：哈希函数对key计算，低8位找到具体的桶。高8位拿来和bucket的top哈希进行比较，如果一致，再比较具体的key,如果相同就返回， 否则再看溢出桶是否为空，不会空对链表进行遍历。如果都没有就返回查找失败。 go的扩容过程 当哈希函数产生过多的哈希碰撞时，就会导致查询效率低下，为了减少哈希碰撞，需要对底层数组的容量扩容或者对数据进行从新排列。 当满足一下任意条件会触发扩容\n当碰撞因子\u0026gt;6.5, 碰撞因子=count(实际元素个数)/2的B次方（bucket数组总的元素长度） 当溢出桶过多时，当B \u0026lt; 15 , 当溢出桶的个数\u0026gt;B次方，触发扩容。当B\u0026gt;15时，overflow超过2的15次方。 为什么是线程不安全的 sync.map使用 sync.map如何实现的 注意事项 ",
"tags":null,
"categories":null
},{
"title":"Http2_grpc",
"permalink": "http://localhost:1313/posts/network/http2_grpc/",
"summary": "http2 http1的弊端 数据以文本传输，十分低效 header头数据很多 每个tcp链接只能发送一次链接 只能单向传递数据，由浏览器发起 加载无法定义顺序 http2 http2针对这些缺点进行了优化\n对数据进行二进制分帧，基于流传输提高了传输效率，还可以进行流量控制，提升安全性和可靠性 对头数据进行了压缩，采用hpack算法对数据进行压缩，提升了传输效率 采用多路复用，每个tcp连接可以发起任意多的传输请求，减少了tcp的三次握手等频繁建立请求 可以实现服务端推送，从单向传输改为双向传输 可以根据页面不同资源的重要程度设置优先级进行加载 通过以上五个方面http2对h1进行了升级，提高了传输效率，增加更多实现的功能，提升了客户端用户体验。 如何使用 反向代理软件如nginx/apache等设置http2选项 如nginx,首先必须支持ssl/tsl证书，再加上listen 443 ssl http2\ngo的net组件自动支持http2,无需手动升级 grpc rpc rpc是远程过程调用，是一种在不同进程或组件上让函数调用如同本地调用一样的技术。有多种实现，比如json-rpc,xrpc(基于xml),gprc google推出，基于protobuf,通过IDL(接口定义)定义同义的方法和参数，使用代码生成工具生成不同语言的代码。\ngrpc也是基于http2,所以他可以利用http2的各种特性，他有google推出，采用protobuf传输。\n他有以下特点：\n基于IDL生成，接口及定义，可以生成多语言，被客户端和服务端共用。 数据传输效率高，基于http2,拥有双向传输、tcp多路复用、二进制数据帧传输、流量控制等特性 常见于微服务当中，可以方便的定义中间件，进行限流、降级等特性 浏览器一次完整的请求过程 服务器会启动进程监听某个端口，当端口监听到请求，进行处理 通过DNS解析域名拿到目标IP,依次通过浏览器、本地缓存查询，没有就往根dns服务器查询。 如果是http协议需要先通过ssl建立安全通道。 建立TCP连接，通过五元组：协议 ip 端口 目标IP 目标端口 进行三次握手，握手完成后开始发送数据 数据进行封装,数据从应用层（报文）-\u0026gt;传输层（报文+端口号）-\u0026gt;网络IP层（数据段+IP）-\u0026gt;数据链路层(数据包+mac主机物理地址-\u0026gt;数据帧)-\u0026gt;物理层(二进制流)这个层次依次进行传输 通过网络层找到目的主机，通过端口号找到主机监听目的端口的程序。应用程序处理请求。 服务器处理响应，完成后，返回给客户端 断开连接、4次挥手，最后一次等待服务器发送完毕数据 参考资料 https://blog.csdn.net/u012914309/article/details/127507726?spm=1001.2014.3001.5501 ",
"content": "http2 http1的弊端 数据以文本传输，十分低效 header头数据很多 每个tcp链接只能发送一次链接 只能单向传递数据，由浏览器发起 加载无法定义顺序 http2 http2针对这些缺点进行了优化\n对数据进行二进制分帧，基于流传输提高了传输效率，还可以进行流量控制，提升安全性和可靠性 对头数据进行了压缩，采用hpack算法对数据进行压缩，提升了传输效率 采用多路复用，每个tcp连接可以发起任意多的传输请求，减少了tcp的三次握手等频繁建立请求 可以实现服务端推送，从单向传输改为双向传输 可以根据页面不同资源的重要程度设置优先级进行加载 通过以上五个方面http2对h1进行了升级，提高了传输效率，增加更多实现的功能，提升了客户端用户体验。 如何使用 反向代理软件如nginx/apache等设置http2选项 如nginx,首先必须支持ssl/tsl证书，再加上listen 443 ssl http2\ngo的net组件自动支持http2,无需手动升级 grpc rpc rpc是远程过程调用，是一种在不同进程或组件上让函数调用如同本地调用一样的技术。有多种实现，比如json-rpc,xrpc(基于xml),gprc google推出，基于protobuf,通过IDL(接口定义)定义同义的方法和参数，使用代码生成工具生成不同语言的代码。\ngrpc也是基于http2,所以他可以利用http2的各种特性，他有google推出，采用protobuf传输。\n他有以下特点：\n基于IDL生成，接口及定义，可以生成多语言，被客户端和服务端共用。 数据传输效率高，基于http2,拥有双向传输、tcp多路复用、二进制数据帧传输、流量控制等特性 常见于微服务当中，可以方便的定义中间件，进行限流、降级等特性 浏览器一次完整的请求过程 服务器会启动进程监听某个端口，当端口监听到请求，进行处理 通过DNS解析域名拿到目标IP,依次通过浏览器、本地缓存查询，没有就往根dns服务器查询。 如果是http协议需要先通过ssl建立安全通道。 建立TCP连接，通过五元组：协议 ip 端口 目标IP 目标端口 进行三次握手，握手完成后开始发送数据 数据进行封装,数据从应用层（报文）-\u0026gt;传输层（报文+端口号）-\u0026gt;网络IP层（数据段+IP）-\u0026gt;数据链路层(数据包+mac主机物理地址-\u0026gt;数据帧)-\u0026gt;物理层(二进制流)这个层次依次进行传输 通过网络层找到目的主机，通过端口号找到主机监听目的端口的程序。应用程序处理请求。 服务器处理响应，完成后，返回给客户端 断开连接、4次挥手，最后一次等待服务器发送完毕数据 参考资料 https://blog.csdn.net/u012914309/article/details/127507726?spm=1001.2014.3001.5501 ",
"tags":null,
"categories":null
},{
"title":"CAP",
"permalink": "http://localhost:1313/posts/architecture/cap/",
"summary": "定义 CAP理论是指分布式当中一致性、可用性以及分区容错性三者不可兼得。我们需要根据实际应用场景做出相应的取舍， 在现实中，一般来说分布式系统中的网络是不可能完全保证可用的，所以就需要在CA和CP中做出选择。\nc一致性(consistency) 同一份数据同一时间在不同的节点看到的结果应该是一致性的\na可用性（availability） 当系统当中某些节点故障仍然可以在一定时间内响应用户请求，也就是说系统在任何时间对于非错请求都能在一定时间做出响应，且不返回错误。\np分区容错性（partition tolerance） 当集群中发生网络分区，因为网络故障导致节点之间不能正常通信，系统仍然正常运行，能够对外提供服务。\n拜占庭将军问题 是指分布式系统中可能有恶意节点对数据一致性造成破坏。如果系统中的节点是f个，为了解决非拜占庭将军问题，至少需要3f+1 个节点。能容忍拜占庭容错的系统一般是高安全性要求的系统，比如区跨链、金融、军事等。\n脑裂 脑裂是指分布式系统中由于网络波动或中断，导致系统被分成多个子系统，子系统在内部选举leader，对外提供服务。这会导致 严重的问题，比如\n数据不一致\t两个分区同时写入同一数据（如账户余额），导致冲突且无法自动合并。 资源冲突\t两个“领导者”同时操作共享资源（如分配同一IP地址、锁定同一文件）。 状态混乱\t客户端可能被不同分区响应矛盾的结果（如A分区说“支付成功”，B分区说“未支付”）。 数据永久丢失\t分区恢复后，冲突写入可能导致部分数据被覆盖或丢弃。 为了防止脑裂，一般分布式一致性协议都会采用多数派原则进行避免，比如五个节点的分布式系统中，需要3个节点的确认才能成为leader,否则会 因为无法选主而停止对外提供服务。\nraft协议 raft协议是分布式系统中多个节点对于某个资源的一致性的达成所采用的一种协议，主要有三个部分：\n主从选择 日志复制 安全性和一致性保证 raft协议是强一致的。还有一些其他的一致性组件比如zookeeper。raft协议提供了强一致性的方案。 zookeeper 实践 常见的使用场景 一些常见的开源软件的使用我们会经常遇到这个场景。拿最常见的redis为例，redis的分布式部署方案有三种，主从、哨兵、cluster。\ngo 简单的实践 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/hashicorp/raft\u0026#34; bolt \u0026#34;github.com/hashicorp/raft-boltdb\u0026#34; ) // 简单的 FSM：提交即打印 type FSM struct{} func (f *FSM) Apply(l *raft.Log) interface{} { fmt.Printf(\u0026#34;Apply: %s\\n\u0026#34;, string(l.Data)) return nil } func (f *FSM) Snapshot() (raft.FSMSnapshot, error) { return \u0026amp;snapshot{}, nil } func (f *FSM) Restore(io.ReadCloser) error { return nil } type snapshot struct{} func (s *snapshot) Persist(sink raft.SnapshotSink) error { return sink.Close() } func (s *snapshot) Release() {} func main() { // 1) 配置 config := raft.DefaultConfig() config.LocalID = raft.ServerID(os.Args[1]) // 节点 ID 来自第一个参数 // 2) 网络传输：TCP addr, err := net.ResolveTCPAddr(\u0026#34;tcp\u0026#34;, os.Args[2]) if err != nil { log.Fatal(err) } transport, err := raft.NewTCPTransport(os.Args[2], addr, 3, 10*time.Second, os.Stdout) if err != nil { log.Fatal(err) } // 3) 日志与快照存储 store, err := bolt.NewBoltStore(fmt.Sprintf(\u0026#34;raft-%s.db\u0026#34;, os.Args[1])) if err != nil { log.Fatal(err) } snapshotStore := raft.NewInmemSnapshotStore() // 4) 创建 Raft 实例 r, err := raft.NewRaft(config, \u0026amp;FSM{}, store, store, snapshotStore, transport) if err != nil { log.Fatal(err) } // 5) Bootstrap 第一个节点 if os.Args[1] == \u0026#34;node1\u0026#34; { cfg := raft.Configuration{ Servers: []raft.Server{ {ID: \u0026#34;node1\u0026#34;, Address: transport.LocalAddr()}, {ID: \u0026#34;node2\u0026#34;, Address: raft.ServerAddress(\u0026#34;127.0.0.1:12002\u0026#34;)}, {ID: \u0026#34;node3\u0026#34;, Address: raft.ServerAddress(\u0026#34;127.0.0.1:12003\u0026#34;)}, }, } r.BootstrapCluster(cfg) } // 6) 简单命令行提交 if config.LocalID == \u0026#34;node1\u0026#34; { go func() { for { time.Sleep(3 * time.Second) f := r.Apply([]byte(\u0026#34;hello raft\u0026#34;), 5*time.Second) if err := f.Error(); err != nil { log.Println(\u0026#34;apply error:\u0026#34;, err) } } }() } select {} // 阻塞 } `\n",
"content": "定义 CAP理论是指分布式当中一致性、可用性以及分区容错性三者不可兼得。我们需要根据实际应用场景做出相应的取舍， 在现实中，一般来说分布式系统中的网络是不可能完全保证可用的，所以就需要在CA和CP中做出选择。\nc一致性(consistency) 同一份数据同一时间在不同的节点看到的结果应该是一致性的\na可用性（availability） 当系统当中某些节点故障仍然可以在一定时间内响应用户请求，也就是说系统在任何时间对于非错请求都能在一定时间做出响应，且不返回错误。\np分区容错性（partition tolerance） 当集群中发生网络分区，因为网络故障导致节点之间不能正常通信，系统仍然正常运行，能够对外提供服务。\n拜占庭将军问题 是指分布式系统中可能有恶意节点对数据一致性造成破坏。如果系统中的节点是f个，为了解决非拜占庭将军问题，至少需要3f+1 个节点。能容忍拜占庭容错的系统一般是高安全性要求的系统，比如区跨链、金融、军事等。\n脑裂 脑裂是指分布式系统中由于网络波动或中断，导致系统被分成多个子系统，子系统在内部选举leader，对外提供服务。这会导致 严重的问题，比如\n数据不一致\t两个分区同时写入同一数据（如账户余额），导致冲突且无法自动合并。 资源冲突\t两个“领导者”同时操作共享资源（如分配同一IP地址、锁定同一文件）。 状态混乱\t客户端可能被不同分区响应矛盾的结果（如A分区说“支付成功”，B分区说“未支付”）。 数据永久丢失\t分区恢复后，冲突写入可能导致部分数据被覆盖或丢弃。 为了防止脑裂，一般分布式一致性协议都会采用多数派原则进行避免，比如五个节点的分布式系统中，需要3个节点的确认才能成为leader,否则会 因为无法选主而停止对外提供服务。\nraft协议 raft协议是分布式系统中多个节点对于某个资源的一致性的达成所采用的一种协议，主要有三个部分：\n主从选择 日志复制 安全性和一致性保证 raft协议是强一致的。还有一些其他的一致性组件比如zookeeper。raft协议提供了强一致性的方案。 zookeeper 实践 常见的使用场景 一些常见的开源软件的使用我们会经常遇到这个场景。拿最常见的redis为例，redis的分布式部署方案有三种，主从、哨兵、cluster。\ngo 简单的实践 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/hashicorp/raft\u0026#34; bolt \u0026#34;github.com/hashicorp/raft-boltdb\u0026#34; ) // 简单的 FSM：提交即打印 type FSM struct{} func (f *FSM) Apply(l *raft.Log) interface{} { fmt.Printf(\u0026#34;Apply: %s\\n\u0026#34;, string(l.Data)) return nil } func (f *FSM) Snapshot() (raft.FSMSnapshot, error) { return \u0026amp;snapshot{}, nil } func (f *FSM) Restore(io.ReadCloser) error { return nil } type snapshot struct{} func (s *snapshot) Persist(sink raft.SnapshotSink) error { return sink.Close() } func (s *snapshot) Release() {} func main() { // 1) 配置 config := raft.DefaultConfig() config.LocalID = raft.ServerID(os.Args[1]) // 节点 ID 来自第一个参数 // 2) 网络传输：TCP addr, err := net.ResolveTCPAddr(\u0026#34;tcp\u0026#34;, os.Args[2]) if err != nil { log.Fatal(err) } transport, err := raft.NewTCPTransport(os.Args[2], addr, 3, 10*time.Second, os.Stdout) if err != nil { log.Fatal(err) } // 3) 日志与快照存储 store, err := bolt.NewBoltStore(fmt.Sprintf(\u0026#34;raft-%s.db\u0026#34;, os.Args[1])) if err != nil { log.Fatal(err) } snapshotStore := raft.NewInmemSnapshotStore() // 4) 创建 Raft 实例 r, err := raft.NewRaft(config, \u0026amp;FSM{}, store, store, snapshotStore, transport) if err != nil { log.Fatal(err) } // 5) Bootstrap 第一个节点 if os.Args[1] == \u0026#34;node1\u0026#34; { cfg := raft.Configuration{ Servers: []raft.Server{ {ID: \u0026#34;node1\u0026#34;, Address: transport.LocalAddr()}, {ID: \u0026#34;node2\u0026#34;, Address: raft.ServerAddress(\u0026#34;127.0.0.1:12002\u0026#34;)}, {ID: \u0026#34;node3\u0026#34;, Address: raft.ServerAddress(\u0026#34;127.0.0.1:12003\u0026#34;)}, }, } r.BootstrapCluster(cfg) } // 6) 简单命令行提交 if config.LocalID == \u0026#34;node1\u0026#34; { go func() { for { time.Sleep(3 * time.Second) f := r.Apply([]byte(\u0026#34;hello raft\u0026#34;), 5*time.Second) if err := f.Error(); err != nil { log.Println(\u0026#34;apply error:\u0026#34;, err) } } }() } select {} // 阻塞 } `\n执行 go run main.go node1 127.0.0.1:12001 执行 go run main.go node1 127.0.0.1:12002 执行 go run main.go node1 127.0.0.1:12003 停掉node1 会重新触发选主 ` 拓展点-状态机 状态机可以看作是ifelse 的封装将强版本，更容易集中管理动作之后状态的变更。\n特点 FSM（如 looplab/fsm） 传统 if-else 结构清晰 明确状态转换图，逻辑集中 逻辑分散，耦合高 易于扩展 增加状态只需配置 增加逻辑可能动很多 if 便于测试 每个状态转换可单测 if else 混杂，不好测 可视化 易转为状态图 很难 条件钩子 before_event/after_event 很方便 手写控制流程 状态合法性控制 内建校验非法状态跳转 自己加判断 使用开源库可以感受一下\npackage workflow import ( \u0026#34;errors\u0026#34; \u0026#34;github.com/looplab/fsm\u0026#34; ) // 所有可能的状态 const ( StateA = \u0026#34;A_PENDING\u0026#34; // 初始由 A 审批 StateCountersign = \u0026#34;COUNTERSIGN_PENDING\u0026#34;// B、C 会签阶段 StateD = \u0026#34;D_PENDING\u0026#34; // D 审批 StateE = \u0026#34;E_PENDING\u0026#34; // E 审批 StateDone = \u0026#34;APPROVED\u0026#34; // 最终审批通过 StateRejected = \u0026#34;REJECTED\u0026#34; // 流程终止（可选） ) // 事件名 const ( EventAApprove = \u0026#34;a_approve\u0026#34; EventACancel = \u0026#34;a_cancel\u0026#34; // A 拒绝或撤回 EventCountersignOK = \u0026#34;countersign_ok\u0026#34; // B、C 会签完成（都同意） EventDCancel = \u0026#34;d_reject\u0026#34; // D 拒绝 EventDApprove = \u0026#34;d_approve\u0026#34; EventECancel = \u0026#34;e_reject\u0026#34; // E 拒绝 EventEApprove = \u0026#34;e_approve\u0026#34; ) // NewWorkflowFSM 创建并返回一个基于当前状态的 FSM func NewWorkflowFSM(currentState string) *fsm.FSM { return fsm.NewFSM( currentState, fsm.Events{ // A 同意，进入会签阶段 {Name: EventAApprove, Src: []string{StateA}, Dst: StateCountersign}, // 会签完成后，进入 D 阶段 {Name: EventCountersignOK, Src: []string{StateCountersign}, Dst: StateD}, // D 同意，进入 E {Name: EventDApprove, Src: []string{StateD}, Dst: StateE}, // E 同意，整个流程完成 {Name: EventEApprove, Src: []string{StateE}, Dst: StateDone}, // 驳回／回退逻辑 {Name: EventDCancel, Src: []string{StateD}, Dst: StateA}, {Name: EventECancel, Src: []string{StateE}, Dst: StateD}, {Name: EventACancel, Src: []string{StateA, StateCountersign}, Dst: StateRejected}, }, fsm.Callbacks{ \u0026#34;enter_state\u0026#34;: func(e *fsm.Event) { // 通用进状态日志；也可针对具体状态做扩展 // fmt.Printf(\u0026#34;Transition: %s -\u0026gt; %s via %s\\n\u0026#34;, e.Src, e.Dst, e.Event) }, }, ) } // 业务层调用示例： // wf := NewWorkflowFSM(dbRecord.State) // if err := wf.Event(EventAApprove); err != nil { … } // dbRecord.State = wf.Current() // save(dbRecord) type ApprovalRecord struct { ID string State string // 存储在 DB：FSM 当前状态 ApprovedByB bool ApprovedByC bool } // B、C 审批 API 调用示例 func ApproveByB(record *ApprovalRecord) error { if record.State != StateCountersign { return errors.New(\u0026#34;不在会签阶段\u0026#34;) } record.ApprovedByB = true return tryFinishCountersign(record) } func ApproveByC(record *ApprovalRecord) error { if record.State != StateCountersign { return errors.New(\u0026#34;不在会签阶段\u0026#34;) } record.ApprovedByC = true return tryFinishCountersign(record) } // 当 B、C 都同意后，触发 FSM 的 countersign_ok func tryFinishCountersign(record *ApprovalRecord) error { if record.ApprovedByB \u0026amp;\u0026amp; record.ApprovedByC { wf := NewWorkflowFSM(record.State) if err := wf.Event(EventCountersignOK); err != nil { return err } record.State = wf.Current() // 持久化 record.State、ApprovedByB/C 到数据库 } return nil } redis 的sentinel 和cluster redis有两种分布式部署方案，分别是sentinel哨兵实现主从架构，哨兵负责监控和主节点下线之后的选主。cluster实现数据分片 和主从切换。\n哨兵只有一个主节点，cluster模式通常有多个主节点。cluster要求至少需要三主三从，cluster如果请求的数据不在当前节点会返回moved和ask,需要支持 cluster的客户端进行重定向，比如go-redis等。\n需要注意的是在分布式部署下，分布式锁都会出现问题，比如redis sentinel模式下主从切换、客户端未感知主从切换导致锁失效。 cluster模式下会出现不能多key操作以及sentinel出现的主备切换客户端无法感知等问题。\n数据分片 数据分片是指将一个大数据集按照某个规则分散成较小的数据集\n注意事项 这个理论提醒我们在分布式系统中需要根据具体的需求做出取舍。 raft协议的只保证写强一致，对于读默认是从leader读就没问题，如果从follower可能会不一致。需要注意 raft协议是在非拜占庭情况下为了达成一致性的一种协议，需要注意这点。 raft协议的组件不适合做分布式锁的实现，因为分布式锁一般对性能要求比较高，而raft需要写日志，同步等比较费时的操作。 redis分布式锁在分布式部署情况下的问题 简单来说需要把所有锁操作限定到一个槽里面，其次可以使用开源的解决方案比如redLock,以及优秀的redis客户端在发生key在其他节点会自动帮助我们 处理move操作\n参考资料 维基百科编者. CAP定理. 维基百科. 最后修订于2023年11月9日. 访问于2025年7月16日. CNBLOG. ZooKeeper 是什么. 维基百科. 最后修订于2020-12-30 10:53. 访问于2025年7月20日. DTM. DTM. 访问于2025年8月20日. ",
"tags":null,
"categories":null
},{
"title":"Socket",
"permalink": "http://localhost:1313/posts/network/socket/",
"summary": "Socket IO模型 常见的IO模型有四种：多进程、多线程、IO复用、协程\n多进程：最原始的一种模式，好处是开发难度小，同一个进程共享内容，缺点是创建和销毁的成本很高。常见的比如php的php-fpm 多线程：相比于多进程开销更小，但是遇到C10K问题还是会出现瓶颈，线程的内存占用通常以M为单位。提高了效率，但是遇到高并发，资源占用还是比较大。常见的比如java的多线程 IO模型: 基于事件的IO处理机制，是单线程模型，通过监听文件句柄socket,注册事件， 当有IO事件发生时，会触发回调函数。由于在单线程模型，开销更小，适合处理高并发。常见的如nodejs、redis。 协程: 协程是态线程，协程的切换开销小，通常以kb为单位，通常一个协程只占用4KB，适合处理高并发。常见的如go语言。 Socket定义 socket是应用层和传输层的一组API接口，用于实现网络通信。 linux当中一切皆文件，操作系统为了统一处理IO模型，将socket也视作文件句柄。\n特性 普通文件 Socket（网络文件） 底层对象 struct inode + struct file struct socket + struct file 操作集 read/write 操作读写磁盘数据 recv/send（也支持 read/write，最终映射到网络收发） 偏移量（offset） 有，指示文件读写位置 无意义，总是以流／报文方式收发 阻塞／非阻塞 可设置阻塞或非阻塞 同样支持阻塞模式和非阻塞模式 I/O 多路复用 支持 select/poll/epoll 完全支持 通过监听文件句柄，结合select/pull/epoll, 可以实现网络编程。\nwebsocket websocket是一种基于http的协议，用于浏览器和服务器之间进行长连接实时通信。一般会通过对http请求升级upgrade，将http协议升级为websocket协议。\n如何使用 tcp连接需要指定五元组：ip、端口、协议、源ip、源端口，同样的socket也需要指定这些参数。 server端的建立过程：\nsocket() bind() listen() accept() close client端的建立过程：\nsocket() connect() accept() close() 代码示例 原始方案，使用net包:\nsever端\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;syscall\u0026#34; ) func check(err error) { if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;错误：\u0026#34;, err) os.Exit(1) } } func main() { // 1. 创建 socket fd, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_STREAM, syscall.IPPROTO_TCP) check(err) defer syscall.Close(fd) // 2. 绑定到本地地址 0.0.0.0:8888 sa := \u0026amp;syscall.SockaddrInet4{Port: 8888} // IP 全 0 表示 INADDR_ANY check(syscall.Bind(fd, sa)) // 3. 开始监听（backlog 128） check(syscall.Listen(fd, 128)) fmt.Println(\u0026#34;raw socket 服务器已启动，端口 8888\u0026#34;) // 4. 接受连接 nfd, rsa, err := syscall.Accept(fd) check(err) fmt.Printf(\u0026#34;接收到客户端：%v\\n\u0026#34;, rsa) defer syscall.Close(nfd) // 5. 全双工：一个 goroutine 从 stdin 发出去，一个 goroutine 从 socket 读进来 go func() { buf := make([]byte, 1024) for { // 从标准输入读 n, err := syscall.Read(syscall.Stdin, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;stdin 读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { _, err = syscall.Write(nfd, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;向客户端写入错误：\u0026#34;, err) return } } } }() // 主 goroutine 负责从 socket 读并写到 stdout buf := make([]byte, 1024) for { n, err := syscall.Read(nfd, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;从客户端读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { // 打印到标准输出 _, err = syscall.Write(syscall.Stdout, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;写到 stdout 错误：\u0026#34;, err) return } } } } client端\n",
"content": "Socket IO模型 常见的IO模型有四种：多进程、多线程、IO复用、协程\n多进程：最原始的一种模式，好处是开发难度小，同一个进程共享内容，缺点是创建和销毁的成本很高。常见的比如php的php-fpm 多线程：相比于多进程开销更小，但是遇到C10K问题还是会出现瓶颈，线程的内存占用通常以M为单位。提高了效率，但是遇到高并发，资源占用还是比较大。常见的比如java的多线程 IO模型: 基于事件的IO处理机制，是单线程模型，通过监听文件句柄socket,注册事件， 当有IO事件发生时，会触发回调函数。由于在单线程模型，开销更小，适合处理高并发。常见的如nodejs、redis。 协程: 协程是态线程，协程的切换开销小，通常以kb为单位，通常一个协程只占用4KB，适合处理高并发。常见的如go语言。 Socket定义 socket是应用层和传输层的一组API接口，用于实现网络通信。 linux当中一切皆文件，操作系统为了统一处理IO模型，将socket也视作文件句柄。\n特性 普通文件 Socket（网络文件） 底层对象 struct inode + struct file struct socket + struct file 操作集 read/write 操作读写磁盘数据 recv/send（也支持 read/write，最终映射到网络收发） 偏移量（offset） 有，指示文件读写位置 无意义，总是以流／报文方式收发 阻塞／非阻塞 可设置阻塞或非阻塞 同样支持阻塞模式和非阻塞模式 I/O 多路复用 支持 select/poll/epoll 完全支持 通过监听文件句柄，结合select/pull/epoll, 可以实现网络编程。\nwebsocket websocket是一种基于http的协议，用于浏览器和服务器之间进行长连接实时通信。一般会通过对http请求升级upgrade，将http协议升级为websocket协议。\n如何使用 tcp连接需要指定五元组：ip、端口、协议、源ip、源端口，同样的socket也需要指定这些参数。 server端的建立过程：\nsocket() bind() listen() accept() close client端的建立过程：\nsocket() connect() accept() close() 代码示例 原始方案，使用net包:\nsever端\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;syscall\u0026#34; ) func check(err error) { if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;错误：\u0026#34;, err) os.Exit(1) } } func main() { // 1. 创建 socket fd, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_STREAM, syscall.IPPROTO_TCP) check(err) defer syscall.Close(fd) // 2. 绑定到本地地址 0.0.0.0:8888 sa := \u0026amp;syscall.SockaddrInet4{Port: 8888} // IP 全 0 表示 INADDR_ANY check(syscall.Bind(fd, sa)) // 3. 开始监听（backlog 128） check(syscall.Listen(fd, 128)) fmt.Println(\u0026#34;raw socket 服务器已启动，端口 8888\u0026#34;) // 4. 接受连接 nfd, rsa, err := syscall.Accept(fd) check(err) fmt.Printf(\u0026#34;接收到客户端：%v\\n\u0026#34;, rsa) defer syscall.Close(nfd) // 5. 全双工：一个 goroutine 从 stdin 发出去，一个 goroutine 从 socket 读进来 go func() { buf := make([]byte, 1024) for { // 从标准输入读 n, err := syscall.Read(syscall.Stdin, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;stdin 读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { _, err = syscall.Write(nfd, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;向客户端写入错误：\u0026#34;, err) return } } } }() // 主 goroutine 负责从 socket 读并写到 stdout buf := make([]byte, 1024) for { n, err := syscall.Read(nfd, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;从客户端读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { // 打印到标准输出 _, err = syscall.Write(syscall.Stdout, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;写到 stdout 错误：\u0026#34;, err) return } } } } client端\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;syscall\u0026#34; ) func check(err error) { if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;错误：\u0026#34;, err) os.Exit(1) } } func main() { // 1. 创建 socket fd, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_STREAM, syscall.IPPROTO_TCP) check(err) defer syscall.Close(fd) // 2. 连接到服务器 127.0.0.1:8888 sa := \u0026amp;syscall.SockaddrInet4{Port: 8888} copy(sa.Addr[:], []byte{127, 0, 0, 1}) check(syscall.Connect(fd, sa)) fmt.Println(\u0026#34;raw socket 已连接到 127.0.0.1:8888\u0026#34;) // 3. 全双工：一个 goroutine 从 stdin 发出去，一个从 socket 读进来 go func() { buf := make([]byte, 1024) for { n, err := syscall.Read(syscall.Stdin, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;stdin 读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { _, err = syscall.Write(fd, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;写到服务器错误：\u0026#34;, err) return } } } }() // 主 goroutine 负责从 socket 读并写到 stdout buf := make([]byte, 1024) for { n, err := syscall.Read(fd, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;从服务器读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { _, err = syscall.Write(syscall.Stdout, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;写到 stdout 错误：\u0026#34;, err) return } } } } 封装成net包，代码更简洁。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; ) func main() { // socket bind listen con, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:8099\u0026#34;) if err != nil { panic(err) } conn, err := con.Accept() go func() { if _, err := io.Copy(conn, os.Stdin); err != nil { fmt.Errorf(\u0026#34;server to client :%w\u0026#34;, err) } }() if _, err := io.Copy(os.Stdout, conn); err != nil { fmt.Errorf(\u0026#34;from client :%w\u0026#34;, err) } } client端\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; ) func main() { // socket connect conn, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:8099\u0026#34;) if err != nil { panic(err) } go func() { if _, err := io.Copy(conn, os.Stdin); err != nil { fmt.Errorf(\u0026#34; to server :%w\u0026#34;, err) } }() if _, err := io.Copy(os.Stdout, conn); err != nil { fmt.Errorf(\u0026#34;from server :%w\u0026#34;, err) } } 注意事项 注意关闭文件句柄 实现高可用，需要处理重试逻辑 ",
"tags":null,
"categories":null
},{
"title":"BFS\u0026\u0026DFS",
"permalink": "http://localhost:1313/posts/datastructalgorithm/bfs_dfs/",
"summary": "树的遍历 深度优先遍历DFS package main import \u0026#34;fmt\u0026#34; func main() { root := \u0026amp;TreeNode{ Val: 1, } root.Left = \u0026amp;TreeNode{Val: 2} root.Right = \u0026amp;TreeNode{Val: 3} root.Right.Left = \u0026amp;TreeNode{Val: 4} root.Left.Left = \u0026amp;TreeNode{Val: 5} list := make([]int, 0) var treeDFS = func(root *TreeNode) {} treeDFS = func(root *TreeNode) { if root == nil { return } list = append(list, root.Val) treeDFS(root.Left) treeDFS(root.Right) } treeDFS(root) fmt.Println(list) //list2 := TreeBFS(root) //fmt.Println(list2) } type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 函数版本\npackage main import \u0026#34;fmt\u0026#34; func main() { root := \u0026amp;TreeNode{ Val: 1, } root.Left = \u0026amp;TreeNode{Val: 2} root.Right = \u0026amp;TreeNode{Val: 3} root.Right.Left = \u0026amp;TreeNode{Val: 4} root.Left.Left = \u0026amp;TreeNode{Val: 5} list := make([]int, 0) TreeDFS(root, \u0026amp;list) fmt.Println(list) //list2 := TreeBFS(root) //fmt.Println(list2) } func TreeDFS(root *TreeNode, list *[]int) { if root == nil { return } *list = append(*list, root.Val) TreeDFS(root.Left, list) TreeDFS(root.Right, list) } type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 广度优先遍历BFS list2 := make([]int, 0) queue := make([]*TreeNode, 0) queue = append(queue, root) for len(queue) \u0026gt; 0 { count := len(queue) for i := 0; i \u0026lt; count; i++ { node := queue[0] queue = queue[1:] list2 = append(list2, node.Val) if node.Left != nil { queue = append(queue, node.Left) } if node.Right != nil { queue = append(queue, node.Right) } } } fmt.Println(list2) 根据先序遍历和中序遍历构造二叉树 package main import \u0026#34;fmt\u0026#34; func main() { // 1 // [1 2 5 3 4] 先序 // [2 5 1 3 4] 中序 // 1 [2 5] [2 5] i = 2 [3 4] // [2 5 3 4] [2 5] // [5 3 4] [5] copyTreeRoot := BuildTree([]int{1, 2, 5, 3, 4}, []int{2, 5, 1, 3, 4}) fmt.Println(copyTreeRoot) list3 := make([]int, 0) TreeDFS(copyTreeRoot, \u0026amp;list3) fmt.Println(\u0026#34;list3:\u0026#34;, list3) //SliceTest() } func BuildTree(first []int, mid []int) *TreeNode { if len(first) == 0 { return nil } root := \u0026amp;TreeNode{Val: first[0]} node := first[0] i := 0 for ; i \u0026lt; len(mid); i++ { if mid[i] == node { break } } root.Left = BuildTree(first[1:i+1], mid[:i]) root.Right = BuildTree(first[i+1:], mid[i+1:]) return root } 图的遍历 深度优先遍历DFS \u0026amp;\u0026amp; 广度优先遍历BFS package main import ( \u0026#34;container/list\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { // 0 // 1 -\u0026gt; 4 -\u0026gt; 5 // 0 2 -\u0026gt; 6 -\u0026gt; 7 // 3 -\u0026gt;^ g := make([][]int, 8) //g = append(g, []int{1, 2, 3} g[0] = []int{1, 2, 3} g[1] = []int{4} g[2] = []int{6} g[3] = []int{6} g[4] = []int{5} g[6] = []int{7} g2 := make(map[int][]int) g2[0] = []int{1, 2, 3} g2[1] = []int{4} g2[2] = []int{6} g2[3] = []int{6} g2[4] = []int{5} g2[6] = []int{7} graphDFS(0, g) //graphBFS(g) fmt.Println(\u0026#34;-----\u0026#34;) graphBFSWithQueue(g2) fmt.Println(\u0026#34;-----\u0026#34;) listC := graphBFSWithC(g2) fmt.Println(listC) } func graphDFS(root int, graph [][]int) { fmt.Println(root) if graph[root] == nil { return } //fmt.Println(root) for i := 0; i \u0026lt; len(graph[root]); i++ { graphDFS(graph[root][i], graph) } return } func graphBFSWithQueue(graph map[int][]int) { queue := make([]int, 0) queue = append(queue, 0) fmt.Println(0) visited := make(map[int]bool) for len(queue) \u0026gt; 0 { node := queue[0] queue = queue[1:] g := graph[node] size := len(g) for i := 0; i \u0026lt; size; i++ { if visited[g[i]] { continue } else { fmt.Println(g[i]) queue = append(queue, g[i]) visited[g[i]] = true } } } } func graphBFSWithC(graph map[int][]int) []int { queue := list.New() order := make([]int, 0) visited := make(map[int]bool) queue.PushBack(0) for queue.Len() \u0026gt; 0 { node := queue.Remove(queue.Front()).(int) order = append(order, node) neighbor := graph[node] size := len(neighbor) for i := 0; i \u0026lt; size; i++ { if visited[neighbor[i]] { continue } else { queue.PushBack(neighbor[i]) visited[neighbor[i]] = true } } } return order } 带权图的最短路径算法 dijkstra 参考 可视化网站. 可视化网站. ",
"content": "树的遍历 深度优先遍历DFS package main import \u0026#34;fmt\u0026#34; func main() { root := \u0026amp;TreeNode{ Val: 1, } root.Left = \u0026amp;TreeNode{Val: 2} root.Right = \u0026amp;TreeNode{Val: 3} root.Right.Left = \u0026amp;TreeNode{Val: 4} root.Left.Left = \u0026amp;TreeNode{Val: 5} list := make([]int, 0) var treeDFS = func(root *TreeNode) {} treeDFS = func(root *TreeNode) { if root == nil { return } list = append(list, root.Val) treeDFS(root.Left) treeDFS(root.Right) } treeDFS(root) fmt.Println(list) //list2 := TreeBFS(root) //fmt.Println(list2) } type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 函数版本\npackage main import \u0026#34;fmt\u0026#34; func main() { root := \u0026amp;TreeNode{ Val: 1, } root.Left = \u0026amp;TreeNode{Val: 2} root.Right = \u0026amp;TreeNode{Val: 3} root.Right.Left = \u0026amp;TreeNode{Val: 4} root.Left.Left = \u0026amp;TreeNode{Val: 5} list := make([]int, 0) TreeDFS(root, \u0026amp;list) fmt.Println(list) //list2 := TreeBFS(root) //fmt.Println(list2) } func TreeDFS(root *TreeNode, list *[]int) { if root == nil { return } *list = append(*list, root.Val) TreeDFS(root.Left, list) TreeDFS(root.Right, list) } type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 广度优先遍历BFS list2 := make([]int, 0) queue := make([]*TreeNode, 0) queue = append(queue, root) for len(queue) \u0026gt; 0 { count := len(queue) for i := 0; i \u0026lt; count; i++ { node := queue[0] queue = queue[1:] list2 = append(list2, node.Val) if node.Left != nil { queue = append(queue, node.Left) } if node.Right != nil { queue = append(queue, node.Right) } } } fmt.Println(list2) 根据先序遍历和中序遍历构造二叉树 package main import \u0026#34;fmt\u0026#34; func main() { // 1 // [1 2 5 3 4] 先序 // [2 5 1 3 4] 中序 // 1 [2 5] [2 5] i = 2 [3 4] // [2 5 3 4] [2 5] // [5 3 4] [5] copyTreeRoot := BuildTree([]int{1, 2, 5, 3, 4}, []int{2, 5, 1, 3, 4}) fmt.Println(copyTreeRoot) list3 := make([]int, 0) TreeDFS(copyTreeRoot, \u0026amp;list3) fmt.Println(\u0026#34;list3:\u0026#34;, list3) //SliceTest() } func BuildTree(first []int, mid []int) *TreeNode { if len(first) == 0 { return nil } root := \u0026amp;TreeNode{Val: first[0]} node := first[0] i := 0 for ; i \u0026lt; len(mid); i++ { if mid[i] == node { break } } root.Left = BuildTree(first[1:i+1], mid[:i]) root.Right = BuildTree(first[i+1:], mid[i+1:]) return root } 图的遍历 深度优先遍历DFS \u0026amp;\u0026amp; 广度优先遍历BFS package main import ( \u0026#34;container/list\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { // 0 // 1 -\u0026gt; 4 -\u0026gt; 5 // 0 2 -\u0026gt; 6 -\u0026gt; 7 // 3 -\u0026gt;^ g := make([][]int, 8) //g = append(g, []int{1, 2, 3} g[0] = []int{1, 2, 3} g[1] = []int{4} g[2] = []int{6} g[3] = []int{6} g[4] = []int{5} g[6] = []int{7} g2 := make(map[int][]int) g2[0] = []int{1, 2, 3} g2[1] = []int{4} g2[2] = []int{6} g2[3] = []int{6} g2[4] = []int{5} g2[6] = []int{7} graphDFS(0, g) //graphBFS(g) fmt.Println(\u0026#34;-----\u0026#34;) graphBFSWithQueue(g2) fmt.Println(\u0026#34;-----\u0026#34;) listC := graphBFSWithC(g2) fmt.Println(listC) } func graphDFS(root int, graph [][]int) { fmt.Println(root) if graph[root] == nil { return } //fmt.Println(root) for i := 0; i \u0026lt; len(graph[root]); i++ { graphDFS(graph[root][i], graph) } return } func graphBFSWithQueue(graph map[int][]int) { queue := make([]int, 0) queue = append(queue, 0) fmt.Println(0) visited := make(map[int]bool) for len(queue) \u0026gt; 0 { node := queue[0] queue = queue[1:] g := graph[node] size := len(g) for i := 0; i \u0026lt; size; i++ { if visited[g[i]] { continue } else { fmt.Println(g[i]) queue = append(queue, g[i]) visited[g[i]] = true } } } } func graphBFSWithC(graph map[int][]int) []int { queue := list.New() order := make([]int, 0) visited := make(map[int]bool) queue.PushBack(0) for queue.Len() \u0026gt; 0 { node := queue.Remove(queue.Front()).(int) order = append(order, node) neighbor := graph[node] size := len(neighbor) for i := 0; i \u0026lt; size; i++ { if visited[neighbor[i]] { continue } else { queue.PushBack(neighbor[i]) visited[neighbor[i]] = true } } } return order } 带权图的最短路径算法 dijkstra 参考 可视化网站. 可视化网站. ",
"tags":["算法","数据结构","BFS","DFS","dijkstra"],
"categories":null
},{
"title":"https原理",
"permalink": "http://localhost:1313/posts/network/https/",
"summary": "定义 http http是超文本传输协议，用于传输网页内容，它基于TCP，所以是可靠性传输。但是它没有解决数据安全性 方面的问题\nhttp安全方面的问题 http没有对数据进行加密，任何人都可以随意读取这些数据，遭成数据的泄密。 其次没有认证，也就是没有办法知道数据来源的可靠性，攻击者可以中间人攻击来伪造数据 数据完整性，任何人可以读取也可以修改数据 https是什么 https是http的安全版本，https基于ssl，ssl基于tls。http+数据加密+认证+数据完整性就是https。\nhttps怎么解决的这些问题 数据加密 加密算法 加密算法分为对称加密和非对称加密，还有一些摘要算法 / 哈希算法，一下是一些常见的加密算法\n类型 示例 是否可逆 说明 对称加密 DES / AES / 3DES ✅ 加密解密用同一密钥 非对称加密 RSA / ECC ✅ 公钥加密，私钥解密 摘要算法 MD5 / SHA256 ❌ 不可逆，用于校验完整性 签名算法 DSA / RSA签名 ❌ 用私钥签名，公钥验签 服务器端生成密钥对，将公钥发送给客户端，客户端使用公钥加密对称加密使用的秘钥，发送给服务器端，服务器端使用私钥解密数据， 得到秘钥，后续通过这个秘钥对数据进行加密解密。\nCA CA（Certificate Authority）是证书颁发机构，它负责签发证书，并管理证书的颁发和吊销。\n为什么需要CA 客户端无法知晓拿到的公钥是由目标服务器颁发的，为了验证证书的合法性，防护中间人攻击，需要CA证书颁发机构签发证书。\n证书生成 首先，服务器管理员会向CA提起证书申请，CA会验证域名的所属权，做法通常是在域名解析加一个特定值。 验证通过后，CA会将服务器的公钥用自己的私钥进行签名，生成证书。并颁发给服务器管理员。\n证书验证过程 客户端发起连接请求，服务器会返回证书，客户端会验证证书的合法性，并获取证书的公钥。 浏览器会在发版的时候将各大CA机构的公钥预制在浏览器中，使用CA的公钥对服务器的证书进行解密，拿到解密的hash值。同时 使用同样的摘要算法对原始内容进行加密，用得到的摘要和解密的摘要对比，如果相等，说明证书是CA颁发的，也就证明 了证书的合法性和完整性。\n更加深入的了解https http是超文本传输协议，它会有以下几个问题：\n窃听风险，由于TCP传输过程中会经过路由器、主机等多个设备，存在被截获数据的风险，泄漏密码等机密信息 篡改风险，被截获的数据可能被恶意篡改，在交易等重要系统会产生非常大的破坏性 身份伪造，无法知晓我们访问的服务端是否是真实的 https通过以下几个方式解决上述问题\n机密性，通过对称加密算法保证 完整性，通过摘要算法保证（md5、sha256） 身份认证，通过CA(证书颁发机构) 为什么https采用了对策加密+非对称加密+CA? 只用对称加密不好解决密钥传输保存的问题，非对称加密由于加解密比较消耗资源，不适合对大量数据进行加解密。\n",
"content": "定义 http http是超文本传输协议，用于传输网页内容，它基于TCP，所以是可靠性传输。但是它没有解决数据安全性 方面的问题\nhttp安全方面的问题 http没有对数据进行加密，任何人都可以随意读取这些数据，遭成数据的泄密。 其次没有认证，也就是没有办法知道数据来源的可靠性，攻击者可以中间人攻击来伪造数据 数据完整性，任何人可以读取也可以修改数据 https是什么 https是http的安全版本，https基于ssl，ssl基于tls。http+数据加密+认证+数据完整性就是https。\nhttps怎么解决的这些问题 数据加密 加密算法 加密算法分为对称加密和非对称加密，还有一些摘要算法 / 哈希算法，一下是一些常见的加密算法\n类型 示例 是否可逆 说明 对称加密 DES / AES / 3DES ✅ 加密解密用同一密钥 非对称加密 RSA / ECC ✅ 公钥加密，私钥解密 摘要算法 MD5 / SHA256 ❌ 不可逆，用于校验完整性 签名算法 DSA / RSA签名 ❌ 用私钥签名，公钥验签 服务器端生成密钥对，将公钥发送给客户端，客户端使用公钥加密对称加密使用的秘钥，发送给服务器端，服务器端使用私钥解密数据， 得到秘钥，后续通过这个秘钥对数据进行加密解密。\nCA CA（Certificate Authority）是证书颁发机构，它负责签发证书，并管理证书的颁发和吊销。\n为什么需要CA 客户端无法知晓拿到的公钥是由目标服务器颁发的，为了验证证书的合法性，防护中间人攻击，需要CA证书颁发机构签发证书。\n证书生成 首先，服务器管理员会向CA提起证书申请，CA会验证域名的所属权，做法通常是在域名解析加一个特定值。 验证通过后，CA会将服务器的公钥用自己的私钥进行签名，生成证书。并颁发给服务器管理员。\n证书验证过程 客户端发起连接请求，服务器会返回证书，客户端会验证证书的合法性，并获取证书的公钥。 浏览器会在发版的时候将各大CA机构的公钥预制在浏览器中，使用CA的公钥对服务器的证书进行解密，拿到解密的hash值。同时 使用同样的摘要算法对原始内容进行加密，用得到的摘要和解密的摘要对比，如果相等，说明证书是CA颁发的，也就证明 了证书的合法性和完整性。\n更加深入的了解https http是超文本传输协议，它会有以下几个问题：\n窃听风险，由于TCP传输过程中会经过路由器、主机等多个设备，存在被截获数据的风险，泄漏密码等机密信息 篡改风险，被截获的数据可能被恶意篡改，在交易等重要系统会产生非常大的破坏性 身份伪造，无法知晓我们访问的服务端是否是真实的 https通过以下几个方式解决上述问题\n机密性，通过对称加密算法保证 完整性，通过摘要算法保证（md5、sha256） 身份认证，通过CA(证书颁发机构) 为什么https采用了对策加密+非对称加密+CA? 只用对称加密不好解决密钥传输保存的问题，非对称加密由于加解密比较消耗资源，不适合对大量数据进行加解密。\ntls的请求建立具体的流程和代码示例 ",
"tags":["计算机网络","https"],
"categories":null
},{
"title":"About Me",
"permalink": "http://localhost:1313/about/me/",
"summary": " 三年PHP经验，2年全栈经验，三年golang经验，持续学习中\u0026hellip; ",
"content": " 三年PHP经验，2年全栈经验，三年golang经验，持续学习中\u0026hellip; ",
"tags":null,
"categories":null
},{
"title":"golang的interface和reflect",
"permalink": "http://localhost:1313/posts/go/interfacereflect/",
"summary": "interface 鸭子类型 如果一个东西，走起来像鸭子，叫起来像鸭子，那么我们认为他就是鸭子。也就是说我们关注对象的行为，而不是对象本身。\ngo里面通过接口来达到鸭子类型的效果。\n多态 多态是指同一个操作（函数、方法），在不通的对象的作用下，会有不同的行为。 一般多态有两种实现方式：\n继承和组合，比如java、c++。 接口的形式 在go里面它没有继承的概念，但是go里面有组合。组合式是一种更灵活的方式。 他可以通过组合和重写来实现继承。在调用结构体的方法的时候，会优先调用最近的结构体的方法。 我们推荐在go里通过接口来实现多态，会更加清晰明了。\ngo的interface 定义 go里面的接口是一种复合数据类型。他的底层有2种实现，eface和iface。\n//eface 结构 type eface struct { tab *typtab data unsafe.Pointer } // iface结构 type iface struct { tab *itab data unsafe.Pointer } go里面的所有数据类型都实现了eface,也就是说可以借助interface来表示他的数据类型。 还可以通过interface来定义方法集合 。\ntype A interface { method() } 可能你会有一个疑问，那go是怎么确定interface 到底应该是使用eface 还是 iface呢？ go是在编译阶段就会确定好interface 使用的eface 还是 iface。后面不会改变。\n如何使用 什么时候会使用interface 通过接口来实现解耦合，比如依赖注入、适配器模式。 不确定传入参数的类型，需要在运行时来确定。 使用方法 接口列表 type animal interface { move() } type dog struct {} func (d dog) move() { fmt.Println(\u0026#34;dog moving\u0026#34;) } type cat struct {} func (c cat) move() { fmt.Println(\u0026#34;cat moving\u0026#34;) } func main() { var a animal a = dog{} a.move() a = cat{} // a是结构可以同意调用 a.move() // 接口注入 call(a) // 不确定具体的参数 vat func1 = func(param any) {} func1 = func(param any) { fmt.Println(\u0026#34;call any\u0026#34;, param) } } func call(a animal) { fmt.Println(\u0026#34;call animal \\n\u0026#34;) a.move() } 需要注意的点和坑 使用接口会让编译器无法确定数据类型，导致无法再编译阶段发现类型错误，引发运行时错误。 使用接口会让程序变得难以阅读和理解。 性能会损失大概一倍 reflect unsafe.pointer go语言unsafe包提供了一些函数，可以获取指针，修改指针，获取指针指向的数据，修改指针指向的数据。 简单来讲，go本身不能操作指针，但是提供了reflect包让我们可以操作指针来获得程序的 性能提升。\n",
"content": "interface 鸭子类型 如果一个东西，走起来像鸭子，叫起来像鸭子，那么我们认为他就是鸭子。也就是说我们关注对象的行为，而不是对象本身。\ngo里面通过接口来达到鸭子类型的效果。\n多态 多态是指同一个操作（函数、方法），在不通的对象的作用下，会有不同的行为。 一般多态有两种实现方式：\n继承和组合，比如java、c++。 接口的形式 在go里面它没有继承的概念，但是go里面有组合。组合式是一种更灵活的方式。 他可以通过组合和重写来实现继承。在调用结构体的方法的时候，会优先调用最近的结构体的方法。 我们推荐在go里通过接口来实现多态，会更加清晰明了。\ngo的interface 定义 go里面的接口是一种复合数据类型。他的底层有2种实现，eface和iface。\n//eface 结构 type eface struct { tab *typtab data unsafe.Pointer } // iface结构 type iface struct { tab *itab data unsafe.Pointer } go里面的所有数据类型都实现了eface,也就是说可以借助interface来表示他的数据类型。 还可以通过interface来定义方法集合 。\ntype A interface { method() } 可能你会有一个疑问，那go是怎么确定interface 到底应该是使用eface 还是 iface呢？ go是在编译阶段就会确定好interface 使用的eface 还是 iface。后面不会改变。\n如何使用 什么时候会使用interface 通过接口来实现解耦合，比如依赖注入、适配器模式。 不确定传入参数的类型，需要在运行时来确定。 使用方法 接口列表 type animal interface { move() } type dog struct {} func (d dog) move() { fmt.Println(\u0026#34;dog moving\u0026#34;) } type cat struct {} func (c cat) move() { fmt.Println(\u0026#34;cat moving\u0026#34;) } func main() { var a animal a = dog{} a.move() a = cat{} // a是结构可以同意调用 a.move() // 接口注入 call(a) // 不确定具体的参数 vat func1 = func(param any) {} func1 = func(param any) { fmt.Println(\u0026#34;call any\u0026#34;, param) } } func call(a animal) { fmt.Println(\u0026#34;call animal \\n\u0026#34;) a.move() } 需要注意的点和坑 使用接口会让编译器无法确定数据类型，导致无法再编译阶段发现类型错误，引发运行时错误。 使用接口会让程序变得难以阅读和理解。 性能会损失大概一倍 reflect unsafe.pointer go语言unsafe包提供了一些函数，可以获取指针，修改指针，获取指针指向的数据，修改指针指向的数据。 简单来讲，go本身不能操作指针，但是提供了reflect包让我们可以操作指针来获得程序的 性能提升。\n定义 在计算机领域，反射（Reflection）是指程序在运行时能够检查自身，并获取其内部信息。可以修改数据，调用方法的 一种能力。 go语言提供了一种在运行时能够获取数据本身的状态，数据，和调用方法的能力，在编译阶段 是不知道具体的类型的，需要在运行时确定。\n使用 常见使用场景 函数参数的动态传入，通过reflect获取参数的类型 动态修改切片，map，结构体 动态创建函数 GORM,通过反射获取结构体的tag来构建数据的sql语句 使用方法 reflect.ValueOf(a) reflect.TypeOf((a) 对指针解引用 reflect.ValueOf(a).Elem() 获取指针类型 reflect.TypeOf(a).Elem() 获取tag reflect.TypeOf(a).Elem().Field(0).Tag.Get(\u0026#34;json\u0026#34;) 获取字段 reflect.TypeOf(a).Elem().Field(0) 动态创建函数 func1 := reflect.MakeFunc(reflect.TypeOf(func(param any) {}), func(args []reflect.Value) []reflect.Value {}) // 动态调用函数 func1.Call([]reflect.Value{reflect.ValueOf(param)}) 需要注意的点和坑 使用反射会损失性能 使用反射会改变代码的可读性 编译器不能检查数据类型，会引发运行时错误 ",
"tags":["go","interface","reflect"],
"categories":null
}]