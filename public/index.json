[{
"title":"如何判断网络状况",
"permalink": "http://localhost:1313/posts/scenario/%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E7%BD%91%E7%BB%9C%E7%8A%B6%E5%86%B5/",
"summary": "",
"content": "",
"tags":null,
"categories":null
},{
"title":"Sql调优",
"permalink": "http://localhost:1313/posts/scenario/sql%E8%B0%83%E4%BC%98/",
"summary": "",
"content": "",
"tags":null,
"categories":null
},{
"title":"Link_合并升序链表",
"permalink": "http://localhost:1313/posts/algorithm/link_%E5%90%88%E5%B9%B6%E5%8D%87%E5%BA%8F%E9%93%BE%E8%A1%A8/",
"summary": "package main import \u0026#34;fmt\u0026#34; func main() { //两个升序链表合并一个新的升序链表 link1 := NewLink() link1.head.next = \u0026amp;node{ value: 1, next: \u0026amp;node{next: \u0026amp;node{ value: 4, }, value: 3}, } link2 := NewLink() link2.head.next = \u0026amp;node{ value: 2, next: \u0026amp;node{next: \u0026amp;node{ value: 6, }, value: 5}, } newLink := mergerSortLink(link1, link2) fmt.Println(newLink) head := newLink.head.next for head != nil { fmt.Println(head.value) head = head.next } } func mergerSortLink(link1, link2 *Link) *Link { // 插入 newNode := \u0026amp;node{} newLink := \u0026amp;Link{ head: newNode, } head1 := link1.head.next head2 := link2.head.next for head1 != nil \u0026amp;\u0026amp; head2 != nil { if head1.value \u0026lt; head2.value { newNode.next = head1 newNode = head1 head1 = head1.next } else { newNode.next = head2 newNode = head2 head2 = head2.next } } // if head1 != nil { newNode.next = head1 } if head2 != nil { newNode.next = head2 } return newLink } type Link struct { head *node } type node struct { value int next *node } func NewLink() *Link { return \u0026amp;Link{ head: \u0026amp;node{}, } } ``` ",
"content": "package main import \u0026#34;fmt\u0026#34; func main() { //两个升序链表合并一个新的升序链表 link1 := NewLink() link1.head.next = \u0026amp;node{ value: 1, next: \u0026amp;node{next: \u0026amp;node{ value: 4, }, value: 3}, } link2 := NewLink() link2.head.next = \u0026amp;node{ value: 2, next: \u0026amp;node{next: \u0026amp;node{ value: 6, }, value: 5}, } newLink := mergerSortLink(link1, link2) fmt.Println(newLink) head := newLink.head.next for head != nil { fmt.Println(head.value) head = head.next } } func mergerSortLink(link1, link2 *Link) *Link { // 插入 newNode := \u0026amp;node{} newLink := \u0026amp;Link{ head: newNode, } head1 := link1.head.next head2 := link2.head.next for head1 != nil \u0026amp;\u0026amp; head2 != nil { if head1.value \u0026lt; head2.value { newNode.next = head1 newNode = head1 head1 = head1.next } else { newNode.next = head2 newNode = head2 head2 = head2.next } } // if head1 != nil { newNode.next = head1 } if head2 != nil { newNode.next = head2 } return newLink } type Link struct { head *node } type node struct { value int next *node } func NewLink() *Link { return \u0026amp;Link{ head: \u0026amp;node{}, } } ``` ",
"tags":null,
"categories":null
},{
"title":"Str_滑动窗口",
"permalink": "http://localhost:1313/posts/algorithm/str_%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/",
"summary": "给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { //给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。 //输入: s = \u0026#34;abcabcbb\u0026#34; //输出: 3 //解释: 因为无重复字符的最长子串是 \u0026#34;abc\u0026#34;，所以其长度为 3。 s := \u0026#34;abcabcbb\u0026#34; //s := \u0026#34;abcbcbb\u0026#34; res := getSubStr(s) fmt.Println(res) } func getSubStr(s string) int { res, left := 0, 0 check := make(map[byte]int) n := len(s) for right := 0; right \u0026lt; n; right++ { if index, ok := check[s[right]]; ok \u0026amp;\u0026amp; index \u0026gt;= left { left = index + 1 } check[s[right]] = right res = Max(res, right-left+1) } return res } func Max(a, b int) int { if a \u0026gt; b { return a } return b } ``` ",
"content": "给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { //给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。 //输入: s = \u0026#34;abcabcbb\u0026#34; //输出: 3 //解释: 因为无重复字符的最长子串是 \u0026#34;abc\u0026#34;，所以其长度为 3。 s := \u0026#34;abcabcbb\u0026#34; //s := \u0026#34;abcbcbb\u0026#34; res := getSubStr(s) fmt.Println(res) } func getSubStr(s string) int { res, left := 0, 0 check := make(map[byte]int) n := len(s) for right := 0; right \u0026lt; n; right++ { if index, ok := check[s[right]]; ok \u0026amp;\u0026amp; index \u0026gt;= left { left = index + 1 } check[s[right]] = right res = Max(res, right-left+1) } return res } func Max(a, b int) int { if a \u0026gt; b { return a } return b } ``` ",
"tags":null,
"categories":null
},{
"title":"GMP",
"permalink": "http://localhost:1313/posts/go/gmp/",
"summary": "什么是GMP 概念 GMP是go的协程调度模型，go代码的程序有运行时runtime进行调度，go可以通过运行时进行内存的分配，通过channel进行协程间通信，通过go关键字创建协程。 而GMP正是协程调度的核心。\nG代表go的goroutine,协程是用户态的轻量级线程，创建销毁的成本非常小，只需要大约2kb，而线程则需要2m,所以go的协程非常适合处理IO密集型任务。 M代表系统级线程，go的协程并不真正执行代码，它需要将协程调度到和内核绑定的系统级线程上进行实际的运行。 P代表逻辑处理单元，包含了待运行的协程和一些上下文。p又可以分为本地队列和全局队列。 调度过程 go的程序通过runtime创建协程\n将协程放到本地队列p p和m绑定 m在操作系统上执行 核心调度时机 用户态态阻塞，比如channel、mutex，这个时候p会和m脱离，p会放入到待运行队列，或者重新绑定其他m 内核态阻塞，比如发生了系统调用，io操作等，m会被标记成阻塞状态，go会重新创建后者唤醒一个m，保证并发度 其他核心概念 ruetime.GOMAXPROCS() 优化手段",
"content": "什么是GMP 概念 GMP是go的协程调度模型，go代码的程序有运行时runtime进行调度，go可以通过运行时进行内存的分配，通过channel进行协程间通信，通过go关键字创建协程。 而GMP正是协程调度的核心。\nG代表go的goroutine,协程是用户态的轻量级线程，创建销毁的成本非常小，只需要大约2kb，而线程则需要2m,所以go的协程非常适合处理IO密集型任务。 M代表系统级线程，go的协程并不真正执行代码，它需要将协程调度到和内核绑定的系统级线程上进行实际的运行。 P代表逻辑处理单元，包含了待运行的协程和一些上下文。p又可以分为本地队列和全局队列。 调度过程 go的程序通过runtime创建协程\n将协程放到本地队列p p和m绑定 m在操作系统上执行 核心调度时机 用户态态阻塞，比如channel、mutex，这个时候p会和m脱离，p会放入到待运行队列，或者重新绑定其他m 内核态阻塞，比如发生了系统调用，io操作等，m会被标记成阻塞状态，go会重新创建后者唤醒一个m，保证并发度 其他核心概念 ruetime.GOMAXPROCS() 优化手段 ",
"tags":null,
"categories":null
},{
"title":"如何保证数据录入不混乱",
"permalink": "http://localhost:1313/posts/scenario/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E5%BD%95%E5%85%A5%E4%B8%8D%E6%B7%B7%E4%B9%B1/",
"summary": "如何保证数据录入不混乱 数据并发 可以采用go的sync.mutex/数据库的锁/分布式锁来实现并发访问控制，在单机服务下，可以采用go的互斥锁保护临界资源。在分布式场景下，并发量不高的情况下，采用 数据库的行锁，行锁从逻辑上可以分为悲观锁和乐观锁，悲观锁通过直接for update 语句加互斥锁，在本次事务未提交之前，其他事务都不能读写当前的临界资源。乐观锁可以使用版本号， 先查询版本号，在写入数据的时候再次验证版本号，如果相同再更新。\n",
"content": "如何保证数据录入不混乱 数据并发 可以采用go的sync.mutex/数据库的锁/分布式锁来实现并发访问控制，在单机服务下，可以采用go的互斥锁保护临界资源。在分布式场景下，并发量不高的情况下，采用 数据库的行锁，行锁从逻辑上可以分为悲观锁和乐观锁，悲观锁通过直接for update 语句加互斥锁，在本次事务未提交之前，其他事务都不能读写当前的临界资源。乐观锁可以使用版本号， 先查询版本号，在写入数据的时候再次验证版本号，如果相同再更新。\n",
"tags":null,
"categories":null
},{
"title":"一次mysql的执行过程",
"permalink": "http://localhost:1313/posts/database/%E4%B8%80%E6%AC%A1mysql%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/",
"summary": "一次mysql的执行过程 连接器 客户端需要先和服务器连接，检查帐号密码、权限，建立连接。 分析器 将客户端发送过来的sql语句进行分析，分为词法分析，将关键词提取出来，进行语法分析，检查是否有 语法错误，最后对语句进行语义分析。 优化器 根据用户的sql 执行查询计划，选择成本和时间最小的方案执行。 执行器 向存储引擎发送请求，执行具体的sql执行 ",
"content": "一次mysql的执行过程 连接器 客户端需要先和服务器连接，检查帐号密码、权限，建立连接。 分析器 将客户端发送过来的sql语句进行分析，分为词法分析，将关键词提取出来，进行语法分析，检查是否有 语法错误，最后对语句进行语义分析。 优化器 根据用户的sql 执行查询计划，选择成本和时间最小的方案执行。 执行器 向存储引擎发送请求，执行具体的sql执行 ",
"tags":null,
"categories":null
},{
"title":"Mysql_分组统计排序",
"permalink": "http://localhost:1313/posts/interview_code/mysql_%E5%88%86%E7%BB%84%E7%BB%9F%E8%AE%A1%E6%8E%92%E5%BA%8F/",
"summary": "记录一些面试遇到的题目\nCREATE TABLE students ( id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(50), age INT, sex CHAR(1), class VARCHAR(50) ); INSERT INTO students (name, age, sex, class) VALUES (\u0026#39;沉默王二\u0026#39;, 18, \u0026#39;女\u0026#39;, \u0026#39;三年二班\u0026#39;), (\u0026#39;沉默王一\u0026#39;, 20, \u0026#39;男\u0026#39;, \u0026#39;三年二班\u0026#39;), (\u0026#39;沉默王三\u0026#39;, 19, \u0026#39;男\u0026#39;, \u0026#39;三年三班\u0026#39;), (\u0026#39;沉默王四\u0026#39;, 17, \u0026#39;男\u0026#39;, \u0026#39;三年三班\u0026#39;), (\u0026#39;沉默王五\u0026#39;, 20, \u0026#39;女\u0026#39;, \u0026#39;三年四班\u0026#39;), (\u0026#39;沉默王六\u0026#39;, 21, \u0026#39;男\u0026#39;, \u0026#39;三年四班\u0026#39;), (\u0026#39;沉默王七\u0026#39;, 18, \u0026#39;女\u0026#39;, \u0026#39;三年四班\u0026#39;); select * from students s1 join ( select id, row_number() over (partition by class order by age) as rank_num from students ) s2 on s2.id = s1.id where s2.rank_num \u0026lt;= 2 ",
"content": "记录一些面试遇到的题目\nCREATE TABLE students ( id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(50), age INT, sex CHAR(1), class VARCHAR(50) ); INSERT INTO students (name, age, sex, class) VALUES (\u0026#39;沉默王二\u0026#39;, 18, \u0026#39;女\u0026#39;, \u0026#39;三年二班\u0026#39;), (\u0026#39;沉默王一\u0026#39;, 20, \u0026#39;男\u0026#39;, \u0026#39;三年二班\u0026#39;), (\u0026#39;沉默王三\u0026#39;, 19, \u0026#39;男\u0026#39;, \u0026#39;三年三班\u0026#39;), (\u0026#39;沉默王四\u0026#39;, 17, \u0026#39;男\u0026#39;, \u0026#39;三年三班\u0026#39;), (\u0026#39;沉默王五\u0026#39;, 20, \u0026#39;女\u0026#39;, \u0026#39;三年四班\u0026#39;), (\u0026#39;沉默王六\u0026#39;, 21, \u0026#39;男\u0026#39;, \u0026#39;三年四班\u0026#39;), (\u0026#39;沉默王七\u0026#39;, 18, \u0026#39;女\u0026#39;, \u0026#39;三年四班\u0026#39;); select * from students s1 join ( select id, row_number() over (partition by class order by age) as rank_num from students ) s2 on s2.id = s1.id where s2.rank_num \u0026lt;= 2 ",
"tags":null,
"categories":null
},{
"title":"数组交集",
"permalink": "http://localhost:1313/posts/algorithm/slice_%E6%95%B0%E7%BB%84%E4%BA%A4%E9%9B%86/",
"summary": " package main import \u0026#34;fmt\u0026#34; func main() { //4.1 实现一个函数，可以计算返回多个切片元素交集，如入参[1,2,3],[2,3,4] 返回 [2,3] arrays := make([][]int, 0) arrays = append(arrays, []int{1, 2, 3}) arrays = append(arrays, []int{2, 3, 4}) arrays = append(arrays, []int{3, 4}) res := calMerge(arrays...) fmt.Println(res) } func calMerge(arrays ...[]int) []int { // 数组先去重，就不实现了 check := make(map[int]int) for i := 0; i \u0026lt; len(arrays); i++ { for j := 0; j \u0026lt; len(arrays[i]); j++ { check[arrays[i][j]] += 1 } } newArray := make([]int, 0) for k, val := range check { if val \u0026gt;= len(arrays) { newArray = append(newArray, k) } } return newArray } ",
"content": " package main import \u0026#34;fmt\u0026#34; func main() { //4.1 实现一个函数，可以计算返回多个切片元素交集，如入参[1,2,3],[2,3,4] 返回 [2,3] arrays := make([][]int, 0) arrays = append(arrays, []int{1, 2, 3}) arrays = append(arrays, []int{2, 3, 4}) arrays = append(arrays, []int{3, 4}) res := calMerge(arrays...) fmt.Println(res) } func calMerge(arrays ...[]int) []int { // 数组先去重，就不实现了 check := make(map[int]int) for i := 0; i \u0026lt; len(arrays); i++ { for j := 0; j \u0026lt; len(arrays[i]); j++ { check[arrays[i][j]] += 1 } } newArray := make([]int, 0) for k, val := range check { if val \u0026gt;= len(arrays) { newArray = append(newArray, k) } } return newArray } ",
"tags":null,
"categories":null
},{
"title":"分布式锁的实现",
"permalink": "http://localhost:1313/posts/scenario/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0/",
"summary": "分布式锁的实现 分布式锁需要满足几个要点\n高性能、互斥，redis高性能，处理模型单线程天然支持互斥 原子性操作（主要是redis），高并发情况下，需要保证加锁、删除、自动续期的并发安全，所以需要原子性保证 安全释放锁、锁的删除，在并发情况下，可能出现A执行任务过长，锁已经自动过期了，B拿到锁在执行了，A执行完毕，释放锁，如果不进行锁的Val判断，会导致锁的异常释放。 自动过期/自动续期,使用set nx px 设置过期时间，使用看门狗机制实现自动续期，在释放锁的时候，使用context,cancel协程。 可重入 基于redis的实现 cache.go\npackage cache import ( \u0026#34;context\u0026#34; \u0026#34;github.com/redis/go-redis/v9\u0026#34; \u0026#34;time\u0026#34; ) type Cache interface { // 通用封装 需要解决 //（1）缓存三大问题 a 穿透 b 击穿 c 缓存雪崩 //（2）缓存不一致的问题 //（3）分布式锁 // 设置通用前缀 app_name , 数据类型 data, 模块名字 ， SetPrefix(prefix ...string) Cache Set(ctx context.Context, key, value string, short bool) error Get(ctx context.Context, key string, handler func(context.Context) (string, error)) (string, error) // 增加 删除 修改的时候调用 Flush(ctx context.Context, handler func(context.Context) error) error FlushWithConsistency(ctx context.Context, handler func(context.Context) error) error // 以下是简单封装 SimpleSet(ctx context.Context, key string, data any, expiration time.Duration) (err error) SimpleGet(ctx context.Context, key string) (data string, err error) SimpleIncr(ctx context.Context, key string) (count int64, err error) SimpleDel(ctx context.Context, keys ...string) (deletedCount int64, err error) Pipelined(ctx context.Context, callback func(redis.Pipeliner) error) (cmder []redis.Cmder, err error) // 批量删除 key 比如 app_name:* DeleteKeysByPattern(ctx context.Context, pattern string) (err error) // 集合操作 SAdd(ctx context.Context, key string, members ...string) (err error) SMembers(ctx context.Context, key string) (members []string, err error) // 过期集合 设置获取 AddMemberWithTTL(ctx context.Context, setKey, member string, ttl time.Duration) error GetValidMembers(ctx context.Context, setKey string) ([]string, error) RemoveMember(ctx context.Context, setKey string, members ...string) (int64, error) // 分布式加解锁 DistributedLock(ctx context.Context, key string, ttl time.Duration) error DistributedUnlock(ctx context.Context, key string) error } redis.go\n",
"content": "分布式锁的实现 分布式锁需要满足几个要点\n高性能、互斥，redis高性能，处理模型单线程天然支持互斥 原子性操作（主要是redis），高并发情况下，需要保证加锁、删除、自动续期的并发安全，所以需要原子性保证 安全释放锁、锁的删除，在并发情况下，可能出现A执行任务过长，锁已经自动过期了，B拿到锁在执行了，A执行完毕，释放锁，如果不进行锁的Val判断，会导致锁的异常释放。 自动过期/自动续期,使用set nx px 设置过期时间，使用看门狗机制实现自动续期，在释放锁的时候，使用context,cancel协程。 可重入 基于redis的实现 cache.go\npackage cache import ( \u0026#34;context\u0026#34; \u0026#34;github.com/redis/go-redis/v9\u0026#34; \u0026#34;time\u0026#34; ) type Cache interface { // 通用封装 需要解决 //（1）缓存三大问题 a 穿透 b 击穿 c 缓存雪崩 //（2）缓存不一致的问题 //（3）分布式锁 // 设置通用前缀 app_name , 数据类型 data, 模块名字 ， SetPrefix(prefix ...string) Cache Set(ctx context.Context, key, value string, short bool) error Get(ctx context.Context, key string, handler func(context.Context) (string, error)) (string, error) // 增加 删除 修改的时候调用 Flush(ctx context.Context, handler func(context.Context) error) error FlushWithConsistency(ctx context.Context, handler func(context.Context) error) error // 以下是简单封装 SimpleSet(ctx context.Context, key string, data any, expiration time.Duration) (err error) SimpleGet(ctx context.Context, key string) (data string, err error) SimpleIncr(ctx context.Context, key string) (count int64, err error) SimpleDel(ctx context.Context, keys ...string) (deletedCount int64, err error) Pipelined(ctx context.Context, callback func(redis.Pipeliner) error) (cmder []redis.Cmder, err error) // 批量删除 key 比如 app_name:* DeleteKeysByPattern(ctx context.Context, pattern string) (err error) // 集合操作 SAdd(ctx context.Context, key string, members ...string) (err error) SMembers(ctx context.Context, key string) (members []string, err error) // 过期集合 设置获取 AddMemberWithTTL(ctx context.Context, setKey, member string, ttl time.Duration) error GetValidMembers(ctx context.Context, setKey string) ([]string, error) RemoveMember(ctx context.Context, setKey string, members ...string) (int64, error) // 分布式加解锁 DistributedLock(ctx context.Context, key string, ttl time.Duration) error DistributedUnlock(ctx context.Context, key string) error } redis.go\npackage cache import ( \u0026#34;codeup.aliyun.com/619b3cb12f595dbd1b9b0b3e/go/common.git/log\u0026#34; \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/go-kratos/kratos/v2/errors\u0026#34; \u0026#34;github.com/redis/go-redis/v9\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) type RedisCache struct { Redis redis.UniversalClient Prefix []string RootPrefix []string Locks map[string]*Lock // key: 业务锁名, value: Lock实例 } func (c *RedisCache) DistributedLock(ctx context.Context, key string, ttl time.Duration) error { if c.Locks == nil { c.Locks = make(map[string]*Lock) } lockKey := c.getKey(key) lock := NewLock(c.Redis, lockKey) err := lock.Lock(ctx, ttl) if err != nil { return err } c.Locks[lockKey] = lock return nil } func (c *RedisCache) DistributedUnlock(ctx context.Context, key string) error { if c.Locks == nil { return fmt.Errorf(\u0026#34;no lock map found\u0026#34;) } lockKey := c.getKey(key) lock, ok := c.Locks[lockKey] if !ok || lock == nil { return fmt.Errorf(\u0026#34;no lock found for key: %s\u0026#34;, lockKey) } err := lock.UnLock(ctx) if err != nil { return err } delete(c.Locks, lockKey) return nil } func (c *RedisCache) SetPrefix(prefix ...string) Cache { return \u0026amp;RedisCache{ Redis: c.Redis, Prefix: prefix, RootPrefix: c.RootPrefix, Locks: c.Locks, } } func (c *RedisCache) Set(ctx context.Context, key, value string, short bool) error { // 默认五分钟 如果空数据 设置 1 分钟 // set random expiration avoid a large number of keys expire at the same time seconds := rand.New(rand.NewSource(time.Now().UnixNano())).Int63n(300) + 300 if short { // 防止缓存穿透 // if record not found, set a short expiration seconds = 60 + rand.New(rand.NewSource(time.Now().UnixNano())).Int63n(60) } return c.Redis.Set(ctx, c.getKey(key), value, time.Duration(seconds)*time.Second).Err() } func (c *RedisCache) Get(ctx context.Context, key string, handler func(context.Context) (string, error)) (result string, err error) { // 分布式锁解决 缓存击穿 currentKey := c.getKey(key) result, err = c.Redis.Get(ctx, currentKey).Result() if err == nil { return } // 加锁 去 数据库 读 数据 lock := NewLock(c.Redis, currentKey) err = c.GetLock(ctx, lock, currentKey) if err != nil { return \u0026#34;\u0026#34;, err } defer lock.UnLock(ctx) // 双重检测 result, err = c.Redis.Get(ctx, currentKey).Result() if err == nil { return } // result, err = handler(ctx) if err != nil { return \u0026#34;\u0026#34;, err } // 数据回填 if result == \u0026#34;\u0026#34; { err = c.Set(ctx, key, result, true) } else { err = c.Set(ctx, key, result, false) } if err != nil { return \u0026#34;\u0026#34;, err } return } func (c *RedisCache) GetLock(ctx context.Context, lock *Lock, key string) (err error) { // 自旋 1s retry := 0 for retry \u0026lt; 20 { err = lock.Lock(ctx, 5*time.Second) if err == nil { return } time.Sleep(50 * time.Millisecond) retry++ if err := ctx.Err(); err != nil { return err } } return errors.Errorf(500, \u0026#34;not get lock\u0026#34;, \u0026#34;\u0026#34;) } func (c *RedisCache) Flush(ctx context.Context, handler func(context.Context) error) error { err := c.DeleteKeysByPattern(ctx, c.getKey(\u0026#34;*\u0026#34;)) if err != nil { return err } return handler(ctx) } func (c *RedisCache) getKey(key string) string { temp := append(c.RootPrefix, c.Prefix...) if key != \u0026#34;\u0026#34; { temp = append(temp, key) } return strings.Join(temp, \u0026#34;:\u0026#34;) } // FlushWithConsistency 缓存双删 func (c *RedisCache) FlushWithConsistency(ctx context.Context, handler func(context.Context) error) (err error) { err = c.DeleteKeysByPattern(ctx, c.getKey(\u0026#34;*\u0026#34;)) if err != nil { return err } err = handler(ctx) if err != nil { return err } go func() { ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second) defer cancel() time.Sleep(1 * time.Second) err = c.DeleteKeysByPattern(ctx, c.getKey(\u0026#34;*\u0026#34;)) if err != nil { log.Info(err.Error()) } }() return } func NewRedisCache(redis redis.UniversalClient, prefix string) Cache { return \u0026amp;RedisCache{ Redis: redis, Prefix: []string{prefix}, RootPrefix: []string{prefix}, } } func (c *RedisCache) Pipelined(ctx context.Context, callback func(redis.Pipeliner) error) (cmder []redis.Cmder, err error) { return c.Redis.Pipelined(ctx, callback) } func (c *RedisCache) DeleteKeysByPattern(ctx context.Context, pattern string) (err error) { iter := c.Redis.Scan(ctx, 0, pattern, 0).Iterator() // 删除计数器 deleted := 0 // 分批删除键以避免一次删除太多键 var keys []string pipe := c.Redis.Pipeline() for iter.Next(ctx) { keys = append(keys, iter.Val()) // 每积累100个键执行一次删除操作 if len(keys) \u0026gt;= 100 { for _, k := range keys { pipe.Unlink(ctx, k) } _, err := pipe.Exec(ctx) if err != nil { return err } deleted += len(keys) keys = []string{} } } // 删除剩余的键 if len(keys) \u0026gt; 0 { for _, k := range keys { pipe.Unlink(ctx, k) } _, err := pipe.Exec(ctx) if err != nil { return err } deleted += len(keys) } // 检查迭代过程中是否有错误 if err := iter.Err(); err != nil { return err } log.Info(\u0026#34;成功删除 %d 个匹配 \u0026#39;%s\u0026#39; 的键\\n\u0026#34;, deleted, pattern) return nil } func (c *RedisCache) RemoveMember(ctx context.Context, setKey string, members ...string) (int64, error) { // 返回成功删除的成员数量 return c.Redis.ZRem(ctx, setKey, members).Result() } func (c *RedisCache) AddMemberWithTTL(ctx context.Context, setKey, member string, ttl time.Duration) error { expireTs := time.Now().Add(ttl).Unix() // 过期时间戳（秒） // ZADD myzset expireTs member if err := c.Redis.ZAdd(ctx, setKey, redis.Z{ Score: float64(expireTs), Member: member, }).Err(); err != nil { return err } return nil } func (c *RedisCache) GetValidMembers(ctx context.Context, setKey string) ([]string, error) { now := time.Now().Unix() // 只取 score \u0026gt; now 的成员 members, err := c.Redis.ZRangeByScore(ctx, setKey, \u0026amp;redis.ZRangeBy{ Min: fmt.Sprintf(\u0026#34;(%d\u0026#34;, now), // (now 表示严格大于 now Max: \u0026#34;+inf\u0026#34;, }).Result() if err != nil { return nil, err } go func() { subCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() err := c.CleanupExpired(subCtx, setKey) if err != nil { log.Info(err) } }() return members, nil } func (c *RedisCache) CleanupExpired(ctx context.Context, setKey string) error { now := time.Now().Unix() // 删除所有 score ≤ now 的成员 _, err := c.Redis.ZRemRangeByScore(ctx, setKey, \u0026#34;-inf\u0026#34;, fmt.Sprintf(\u0026#34;%d\u0026#34;, now)).Result() return err } func (c *RedisCache) SAdd(ctx context.Context, key string, members ...string) (err error) { return c.Redis.SAdd(ctx, key, members).Err() } func (c *RedisCache) SMembers(ctx context.Context, key string) (members []string, err error) { return c.Redis.SMembers(ctx, key).Result() } func (c *RedisCache) SimpleDel(ctx context.Context, keys ...string) (deletedCount int64, err error) { // 7. Del: 删除键 return c.Redis.Del(ctx, keys...).Result() } func (c *RedisCache) SimpleIncr(ctx context.Context, key string) (count int64, err error) { // 6. Incr: 对数字进行原子递增 return c.Redis.Incr(ctx, key).Result() } func (c *RedisCache) SimpleSet(ctx context.Context, key string, data any, expiration time.Duration) (err error) { // 2. Set: 设置键值对 (key: \u0026#34;mykey\u0026#34;, value: \u0026#34;hello Redis\u0026#34;)，没有过期时间 return c.Redis.Set(ctx, key, data, expiration).Err() } func (c *RedisCache) SimpleGet(ctx context.Context, key string) (data string, err error) { // 4. Get: 获取键的值 data, err = c.Redis.Get(ctx, key).Result() if errors.Is(err, redis.Nil) || err != nil { return \u0026#34;\u0026#34;, err } else { return data, nil } } redislock.go\npackage cache import ( //\u0026#34;codeup.aliyun.com/619b3cb12f595dbd1b9b0b3e/go/common.git/id\u0026#34; \u0026#34;codeup.aliyun.com/619b3cb12f595dbd1b9b0b3e/go/common.git/log\u0026#34; \u0026#34;context\u0026#34; \u0026#34;github.com/google/uuid\u0026#34; \u0026#34;github.com/pkg/errors\u0026#34; \u0026#34;github.com/redis/go-redis/v9\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) // 实现分布式锁 // 几个 要点 // 互斥 redis 天然支持 // 1.set nx px 设置过期时间 5.0之后可以一条命令设置 // 2.释放锁的时候需要判断，线程卡住，自动过期，其他线程加锁，你再删除九五删除了 // 3.需要 lua 脚本 执行删除操作 因为判断和删除是2个操作 。 判断和删除的过程中，锁过期，刚好其他线程上锁， // 就会导致误删除。 // 4.可重入（看具体业务）、 自动续期（看门狗） type Lock struct { client redis.UniversalClient key string uuID string MaxTtl int wg *sync.WaitGroup cancel context.CancelFunc } func NewLock(client redis.UniversalClient, key string) *Lock { //sf := id.NewSonyflake() uuID := uuid.NewString() return \u0026amp;Lock{ client: client, uuID: uuID, MaxTtl: 5, key: key + \u0026#34;:lock\u0026#34;, wg: \u0026amp;sync.WaitGroup{}, } } func (l *Lock) Lock(ctx context.Context, expire time.Duration) (err error) { ok, _ := l.client.SetNX(ctx, l.key, l.uuID, expire).Result() if !ok { return errors.New(\u0026#34;lock failed\u0026#34;) } // 设置最大延期时间 // 在 Lock 方法中修正 maxTtl 的计算 maxTtl := time.Duration(l.MaxTtl) * expire ctx, cancel := context.WithCancel(ctx) l.cancel = cancel go l.startWatchdog(ctx, expire, maxTtl) return } func (l *Lock) startWatchdog(ctx context.Context, expire time.Duration, maxTtl time.Duration) { l.wg.Add(1) defer l.wg.Done() ctx, cancel := context.WithTimeout(ctx, maxTtl) defer cancel() timer := time.NewTicker(expire / 3) defer timer.Stop() for { select { case \u0026lt;-timer.C: // 延期 extensionScript := ` if redis.call(\u0026#34;GET\u0026#34;, KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;PEXPIRE\u0026#34;, KEYS[1], ARGV[2]) else return 0 end ` expireMs := int64(expire.Milliseconds()) err := l.client.Eval(ctx, extensionScript, []string{l.key}, l.uuID, expireMs).Err() if err != nil { log.Info(err.Error()) return } case \u0026lt;-ctx.Done(): return } } } func (l *Lock) UnLock(ctx context.Context) (err error) { if l.cancel == nil { return errors.New(\u0026#34;lock not held\u0026#34;) } // 释放watchdog l.cancel() l.wg.Wait() script := ` if redis.call(\u0026#34;GET\u0026#34;, KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;DEL\u0026#34;, KEYS[1]) else return 0 end ` ok, err := l.client.Eval(ctx, script, []string{l.key}, l.uuID).Result() if err != nil { return err } if ok.(int64) != 1 { return errors.New(\u0026#34;unlock failed: lock not held\u0026#34;) } return nil } ",
"tags":null,
"categories":null
},{
"title":"零拷贝",
"permalink": "http://localhost:1313/posts/cs/%E9%9B%B6%E6%8B%B7%E8%B4%9D/",
"summary": "零拷贝技术 通过sendfile 等函数减少用户态和内核态的切换，减少拷贝次数，加快文件传输速度，但只适用于原样传输的场景，比如静态文件服务器，消息队列等，比如mysql 也是磁盘加载数据，但是需要对取出来的数据做各种处理就不适合这种场景。\n",
"content": "零拷贝技术 通过sendfile 等函数减少用户态和内核态的切换，减少拷贝次数，加快文件传输速度，但只适用于原样传输的场景，比如静态文件服务器，消息队列等，比如mysql 也是磁盘加载数据，但是需要对取出来的数据做各种处理就不适合这种场景。\n",
"tags":null,
"categories":null
},{
"title":"Str_百度真题原地置换大小写",
"permalink": "http://localhost:1313/posts/algorithm/str_%E7%99%BE%E5%BA%A6%E7%9C%9F%E9%A2%98%E5%8E%9F%E5%9C%B0%E7%BD%AE%E6%8D%A2%E5%A4%A7%E5%B0%8F%E5%86%99/",
"summary": "代码实现 package test3 import ( \u0026#34;fmt\u0026#34; \u0026#34;unicode\u0026#34; ) func main() { //输入一个字符串，里面有大写字母、小写字母、数字， //处理结束后，大写字母在前，然后是小写字母，最后是数字， //要求：在原有字符串上做交换实现，不要建新的数据结构。 //mN1oO2pP3 //Nm1oO2pP3 str := []rune(\u0026#34;mN1oO2pP3\u0026#34;) // AbcafafaaFAs exchangePos(str) fmt.Println(string(str)) } func exchangePos(str []rune) { // i 找非大写字母 j 找大写字母 如果 i ！= j 交换 length := len(str) i, j := 0, 0 for i \u0026lt; length \u0026amp;\u0026amp; j \u0026lt; length { if isUper(str[j]) { //\u0026amp;\u0026amp; !isUper(rune(str[i])) if i != j { str[i], str[j] = str[j], str[i] i++ } } if isUper(str[i]) { i++ } j++ } // i 从上一次结束为止开始，找 数字， j 找小写字母 如果 i ！= j 交换 j = i //fmt.Println(string(str), i, j) for i \u0026lt; length \u0026amp;\u0026amp; j \u0026lt; length { if isLower(str[j]) { //\u0026amp;\u0026amp; !isUper(rune(str[i])) if i != j { str[i], str[j] = str[j], str[i] i++ } } if isLower(str[i]) { i++ } j++ } return } func isUper(s rune) bool { return unicode.IsUpper(s) } func isLower(s rune) bool { return unicode.IsLower(s) } 测试用例 package test3 import ( \u0026#34;testing\u0026#34; ) func TestExchangePos(t *testing.T) { cases := []struct { input string expected string }{ // 基础情况 {\u0026#34;\u0026#34;, \u0026#34;\u0026#34;}, {\u0026#34;A\u0026#34;, \u0026#34;A\u0026#34;}, {\u0026#34;a\u0026#34;, \u0026#34;a\u0026#34;}, {\u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;}, // 已经有序 {\u0026#34;ABCabc123\u0026#34;, \u0026#34;ABCabc123\u0026#34;}, // 完全逆序 {\u0026#34;123cbaCBA\u0026#34;, \u0026#34;CBAcba123\u0026#34;}, // 混合 {\u0026#34;aA1\u0026#34;, \u0026#34;Aa1\u0026#34;}, {\u0026#34;1aA\u0026#34;, \u0026#34;Aa1\u0026#34;}, {\u0026#34;Aa1Bb2Cc3\u0026#34;, \u0026#34;ABCabc123\u0026#34;}, // 两类字符 {\u0026#34;abc123\u0026#34;, \u0026#34;abc123\u0026#34;}, {\u0026#34;ABC123\u0026#34;, \u0026#34;ABC123\u0026#34;}, {\u0026#34;ABCabc\u0026#34;, \u0026#34;ABCabc\u0026#34;}, // 全部同类 {\u0026#34;ABCDEF\u0026#34;, \u0026#34;ABCDEF\u0026#34;}, {\u0026#34;abcdef\u0026#34;, \u0026#34;abcdef\u0026#34;}, {\u0026#34;123456\u0026#34;, \u0026#34;123456\u0026#34;}, // 随机混乱 {\u0026#34;Zy9Xx8Ww7\u0026#34;, \u0026#34;ZXWyxw987\u0026#34;}, {\u0026#34;mN1oO2pP3\u0026#34;, \u0026#34;NOPomp213\u0026#34;}, // 边界 {\u0026#34;A1a\u0026#34;, \u0026#34;Aa1\u0026#34;}, {\u0026#34;1A1aA1\u0026#34;, \u0026#34;AAa111\u0026#34;}, {\u0026#34;zZ9zZ9\u0026#34;, \u0026#34;ZZzz99\u0026#34;}, // 重复模式 / 长度较大 {\u0026#34;Aa1Aa1Aa1Aa1\u0026#34;, \u0026#34;AAAAaaaa1111\u0026#34;}, {\u0026#34;987ZYXcba654\u0026#34;, \u0026#34;ZYXcba987654\u0026#34;}, } for _, c := range cases { runes := []rune(c.input) exchangePos(runes) got := string(runes) if got != c.expected { t.Errorf(\u0026#34;exchangePos(%q) = %q; expected %q\u0026#34;, c.input, got, c.expected) } } } ",
"content": "代码实现 package test3 import ( \u0026#34;fmt\u0026#34; \u0026#34;unicode\u0026#34; ) func main() { //输入一个字符串，里面有大写字母、小写字母、数字， //处理结束后，大写字母在前，然后是小写字母，最后是数字， //要求：在原有字符串上做交换实现，不要建新的数据结构。 //mN1oO2pP3 //Nm1oO2pP3 str := []rune(\u0026#34;mN1oO2pP3\u0026#34;) // AbcafafaaFAs exchangePos(str) fmt.Println(string(str)) } func exchangePos(str []rune) { // i 找非大写字母 j 找大写字母 如果 i ！= j 交换 length := len(str) i, j := 0, 0 for i \u0026lt; length \u0026amp;\u0026amp; j \u0026lt; length { if isUper(str[j]) { //\u0026amp;\u0026amp; !isUper(rune(str[i])) if i != j { str[i], str[j] = str[j], str[i] i++ } } if isUper(str[i]) { i++ } j++ } // i 从上一次结束为止开始，找 数字， j 找小写字母 如果 i ！= j 交换 j = i //fmt.Println(string(str), i, j) for i \u0026lt; length \u0026amp;\u0026amp; j \u0026lt; length { if isLower(str[j]) { //\u0026amp;\u0026amp; !isUper(rune(str[i])) if i != j { str[i], str[j] = str[j], str[i] i++ } } if isLower(str[i]) { i++ } j++ } return } func isUper(s rune) bool { return unicode.IsUpper(s) } func isLower(s rune) bool { return unicode.IsLower(s) } 测试用例 package test3 import ( \u0026#34;testing\u0026#34; ) func TestExchangePos(t *testing.T) { cases := []struct { input string expected string }{ // 基础情况 {\u0026#34;\u0026#34;, \u0026#34;\u0026#34;}, {\u0026#34;A\u0026#34;, \u0026#34;A\u0026#34;}, {\u0026#34;a\u0026#34;, \u0026#34;a\u0026#34;}, {\u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;}, // 已经有序 {\u0026#34;ABCabc123\u0026#34;, \u0026#34;ABCabc123\u0026#34;}, // 完全逆序 {\u0026#34;123cbaCBA\u0026#34;, \u0026#34;CBAcba123\u0026#34;}, // 混合 {\u0026#34;aA1\u0026#34;, \u0026#34;Aa1\u0026#34;}, {\u0026#34;1aA\u0026#34;, \u0026#34;Aa1\u0026#34;}, {\u0026#34;Aa1Bb2Cc3\u0026#34;, \u0026#34;ABCabc123\u0026#34;}, // 两类字符 {\u0026#34;abc123\u0026#34;, \u0026#34;abc123\u0026#34;}, {\u0026#34;ABC123\u0026#34;, \u0026#34;ABC123\u0026#34;}, {\u0026#34;ABCabc\u0026#34;, \u0026#34;ABCabc\u0026#34;}, // 全部同类 {\u0026#34;ABCDEF\u0026#34;, \u0026#34;ABCDEF\u0026#34;}, {\u0026#34;abcdef\u0026#34;, \u0026#34;abcdef\u0026#34;}, {\u0026#34;123456\u0026#34;, \u0026#34;123456\u0026#34;}, // 随机混乱 {\u0026#34;Zy9Xx8Ww7\u0026#34;, \u0026#34;ZXWyxw987\u0026#34;}, {\u0026#34;mN1oO2pP3\u0026#34;, \u0026#34;NOPomp213\u0026#34;}, // 边界 {\u0026#34;A1a\u0026#34;, \u0026#34;Aa1\u0026#34;}, {\u0026#34;1A1aA1\u0026#34;, \u0026#34;AAa111\u0026#34;}, {\u0026#34;zZ9zZ9\u0026#34;, \u0026#34;ZZzz99\u0026#34;}, // 重复模式 / 长度较大 {\u0026#34;Aa1Aa1Aa1Aa1\u0026#34;, \u0026#34;AAAAaaaa1111\u0026#34;}, {\u0026#34;987ZYXcba654\u0026#34;, \u0026#34;ZYXcba987654\u0026#34;}, } for _, c := range cases { runes := []rune(c.input) exchangePos(runes) got := string(runes) if got != c.expected { t.Errorf(\u0026#34;exchangePos(%q) = %q; expected %q\u0026#34;, c.input, got, c.expected) } } } ",
"tags":null,
"categories":null
},{
"title":"Matrix_多源扩散",
"permalink": "http://localhost:1313/posts/algorithm/matrix_%E5%A4%9A%E6%BA%90%E6%89%A9%E6%95%A3/",
"summary": "package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;strings\u0026#34; ) // 题目描述 // // 存在一个mxn的二维数组，其成员取值范围为0或1，其中值为1的成员具备扩散性，每经过1S，将上下左右值为0的成员同化为1，二维数组的成员初始值都为0，将第[i,j]和[k,l]两个个位置上元素修改成1后，求矩阵的所有，元素变为1需要多长时间 // // 输入描述 // // 输入数据中的前2个数字表示这是一个mxn的矩阵，m和n不会超过1024大小; // // 中间两个数字表示一个初始扩散点位置为I,j // // 最后2个数字表示另一个扩散点位置为k,l // // 输出描述 // // 输出矩阵的所有元素变为1所需要秒数 // // 用例 func main() { input := bufio.NewScanner(os.Stdin) input.Scan() str := input.Text() strArr := strings.Split(str, \u0026#34;,\u0026#34;) m, n := Atoi(strArr[0]), Atoi(strArr[1]) pos1, pos2, pos3, pos4 := Atoi(strArr[2]), Atoi(strArr[3]), Atoi(strArr[4]), Atoi(strArr[5]) time := getMatrixBroadcastTime(m, n, pos1, pos2, pos3, pos4) fmt.Println(time) } func getMatrixBroadcastTime(m, n, pos1, pos2, pos3, pos4 int) (res int) { path := make([]string, 0) path = append(path, getPos(pos1, pos2)) path = append(path, getPos(pos3, pos4)) check := make(map[string]bool) check[getPos(pos1, pos2)] = true check[getPos(pos3, pos4)] = true count := 2 for len(path) \u0026gt; 0 { length := len(path) for i := 0; i \u0026lt; length; i++ { pos := strings.Split(path[i], \u0026#34;_\u0026#34;) x, y := Atoi(pos[0]), Atoi(pos[1]) // 上 if x-1 \u0026gt;= 0 \u0026amp;\u0026amp; check[getPos(x-1, y)] != true { path = append(path, getPos(x-1, y)) check[getPos(x-1, y)] = true count++ } // 下 if x+1 \u0026lt; m \u0026amp;\u0026amp; check[getPos(x+1, y)] != true { path = append(path, getPos(x+1, y)) check[getPos(x+1, y)] = true count++ } // 左 if y-1 \u0026gt;= 0 \u0026amp;\u0026amp; check[getPos(x, y-1)] != true { path = append(path, getPos(x, y-1)) check[getPos(x, y-1)] = true count++ } // 右 if y+1 \u0026lt; n \u0026amp;\u0026amp; check[getPos(x, y+1)] != true { path = append(path, getPos(x, y+1)) check[getPos(x, y+1)] = true count++ } } res++ if count \u0026gt;= m*n { return } } return } func getPos(x, y int) string { return fmt.Sprintf(\u0026#34;%d_%d\u0026#34;, x, y) } func Atoi(str string) int { res, _ := strconv.Atoi(str) return res } ",
"content": "package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;strings\u0026#34; ) // 题目描述 // // 存在一个mxn的二维数组，其成员取值范围为0或1，其中值为1的成员具备扩散性，每经过1S，将上下左右值为0的成员同化为1，二维数组的成员初始值都为0，将第[i,j]和[k,l]两个个位置上元素修改成1后，求矩阵的所有，元素变为1需要多长时间 // // 输入描述 // // 输入数据中的前2个数字表示这是一个mxn的矩阵，m和n不会超过1024大小; // // 中间两个数字表示一个初始扩散点位置为I,j // // 最后2个数字表示另一个扩散点位置为k,l // // 输出描述 // // 输出矩阵的所有元素变为1所需要秒数 // // 用例 func main() { input := bufio.NewScanner(os.Stdin) input.Scan() str := input.Text() strArr := strings.Split(str, \u0026#34;,\u0026#34;) m, n := Atoi(strArr[0]), Atoi(strArr[1]) pos1, pos2, pos3, pos4 := Atoi(strArr[2]), Atoi(strArr[3]), Atoi(strArr[4]), Atoi(strArr[5]) time := getMatrixBroadcastTime(m, n, pos1, pos2, pos3, pos4) fmt.Println(time) } func getMatrixBroadcastTime(m, n, pos1, pos2, pos3, pos4 int) (res int) { path := make([]string, 0) path = append(path, getPos(pos1, pos2)) path = append(path, getPos(pos3, pos4)) check := make(map[string]bool) check[getPos(pos1, pos2)] = true check[getPos(pos3, pos4)] = true count := 2 for len(path) \u0026gt; 0 { length := len(path) for i := 0; i \u0026lt; length; i++ { pos := strings.Split(path[i], \u0026#34;_\u0026#34;) x, y := Atoi(pos[0]), Atoi(pos[1]) // 上 if x-1 \u0026gt;= 0 \u0026amp;\u0026amp; check[getPos(x-1, y)] != true { path = append(path, getPos(x-1, y)) check[getPos(x-1, y)] = true count++ } // 下 if x+1 \u0026lt; m \u0026amp;\u0026amp; check[getPos(x+1, y)] != true { path = append(path, getPos(x+1, y)) check[getPos(x+1, y)] = true count++ } // 左 if y-1 \u0026gt;= 0 \u0026amp;\u0026amp; check[getPos(x, y-1)] != true { path = append(path, getPos(x, y-1)) check[getPos(x, y-1)] = true count++ } // 右 if y+1 \u0026lt; n \u0026amp;\u0026amp; check[getPos(x, y+1)] != true { path = append(path, getPos(x, y+1)) check[getPos(x, y+1)] = true count++ } } res++ if count \u0026gt;= m*n { return } } return } func getPos(x, y int) string { return fmt.Sprintf(\u0026#34;%d_%d\u0026#34;, x, y) } func Atoi(str string) int { res, _ := strconv.Atoi(str) return res } ",
"tags":null,
"categories":null
},{
"title":"Str_判断字符顺序和存在",
"permalink": "http://localhost:1313/posts/algorithm/str_%E5%88%A4%E6%96%AD%E5%AD%97%E7%AC%A6%E9%A1%BA%E5%BA%8F%E5%92%8C%E5%AD%98%E5%9C%A8/",
"summary": "package test1 import \u0026#34;sort\u0026#34; //题目 // 题目描述输入两个字符串S和L，都只包含英文小写字母。S长度\u0026lt;=100，L长度\u0026lt;=500,000。 //判定S是否是L的有效子串。判定规则：S中的每个字符在L中都能找到（可以不连续），且S在Ｌ中字符的前后顺序与S中顺序要保持一致。 //（例如，S=”ace”是L=”abcde”的一个子序列且有效字符是a、c、e，而”aec”不是有效子序列，且有效字符只有a、e） //输入输出 //输入输入两个字符串S和L，都只包含英文小写字母。S长度\u0026lt;=100，L长度\u0026lt;=500,000。 //先输入S，再输入L，每个字符串占一行。输出S串最后一个有效字符在L中的位置。 //（首位从0开始计算，无有效字符返回-1） func SubStrLasPos(str string, sub string) int { // aabcdabc 8 // abc findKey := -1 // 循环找到所有的字符在str中的位置 预处理 strPos := make(map[byte][]int) for i := 0; i \u0026lt; len(str); i++ { strPos[str[i]] = append(strPos[str[i]], i) } // limit 限制每个字符的位置 当前值比后一个值的最大位置要小才行 limit := len(str) for i := len(sub) - 1; i \u0026gt;= 0; i-- { if _, ok := strPos[sub[i]]; !ok { return -1 } else { subArr := strPos[sub[i]] //sort.SearchInts() // 如果满足子数组的位置比Limit 小 就ok key := sort.SearchInts(subArr, limit) if key == 0 { return -1 } limit = subArr[key-1] if i == len(sub)-1 { findKey = limit } } // 排序拿到最大的值 //sort.Slice(strPos[sub[i]], func(i, j int) bool { //\treturn strPos[sub[i]][i] \u0026lt; strPos[sub[i]][j] //}) } return findKey } func search(arr []int, limit int) int { low, high := 0, len(arr)-1 for low \u0026lt;= high { mid := low + (high-low)/2 if arr[mid] == limit { return mid } else if arr[mid] \u0026gt; limit { high = mid - 1 } else { low = mid + 1 } } return -1 } ",
"content": "package test1 import \u0026#34;sort\u0026#34; //题目 // 题目描述输入两个字符串S和L，都只包含英文小写字母。S长度\u0026lt;=100，L长度\u0026lt;=500,000。 //判定S是否是L的有效子串。判定规则：S中的每个字符在L中都能找到（可以不连续），且S在Ｌ中字符的前后顺序与S中顺序要保持一致。 //（例如，S=”ace”是L=”abcde”的一个子序列且有效字符是a、c、e，而”aec”不是有效子序列，且有效字符只有a、e） //输入输出 //输入输入两个字符串S和L，都只包含英文小写字母。S长度\u0026lt;=100，L长度\u0026lt;=500,000。 //先输入S，再输入L，每个字符串占一行。输出S串最后一个有效字符在L中的位置。 //（首位从0开始计算，无有效字符返回-1） func SubStrLasPos(str string, sub string) int { // aabcdabc 8 // abc findKey := -1 // 循环找到所有的字符在str中的位置 预处理 strPos := make(map[byte][]int) for i := 0; i \u0026lt; len(str); i++ { strPos[str[i]] = append(strPos[str[i]], i) } // limit 限制每个字符的位置 当前值比后一个值的最大位置要小才行 limit := len(str) for i := len(sub) - 1; i \u0026gt;= 0; i-- { if _, ok := strPos[sub[i]]; !ok { return -1 } else { subArr := strPos[sub[i]] //sort.SearchInts() // 如果满足子数组的位置比Limit 小 就ok key := sort.SearchInts(subArr, limit) if key == 0 { return -1 } limit = subArr[key-1] if i == len(sub)-1 { findKey = limit } } // 排序拿到最大的值 //sort.Slice(strPos[sub[i]], func(i, j int) bool { //\treturn strPos[sub[i]][i] \u0026lt; strPos[sub[i]][j] //}) } return findKey } func search(arr []int, limit int) int { low, high := 0, len(arr)-1 for low \u0026lt;= high { mid := low + (high-low)/2 if arr[mid] == limit { return mid } else if arr[mid] \u0026gt; limit { high = mid - 1 } else { low = mid + 1 } } return -1 } ",
"tags":null,
"categories":null
},{
"title":"Go实现lru",
"permalink": "http://localhost:1313/posts/datastructalgorithm/go%E5%AE%9E%E7%8E%B0lru/",
"summary": "package main import \u0026#34;fmt\u0026#34; // func main() { // //\t//LRU //\t//实现一个 LRU 缓存，要求支持以下操作： //\t//- Get(key int)(int, bool)：如果缓存中存在该 key，返回其对应的值，否则返回 0,false。 //\t//- Put(key, value int)：将一个 key-value 对插入缓存。如果缓存已经满了，淘汰最久未使用的元素。 //\t// //\t//示例： //\t//func main() { //\t// // 构造 一个 LRU cache //\t// cache := Constructor(2) //\t// cache.Put(1, 1) //\t// cache.Put(2, 2) //\t// //\t// // 测试缓存获取 //\t// fmt.Println(cache.Get(1)) // 输出: 1 true //\t// fmt.Println(cache.Get(3)) // 输出: 0 false //\t// //\t// cache.Put(3, 3) //\t// fmt.Println(cache.Get(2)) // 输出: 0 false //\t// //\t// cache.Put(4, 4) //\t// fmt.Println(cache.Get(1)) // 输出: 0 false //\t// fmt.Println(cache.Get(3)) // 输出: 3 true //\t// fmt.Println(cache.Get(4)) // 输出: 4 true //\t//} //\t} func main() { // 构造 一个 LRU cache cache := Constructor(2) cache.Put(2, 1) cache.Put(1, 1) cache.Put(2, 3) cache.Put(4, 1) fmt.Println(cache.Get(1)) fmt.Println(cache.Get(2)) } type Node struct { next *Node pre *Node val int key int } type LRUCache struct { capacity int size int cache map[int]*Node head, tail *Node } func Constructor(capacity int) LRUCache { l := LRUCache{ capacity: capacity, cache: make(map[int]*Node, capacity), head: \u0026amp;Node{}, tail: \u0026amp;Node{}, } l.head.next = l.tail l.tail.pre = l.head return l } // 1 2 3 4 func (l *LRUCache) Get(key int) int { // 从map拿数据 if _, ok := l.cache[key]; !ok { return -1 } node := l.cache[key] l.MoveToHead(node) return node.val } func (l *LRUCache) Put(key int, val int) { if _, ok := l.cache[key]; ok { l.cache[key].val = val l.MoveToHead(l.cache[key]) } else { l.size++ node := InitNode(key, val) l.cache[key] = node l.AddToHead(node) if l.size \u0026gt; l.capacity { node := l.RemoveTail() l.size-- delete(l.cache, node.key) } } } func InitNode(key, val int) *Node { return \u0026amp;Node{ key: key, val: val, } } // 添加到头节点 func (l *LRUCache) AddToHead(newNode *Node) *Node { newNode.next = l.head.next newNode.pre = l.head l.head.next.pre = newNode l.head.next = newNode return newNode } func (l *LRUCache) RemoveNode(node *Node) { node.pre.next = node.next node.next.pre = node.pre } func (l *LRUCache) RemoveTail() *Node { node := l.tail.pre //l.tail.pre = node.pre l.RemoveNode(node) return node } func (l *LRUCache) MoveToHead(node *Node) { l.RemoveNode(node) l.AddToHead(node) } ",
"content": "package main import \u0026#34;fmt\u0026#34; // func main() { // //\t//LRU //\t//实现一个 LRU 缓存，要求支持以下操作： //\t//- Get(key int)(int, bool)：如果缓存中存在该 key，返回其对应的值，否则返回 0,false。 //\t//- Put(key, value int)：将一个 key-value 对插入缓存。如果缓存已经满了，淘汰最久未使用的元素。 //\t// //\t//示例： //\t//func main() { //\t// // 构造 一个 LRU cache //\t// cache := Constructor(2) //\t// cache.Put(1, 1) //\t// cache.Put(2, 2) //\t// //\t// // 测试缓存获取 //\t// fmt.Println(cache.Get(1)) // 输出: 1 true //\t// fmt.Println(cache.Get(3)) // 输出: 0 false //\t// //\t// cache.Put(3, 3) //\t// fmt.Println(cache.Get(2)) // 输出: 0 false //\t// //\t// cache.Put(4, 4) //\t// fmt.Println(cache.Get(1)) // 输出: 0 false //\t// fmt.Println(cache.Get(3)) // 输出: 3 true //\t// fmt.Println(cache.Get(4)) // 输出: 4 true //\t//} //\t} func main() { // 构造 一个 LRU cache cache := Constructor(2) cache.Put(2, 1) cache.Put(1, 1) cache.Put(2, 3) cache.Put(4, 1) fmt.Println(cache.Get(1)) fmt.Println(cache.Get(2)) } type Node struct { next *Node pre *Node val int key int } type LRUCache struct { capacity int size int cache map[int]*Node head, tail *Node } func Constructor(capacity int) LRUCache { l := LRUCache{ capacity: capacity, cache: make(map[int]*Node, capacity), head: \u0026amp;Node{}, tail: \u0026amp;Node{}, } l.head.next = l.tail l.tail.pre = l.head return l } // 1 2 3 4 func (l *LRUCache) Get(key int) int { // 从map拿数据 if _, ok := l.cache[key]; !ok { return -1 } node := l.cache[key] l.MoveToHead(node) return node.val } func (l *LRUCache) Put(key int, val int) { if _, ok := l.cache[key]; ok { l.cache[key].val = val l.MoveToHead(l.cache[key]) } else { l.size++ node := InitNode(key, val) l.cache[key] = node l.AddToHead(node) if l.size \u0026gt; l.capacity { node := l.RemoveTail() l.size-- delete(l.cache, node.key) } } } func InitNode(key, val int) *Node { return \u0026amp;Node{ key: key, val: val, } } // 添加到头节点 func (l *LRUCache) AddToHead(newNode *Node) *Node { newNode.next = l.head.next newNode.pre = l.head l.head.next.pre = newNode l.head.next = newNode return newNode } func (l *LRUCache) RemoveNode(node *Node) { node.pre.next = node.next node.next.pre = node.pre } func (l *LRUCache) RemoveTail() *Node { node := l.tail.pre //l.tail.pre = node.pre l.RemoveNode(node) return node } func (l *LRUCache) MoveToHead(node *Node) { l.RemoveNode(node) l.AddToHead(node) } ",
"tags":null,
"categories":null
},{
"title":"Mod",
"permalink": "http://localhost:1313/posts/go/mod/",
"summary": "go mod 加载机制 go root go的安装目录\ngo path go的源代码工作目录\ngo mod go从1.11开始，加入了 go mod。开启 go mod 之后，不需要讲所有的源代码放到gopath。\ngo 的加载机制 go 会把go mod所在的目录当成工作目录，先加载相对路径下的本地包，如果没有会去go mod文件查找，go mod 会尝试从go proxy 拉取代码，go proxy 是Google维护的go的包仓库，即使某些包的源码被删除，也还是可以从包仓库 下载，这保证了包引入的稳定性。如果go proxy没有，那么go会尝试从代码仓库拉取源码，比如github上的源码。go mod 当中 带有 // indirect的就是直接源码下载的。\n还可以使用 go mod edit -replace [old git package]@[version]=[new git package]@[version] 命令将远程代码仓库替换成本地的代码。 使用go private 设置私有化代码仓库的路径，然后配置认证就可以使用内部代码库。\n常用命令 go mod init 初始化模块，生成 go mod go mod tidy 拉取依赖，自动增删依赖，生成go.sum go mod download 将依赖预下载到本地缓存 go mod vendor 将下载的依赖缓存到 ./vendor,用于离线构建 go mod edit ",
"content": "go mod 加载机制 go root go的安装目录\ngo path go的源代码工作目录\ngo mod go从1.11开始，加入了 go mod。开启 go mod 之后，不需要讲所有的源代码放到gopath。\ngo 的加载机制 go 会把go mod所在的目录当成工作目录，先加载相对路径下的本地包，如果没有会去go mod文件查找，go mod 会尝试从go proxy 拉取代码，go proxy 是Google维护的go的包仓库，即使某些包的源码被删除，也还是可以从包仓库 下载，这保证了包引入的稳定性。如果go proxy没有，那么go会尝试从代码仓库拉取源码，比如github上的源码。go mod 当中 带有 // indirect的就是直接源码下载的。\n还可以使用 go mod edit -replace [old git package]@[version]=[new git package]@[version] 命令将远程代码仓库替换成本地的代码。 使用go private 设置私有化代码仓库的路径，然后配置认证就可以使用内部代码库。\n常用命令 go mod init 初始化模块，生成 go mod go mod tidy 拉取依赖，自动增删依赖，生成go.sum go mod download 将依赖预下载到本地缓存 go mod vendor 将下载的依赖缓存到 ./vendor,用于离线构建 go mod edit ",
"tags":null,
"categories":null
},{
"title":"初始化方法比较",
"permalink": "http://localhost:1313/posts/go/%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95%E6%AF%94%E8%BE%83/",
"summary": "make和new的初始化比较 make new 返回值 返回实例化对象本身 返回类型并清空返回实例化对象的指针 作用类型、常见用法 slice、map、channel 所有类型 内部作用机制 初始化结构体，并初始化结构体内部的相关字段机构 初始化对象，清空内存，分配内存，置为零值 为什么new slice map 得到是nil 首先 new 严格遵守返回的是初始化对象指针的原则，而new slice、map的时候，返回的就是对象的引用，只是切片和哈希的 零值就是nil,所以如果new切片和map会出现无法使用的情况。\n",
"content": "make和new的初始化比较 make new 返回值 返回实例化对象本身 返回类型并清空返回实例化对象的指针 作用类型、常见用法 slice、map、channel 所有类型 内部作用机制 初始化结构体，并初始化结构体内部的相关字段机构 初始化对象，清空内存，分配内存，置为零值 为什么new slice map 得到是nil 首先 new 严格遵守返回的是初始化对象指针的原则，而new slice、map的时候，返回的就是对象的引用，只是切片和哈希的 零值就是nil,所以如果new切片和map会出现无法使用的情况。\n",
"tags":["go","make","new","初始化"],
"categories":null
},{
"title":"内存泄漏",
"permalink": "http://localhost:1313/posts/go/%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F/",
"summary": "什么是内存泄漏 指内存资源长期得不到释放，导致内存持续增长，最终导致内存溢出\n内存泄漏的常见场景 协程的泄漏 耗时任务或者http请求一直得不到响应，又没有设置超时时间 chan未正确关闭、阻塞。range channel 发送端未关闭导致死循环。 锁未正确释放、导致协程未能释放 资源未关闭，如file、数据库、redis连接、timer定时器、channel cgo 其他的一些 内存泄漏分析工具 pprof分析协程数量，内存占用情况等\n如何针对内存泄漏进行优化 针对协程泄漏 设置超时时间 context.deadline timeout 结合select进行超时控制 正确使用channel 正确使用互斥锁，配对使用 针对channel的泄漏 配对使用 在发送方关闭channel 正确使用缓冲channel和非缓冲channel 养成关闭资源的习惯，使用defer,clear up 等工具 cgo和其他场景记得防止协程泄漏 ",
"content": "什么是内存泄漏 指内存资源长期得不到释放，导致内存持续增长，最终导致内存溢出\n内存泄漏的常见场景 协程的泄漏 耗时任务或者http请求一直得不到响应，又没有设置超时时间 chan未正确关闭、阻塞。range channel 发送端未关闭导致死循环。 锁未正确释放、导致协程未能释放 资源未关闭，如file、数据库、redis连接、timer定时器、channel cgo 其他的一些 内存泄漏分析工具 pprof分析协程数量，内存占用情况等\n如何针对内存泄漏进行优化 针对协程泄漏 设置超时时间 context.deadline timeout 结合select进行超时控制 正确使用channel 正确使用互斥锁，配对使用 针对channel的泄漏 配对使用 在发送方关闭channel 正确使用缓冲channel和非缓冲channel 养成关闭资源的习惯，使用defer,clear up 等工具 cgo和其他场景记得防止协程泄漏 ",
"tags":null,
"categories":null
},{
"title":"逃逸分析",
"permalink": "http://localhost:1313/posts/go/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/",
"summary": "什么是逃逸分析 计算机科学中对指针作用范围进行分析就叫做逃逸分析。分析变量是分配到堆上还是栈上。 分配到堆上和栈上的对比\n栈 堆 分配方式 随着函数创建自动分配 程序员手动分配 资源消耗 很小 ，大小固定 比较大，大小不固定，需要寻找到合适的大小。容易产生内存碎片 回收方式 随着函数的结束进行销毁 需要手动回收,或者根据gc算法进行回收 所以说编译器会尽可能的将变量分配到栈上， go会在静态编译阶段就确定变量到底应该分配到堆上还是栈上。 当一个变量在函数之外的地方还会被使用就会发生逃逸。\n以下几个场景会发生逃逸 返回一个变量的指针 返回一个闭包函数，闭包函数捕获了调用函数的变量 往channel发送了变量的指针 巨大的变量，编译器为了防止栈内存不够，会将其分配到堆上 引用类型的使用，比如传递slice、map、chan、interface等 如何对go的程序进行逃逸分析 使用源码go build \u0026ndash;gcflags \u0026lsquo;-m -l\u0026rsquo;分析，看变量是否发生了逃逸 还可以结合pprof对堆内存的分配进行查看，结合热点路径使用go gc flag 进行分析\n如何使用 逃逸分析需要注意的点 在不影响代码结构合理性的情况下，进行减少使用指针（变量的内存占用不大的情况下）。 不要过度设计，持续重构。也就是先实现业务，再去结合工具来进行调整 ",
"content": "什么是逃逸分析 计算机科学中对指针作用范围进行分析就叫做逃逸分析。分析变量是分配到堆上还是栈上。 分配到堆上和栈上的对比\n栈 堆 分配方式 随着函数创建自动分配 程序员手动分配 资源消耗 很小 ，大小固定 比较大，大小不固定，需要寻找到合适的大小。容易产生内存碎片 回收方式 随着函数的结束进行销毁 需要手动回收,或者根据gc算法进行回收 所以说编译器会尽可能的将变量分配到栈上， go会在静态编译阶段就确定变量到底应该分配到堆上还是栈上。 当一个变量在函数之外的地方还会被使用就会发生逃逸。\n以下几个场景会发生逃逸 返回一个变量的指针 返回一个闭包函数，闭包函数捕获了调用函数的变量 往channel发送了变量的指针 巨大的变量，编译器为了防止栈内存不够，会将其分配到堆上 引用类型的使用，比如传递slice、map、chan、interface等 如何对go的程序进行逃逸分析 使用源码go build \u0026ndash;gcflags \u0026lsquo;-m -l\u0026rsquo;分析，看变量是否发生了逃逸 还可以结合pprof对堆内存的分配进行查看，结合热点路径使用go gc flag 进行分析\n如何使用 逃逸分析需要注意的点 在不影响代码结构合理性的情况下，进行减少使用指针（变量的内存占用不大的情况下）。 不要过度设计，持续重构。也就是先实现业务，再去结合工具来进行调整 ",
"tags":null,
"categories":null
},{
"title":"Gc",
"permalink": "http://localhost:1313/posts/go/gc/",
"summary": "什么是GC gc就是内存垃圾回收。c/c++这类语言可以由程序员申请内存，分配到堆上，堆上的数据随着函数结束并不会自动被清零，需要程序员手动清理。 这会给编程增加负担和隐患。高级语言如java/go支持gc,自动分析没有被引用的变量，进行内存回收。\n常见的GC方法 引用计数法 对变量对象的引用次数进行计数，当计数为0就会被回收。它实现简单，但效率不高无法解决循环引用的问题。\n标记清除法 扫描所有对象，将有引用的进行标记。优点是实现简单，但可能出现很多内存碎片，不利于内存重新分配。\n复制法 准备2个大小一样的内存块，将存活的对象放到新的内存块。优点是解决了内存碎片问题，但内存复制比较消耗资源，还需要将引用关系进行复制。\n分代法 将对象创建的不同时间分为青年代、老年代。分代发基于一种实践思想，大多数对象的生命周期都很短。\n三色标记法 stw可以是start the world 或者 stop zhe world的缩写，他指的是stop the word 到 start the world 这个间隔的时间。在gc过程需要暂停用户 代码执行，进行内存扫描，这个stw时间越短，对程序的性能提升越高。\ngo的GC实现 go因为内存分配是采用tcmalloc分配法，所有不需要处理内存碎片问题，同时go团队更加希望的是gc操作可以和用户代码一起执行，不仅是减少 stw的时间。go采用三色标记法对内存进行回收，并采用混合屏障提升并发时的回收效率。\ntcmalloc内存分配 首先每个协程都有自己的内存分配器，由一系列递增的内存大小块组成，每次内存申请回优先在本地分配器进行申请，当内存不足会向更高一级的内存分配器进行申请。 内存分类器会定时整理内存碎片，当空闲内存超过一定数量时会进行内存回收，不足时会进行内存分配。\ngo为什么采用三色标记法 go采用tcmalloc所以对内存碎片优化的方案的gc算法并不会带来明显的性能提升 go团队的目标不仅仅是减少stw的时候，还希望回收过程可以和用户代码共同执行，提升程序性能。 定义 go的gc扫描器将所有对象分为三类，分别是：\n白色对象（可能存活的对象）：一开始所有对象都标记成白色对象，当扫描完成后，白色对象不可达 灰色对象（波面）：正在被访问器访问到的对象，他可能指向白色对象 黑色对象（确定存活）：已经被回收期扫描。 扫描过程 分为4步\n所有根对象标记为白色 将根对象放入待扫描队列，标记成灰色 扫描队列所有的灰色对象，标记成黑色，并将引用对象标记成灰色。 重复步骤三，直到待扫描的灰色对象为空，所有对象标记成黑色或者白色。白色对象不可达，进行回收。 根对象在垃圾回收术语中被称为根集合，它包含 全局对象，程序在编译阶段就能确定的存在于程序整个生命周期的对象 执行栈，每个goroutine都有自己的内存栈，会有自己的栈对象和指向堆区块的指针 寄存器，计算过程中可能指向的一些堆区块的指针 没有stw可能得问题，对象被错误删除 假设以下场景：扫描到某个节点，存在a灰色对象引用白色对象b,存在一个黑色对象c。此时现将删除a对b的引用，同时添加 c对b的引用。b本来应该被正确标记成黑色的，由于对象c为黑色不会对它进行扫描，而a又删除了对b的引用，就会造成c始终不可达 造成误删除。\n当同时满足以下2个条件时，会出现误删除：\n赋值器创建一个黑色对象对白色对象的引用 删除灰色对象对这个白色的引用 只要破坏任意条件就可以避免误删除 避免条件一，也就避免了修改对象池当中需要被删除的对象的存活状态，应该存活的对象均可达。出现条件二，删除了灰色对象对白色对象的引用 这个白色对象也应该被删除。 避免条件二，白色对象最终可以由灰色访问到，进行正常标记。就算创建了黑色对象对白色对象的引用，也可以由灰色对象触达。 屏障机制 分成2种赋值器，插入时使用灰色赋值器，删除时使用黑色赋值器\n插入屏障 当添加一新的对象引用时，会先将插入对象赋值成灰色。破坏条件一，破坏了增加了一个黑色对象对白色对象的引用。有个一个细节，由于对所有对象进行插入屏障会比较 影响性能，golang团队后来决定只对堆区的对象启用插入屏障，栈区的对象会在第一次gc完成之后stw重新扫描一次栈区。\n删除屏障 当删除一个对象时，现将对象赋值为黑色。破坏条件二，破坏了删除一个灰色对象对白色对象的引用。\n",
"content": "什么是GC gc就是内存垃圾回收。c/c++这类语言可以由程序员申请内存，分配到堆上，堆上的数据随着函数结束并不会自动被清零，需要程序员手动清理。 这会给编程增加负担和隐患。高级语言如java/go支持gc,自动分析没有被引用的变量，进行内存回收。\n常见的GC方法 引用计数法 对变量对象的引用次数进行计数，当计数为0就会被回收。它实现简单，但效率不高无法解决循环引用的问题。\n标记清除法 扫描所有对象，将有引用的进行标记。优点是实现简单，但可能出现很多内存碎片，不利于内存重新分配。\n复制法 准备2个大小一样的内存块，将存活的对象放到新的内存块。优点是解决了内存碎片问题，但内存复制比较消耗资源，还需要将引用关系进行复制。\n分代法 将对象创建的不同时间分为青年代、老年代。分代发基于一种实践思想，大多数对象的生命周期都很短。\n三色标记法 stw可以是start the world 或者 stop zhe world的缩写，他指的是stop the word 到 start the world 这个间隔的时间。在gc过程需要暂停用户 代码执行，进行内存扫描，这个stw时间越短，对程序的性能提升越高。\ngo的GC实现 go因为内存分配是采用tcmalloc分配法，所有不需要处理内存碎片问题，同时go团队更加希望的是gc操作可以和用户代码一起执行，不仅是减少 stw的时间。go采用三色标记法对内存进行回收，并采用混合屏障提升并发时的回收效率。\ntcmalloc内存分配 首先每个协程都有自己的内存分配器，由一系列递增的内存大小块组成，每次内存申请回优先在本地分配器进行申请，当内存不足会向更高一级的内存分配器进行申请。 内存分类器会定时整理内存碎片，当空闲内存超过一定数量时会进行内存回收，不足时会进行内存分配。\ngo为什么采用三色标记法 go采用tcmalloc所以对内存碎片优化的方案的gc算法并不会带来明显的性能提升 go团队的目标不仅仅是减少stw的时候，还希望回收过程可以和用户代码共同执行，提升程序性能。 定义 go的gc扫描器将所有对象分为三类，分别是：\n白色对象（可能存活的对象）：一开始所有对象都标记成白色对象，当扫描完成后，白色对象不可达 灰色对象（波面）：正在被访问器访问到的对象，他可能指向白色对象 黑色对象（确定存活）：已经被回收期扫描。 扫描过程 分为4步\n所有根对象标记为白色 将根对象放入待扫描队列，标记成灰色 扫描队列所有的灰色对象，标记成黑色，并将引用对象标记成灰色。 重复步骤三，直到待扫描的灰色对象为空，所有对象标记成黑色或者白色。白色对象不可达，进行回收。 根对象在垃圾回收术语中被称为根集合，它包含 全局对象，程序在编译阶段就能确定的存在于程序整个生命周期的对象 执行栈，每个goroutine都有自己的内存栈，会有自己的栈对象和指向堆区块的指针 寄存器，计算过程中可能指向的一些堆区块的指针 没有stw可能得问题，对象被错误删除 假设以下场景：扫描到某个节点，存在a灰色对象引用白色对象b,存在一个黑色对象c。此时现将删除a对b的引用，同时添加 c对b的引用。b本来应该被正确标记成黑色的，由于对象c为黑色不会对它进行扫描，而a又删除了对b的引用，就会造成c始终不可达 造成误删除。\n当同时满足以下2个条件时，会出现误删除：\n赋值器创建一个黑色对象对白色对象的引用 删除灰色对象对这个白色的引用 只要破坏任意条件就可以避免误删除 避免条件一，也就避免了修改对象池当中需要被删除的对象的存活状态，应该存活的对象均可达。出现条件二，删除了灰色对象对白色对象的引用 这个白色对象也应该被删除。 避免条件二，白色对象最终可以由灰色访问到，进行正常标记。就算创建了黑色对象对白色对象的引用，也可以由灰色对象触达。 屏障机制 分成2种赋值器，插入时使用灰色赋值器，删除时使用黑色赋值器\n插入屏障 当添加一新的对象引用时，会先将插入对象赋值成灰色。破坏条件一，破坏了增加了一个黑色对象对白色对象的引用。有个一个细节，由于对所有对象进行插入屏障会比较 影响性能，golang团队后来决定只对堆区的对象启用插入屏障，栈区的对象会在第一次gc完成之后stw重新扫描一次栈区。\n删除屏障 当删除一个对象时，现将对象赋值为黑色。破坏条件二，破坏了删除一个灰色对象对白色对象的引用。\n混合屏障 栈区： gc开始阶段栈区所有的对象都被遍历并标记为黑色 gc进行阶段，增加和删除的对象也都被标记成黑色 堆区：删除或添加对象都标记为灰色 分析工具和分析方法 go的垃圾回收算法是按比例，无分代，与用户代码并发执行，无内存移动并主动向操作系统归还内存的回收算法，所以需要关注的点是：\nCPU利用率 stw的时间和频率 如何针对GC进行优化 调整gc CPU使用率 逃逸分析尽可能将变量分配到栈上 ",
"tags":null,
"categories":null
},{
"title":"Map",
"permalink": "http://localhost:1313/posts/go/map/",
"summary": "go的哈希实现 通用哈希实现 哈希表是一个高效的数据结构，通过对key经过哈希函数计算的值和存储数据的数组的长度，两者求余得到在数组插入的位置。高效的查找效率 时间复杂度为O(1)。\n哈希函数 任意长度的输入有固定输出 同一输入会产生同一个输出 输入的细小改变会造成输入的完全不一样 速度快 单项不可逆 go的哈希底层实现 通过底层结构体hmap来实例化map对象，hmap 包含指向[]bucket数组的指针。bucket结构里面会存储真实的数据 以key1key2 val1value2 的形式进行排列，方便内存对齐。头部有top哈希方便bucket内部进行数据定位，底部有指向溢出bucket的指针。 当发生哈希冲突，冲突的数据会存放到溢出bucket链表。\n插入过程 首先用哈希函数对key计算，得到64位数据（64位机器上）。低B位决定数据落入哪个桶。B是log2count，也就是以2为底bucket元素的长度的对数。 高8位决定落入bucket具体的位置。如果发送哈希冲突，就把数据存入溢出桶。\n遍历过程、查找过程 遍历：从0-bucket长度随机一个数字选择bucket进行遍历。所以go的map是无序。如果bucket遍历完，溢出桶不为空，继续遍历溢出桶。 查找：哈希函数对key计算，低8位找到具体的桶。高8位拿来和bucket的top哈希进行比较，如果一致，再比较具体的key,如果相同就返回， 否则再看溢出桶是否为空，不会空对链表进行遍历。如果都没有就返回查找失败。 go的扩容过程 当哈希函数产生过多的哈希碰撞时，就会导致查询效率低下，为了减少哈希碰撞，需要对底层数组的容量扩容或者对数据进行从新排列。 当满足一下任意条件会触发扩容\n当碰撞因子\u0026gt;6.5, 碰撞因子=count(实际元素个数)/2的B次方（bucket数组总的元素长度） 当溢出桶过多时，当B \u0026lt; 15 , 当溢出桶的个数\u0026gt;B次方，触发扩容。当B\u0026gt;15时，overflow超过2的15次方。 为什么是线程不安全的 sync.map使用 sync.map如何实现的 注意事项",
"content": "go的哈希实现 通用哈希实现 哈希表是一个高效的数据结构，通过对key经过哈希函数计算的值和存储数据的数组的长度，两者求余得到在数组插入的位置。高效的查找效率 时间复杂度为O(1)。\n哈希函数 任意长度的输入有固定输出 同一输入会产生同一个输出 输入的细小改变会造成输入的完全不一样 速度快 单项不可逆 go的哈希底层实现 通过底层结构体hmap来实例化map对象，hmap 包含指向[]bucket数组的指针。bucket结构里面会存储真实的数据 以key1key2 val1value2 的形式进行排列，方便内存对齐。头部有top哈希方便bucket内部进行数据定位，底部有指向溢出bucket的指针。 当发生哈希冲突，冲突的数据会存放到溢出bucket链表。\n插入过程 首先用哈希函数对key计算，得到64位数据（64位机器上）。低B位决定数据落入哪个桶。B是log2count，也就是以2为底bucket元素的长度的对数。 高8位决定落入bucket具体的位置。如果发送哈希冲突，就把数据存入溢出桶。\n遍历过程、查找过程 遍历：从0-bucket长度随机一个数字选择bucket进行遍历。所以go的map是无序。如果bucket遍历完，溢出桶不为空，继续遍历溢出桶。 查找：哈希函数对key计算，低8位找到具体的桶。高8位拿来和bucket的top哈希进行比较，如果一致，再比较具体的key,如果相同就返回， 否则再看溢出桶是否为空，不会空对链表进行遍历。如果都没有就返回查找失败。 go的扩容过程 当哈希函数产生过多的哈希碰撞时，就会导致查询效率低下，为了减少哈希碰撞，需要对底层数组的容量扩容或者对数据进行从新排列。 当满足一下任意条件会触发扩容\n当碰撞因子\u0026gt;6.5, 碰撞因子=count(实际元素个数)/2的B次方（bucket数组总的元素长度） 当溢出桶过多时，当B \u0026lt; 15 , 当溢出桶的个数\u0026gt;B次方，触发扩容。当B\u0026gt;15时，overflow超过2的15次方。 为什么是线程不安全的 sync.map使用 sync.map如何实现的 注意事项 ",
"tags":null,
"categories":null
},{
"title":"Http2_grpc",
"permalink": "http://localhost:1313/posts/network/http2_grpc/",
"summary": "http2 http1的弊端 数据以文本传输，十分低效 header头数据很多 每个tcp链接只能发送一次链接 只能单向传递数据，由浏览器发起 加载无法定义顺序 http2 http2针对这些缺点进行了优化\n对数据进行二进制分帧，基于流传输提高了传输效率，还可以进行流量控制，提升安全性和可靠性 对头数据进行了压缩，采用hpack算法对数据进行压缩，提升了传输效率 采用多路复用，每个tcp连接可以发起任意多的传输请求，减少了tcp的三次握手等频繁建立请求 可以实现服务端推送，从单向传输改为双向传输 可以根据页面不同资源的重要程度设置优先级进行加载 通过以上五个方面http2对h1进行了升级，提高了传输效率，增加更多实现的功能，提升了客户端用户体验。 如何使用 反向代理软件如nginx/apache等设置http2选项 如nginx,首先必须支持ssl/tsl证书，再加上listen 443 ssl http2\ngo的net组件自动支持http2,无需手动升级 grpc rpc rpc是远程过程调用，是一种在不同进程或组件上让函数调用如同本地调用一样的技术。有多种实现，比如json-rpc,xrpc(基于xml),gprc google推出，基于protobuf,通过IDL(接口定义)定义同义的方法和参数，使用代码生成工具生成不同语言的代码。\ngrpc也是基于http2,所以他可以利用http2的各种特性，他有google推出，采用protobuf传输。\n他有以下特点：\n基于IDL生成，接口及定义，可以生成多语言，被客户端和服务端共用。 数据传输效率高，基于http2,拥有双向传输、tcp多路复用、二进制数据帧传输、流量控制等特性 常见于微服务当中，可以方便的定义中间件，进行限流、降级等特性 浏览器一次完整的请求过程 服务器会启动进程监听某个端口，当端口监听到请求，进行处理 通过DNS解析域名拿到目标IP,依次通过浏览器、本地缓存查询，没有就往根dns服务器查询。 如果是http协议需要先通过ssl建立安全通道。 建立TCP连接，通过五元组：协议 ip 端口 目标IP 目标端口 进行三次握手，握手完成后开始发送数据 数据进行封装,数据从应用层（报文）-\u0026gt;传输层（报文+端口号）-\u0026gt;网络IP层（数据段+IP）-\u0026gt;数据链路层(数据包+mac主机物理地址-\u0026gt;数据帧)-\u0026gt;物理层(二进制流)这个层次依次进行传输 通过网络层找到目的主机，通过端口号找到主机监听目的端口的程序。应用程序处理请求。 服务器处理响应，完成后，返回给客户端 断开连接、4次挥手，最后一次等待服务器发送完毕数据 参考资料 https://blog.csdn.net/u012914309/article/details/127507726?spm=1001.2014.3001.5501 ",
"content": "http2 http1的弊端 数据以文本传输，十分低效 header头数据很多 每个tcp链接只能发送一次链接 只能单向传递数据，由浏览器发起 加载无法定义顺序 http2 http2针对这些缺点进行了优化\n对数据进行二进制分帧，基于流传输提高了传输效率，还可以进行流量控制，提升安全性和可靠性 对头数据进行了压缩，采用hpack算法对数据进行压缩，提升了传输效率 采用多路复用，每个tcp连接可以发起任意多的传输请求，减少了tcp的三次握手等频繁建立请求 可以实现服务端推送，从单向传输改为双向传输 可以根据页面不同资源的重要程度设置优先级进行加载 通过以上五个方面http2对h1进行了升级，提高了传输效率，增加更多实现的功能，提升了客户端用户体验。 如何使用 反向代理软件如nginx/apache等设置http2选项 如nginx,首先必须支持ssl/tsl证书，再加上listen 443 ssl http2\ngo的net组件自动支持http2,无需手动升级 grpc rpc rpc是远程过程调用，是一种在不同进程或组件上让函数调用如同本地调用一样的技术。有多种实现，比如json-rpc,xrpc(基于xml),gprc google推出，基于protobuf,通过IDL(接口定义)定义同义的方法和参数，使用代码生成工具生成不同语言的代码。\ngrpc也是基于http2,所以他可以利用http2的各种特性，他有google推出，采用protobuf传输。\n他有以下特点：\n基于IDL生成，接口及定义，可以生成多语言，被客户端和服务端共用。 数据传输效率高，基于http2,拥有双向传输、tcp多路复用、二进制数据帧传输、流量控制等特性 常见于微服务当中，可以方便的定义中间件，进行限流、降级等特性 浏览器一次完整的请求过程 服务器会启动进程监听某个端口，当端口监听到请求，进行处理 通过DNS解析域名拿到目标IP,依次通过浏览器、本地缓存查询，没有就往根dns服务器查询。 如果是http协议需要先通过ssl建立安全通道。 建立TCP连接，通过五元组：协议 ip 端口 目标IP 目标端口 进行三次握手，握手完成后开始发送数据 数据进行封装,数据从应用层（报文）-\u0026gt;传输层（报文+端口号）-\u0026gt;网络IP层（数据段+IP）-\u0026gt;数据链路层(数据包+mac主机物理地址-\u0026gt;数据帧)-\u0026gt;物理层(二进制流)这个层次依次进行传输 通过网络层找到目的主机，通过端口号找到主机监听目的端口的程序。应用程序处理请求。 服务器处理响应，完成后，返回给客户端 断开连接、4次挥手，最后一次等待服务器发送完毕数据 参考资料 https://blog.csdn.net/u012914309/article/details/127507726?spm=1001.2014.3001.5501 ",
"tags":null,
"categories":null
},{
"title":"CAP",
"permalink": "http://localhost:1313/posts/architecture/cap/",
"summary": "定义 CAP理论是指分布式当中一致性、可用性以及分区容错性三者不可兼得。我们需要根据实际应用场景做出相应的取舍， 在现实中，一般来说分布式系统中的网络是不可能完全保证可用的，所以就需要在CA和CP中做出选择。\nc一致性(consistency) 同一份数据同一时间在不同的节点看到的结果应该是一致性的\na可用性（availability） 当系统当中某些节点故障仍然可以在一定时间内响应用户请求，也就是说系统在任何时间对于非错请求都能在一定时间做出响应，且不返回错误。\np分区容错性（partition tolerance） 当集群中发生网络分区，因为网络故障导致节点之间不能正常通信，系统仍然正常运行，能够对外提供服务。\n拜占庭将军问题 是指分布式系统中可能有恶意节点对数据一致性造成破坏。如果系统中的节点是f个，为了解决非拜占庭将军问题，至少需要3f+1 个节点。能容忍拜占庭容错的系统一般是高安全性要求的系统，比如区跨链、金融、军事等。\n脑裂 脑裂是指分布式系统中由于网络波动或中断，导致系统被分成多个子系统，子系统在内部选举leader，对外提供服务。这会导致 严重的问题，比如\n数据不一致\t两个分区同时写入同一数据（如账户余额），导致冲突且无法自动合并。 资源冲突\t两个“领导者”同时操作共享资源（如分配同一IP地址、锁定同一文件）。 状态混乱\t客户端可能被不同分区响应矛盾的结果（如A分区说“支付成功”，B分区说“未支付”）。 数据永久丢失\t分区恢复后，冲突写入可能导致部分数据被覆盖或丢弃。 为了防止脑裂，一般分布式一致性协议都会采用多数派原则进行避免，比如五个节点的分布式系统中，需要3个节点的确认才能成为leader,否则会 因为无法选主而停止对外提供服务。\nraft协议 raft协议是分布式系统中多个节点对于某个资源的一致性的达成所采用的一种协议，主要有三个部分：\n主从选择 日志复制 安全性和一致性保证 raft协议是强一致的。还有一些其他的一致性组件比如zookeeper。raft协议提供了强一致性的方案。 zookeeper 实践 常见的使用场景 一些常见的开源软件的使用我们会经常遇到这个场景。拿最常见的redis为例，redis的分布式部署方案有三种，主从、哨兵、cluster。\ngo 简单的实践 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/hashicorp/raft\u0026#34; bolt \u0026#34;github.com/hashicorp/raft-boltdb\u0026#34; ) // 简单的 FSM：提交即打印 type FSM struct{} func (f *FSM) Apply(l *raft.Log) interface{} { fmt.Printf(\u0026#34;Apply: %s\\n\u0026#34;, string(l.Data)) return nil } func (f *FSM) Snapshot() (raft.FSMSnapshot, error) { return \u0026amp;snapshot{}, nil } func (f *FSM) Restore(io.ReadCloser) error { return nil } type snapshot struct{} func (s *snapshot) Persist(sink raft.SnapshotSink) error { return sink.Close() } func (s *snapshot) Release() {} func main() { // 1) 配置 config := raft.DefaultConfig() config.LocalID = raft.ServerID(os.Args[1]) // 节点 ID 来自第一个参数 // 2) 网络传输：TCP addr, err := net.ResolveTCPAddr(\u0026#34;tcp\u0026#34;, os.Args[2]) if err != nil { log.Fatal(err) } transport, err := raft.NewTCPTransport(os.Args[2], addr, 3, 10*time.Second, os.Stdout) if err != nil { log.Fatal(err) } // 3) 日志与快照存储 store, err := bolt.NewBoltStore(fmt.Sprintf(\u0026#34;raft-%s.db\u0026#34;, os.Args[1])) if err != nil { log.Fatal(err) } snapshotStore := raft.NewInmemSnapshotStore() // 4) 创建 Raft 实例 r, err := raft.NewRaft(config, \u0026amp;FSM{}, store, store, snapshotStore, transport) if err != nil { log.Fatal(err) } // 5) Bootstrap 第一个节点 if os.Args[1] == \u0026#34;node1\u0026#34; { cfg := raft.Configuration{ Servers: []raft.Server{ {ID: \u0026#34;node1\u0026#34;, Address: transport.LocalAddr()}, {ID: \u0026#34;node2\u0026#34;, Address: raft.ServerAddress(\u0026#34;127.0.0.1:12002\u0026#34;)}, {ID: \u0026#34;node3\u0026#34;, Address: raft.ServerAddress(\u0026#34;127.0.0.1:12003\u0026#34;)}, }, } r.BootstrapCluster(cfg) } // 6) 简单命令行提交 if config.LocalID == \u0026#34;node1\u0026#34; { go func() { for { time.Sleep(3 * time.Second) f := r.Apply([]byte(\u0026#34;hello raft\u0026#34;), 5*time.Second) if err := f.Error(); err != nil { log.Println(\u0026#34;apply error:\u0026#34;, err) } } }() } select {} // 阻塞 } `\n",
"content": "定义 CAP理论是指分布式当中一致性、可用性以及分区容错性三者不可兼得。我们需要根据实际应用场景做出相应的取舍， 在现实中，一般来说分布式系统中的网络是不可能完全保证可用的，所以就需要在CA和CP中做出选择。\nc一致性(consistency) 同一份数据同一时间在不同的节点看到的结果应该是一致性的\na可用性（availability） 当系统当中某些节点故障仍然可以在一定时间内响应用户请求，也就是说系统在任何时间对于非错请求都能在一定时间做出响应，且不返回错误。\np分区容错性（partition tolerance） 当集群中发生网络分区，因为网络故障导致节点之间不能正常通信，系统仍然正常运行，能够对外提供服务。\n拜占庭将军问题 是指分布式系统中可能有恶意节点对数据一致性造成破坏。如果系统中的节点是f个，为了解决非拜占庭将军问题，至少需要3f+1 个节点。能容忍拜占庭容错的系统一般是高安全性要求的系统，比如区跨链、金融、军事等。\n脑裂 脑裂是指分布式系统中由于网络波动或中断，导致系统被分成多个子系统，子系统在内部选举leader，对外提供服务。这会导致 严重的问题，比如\n数据不一致\t两个分区同时写入同一数据（如账户余额），导致冲突且无法自动合并。 资源冲突\t两个“领导者”同时操作共享资源（如分配同一IP地址、锁定同一文件）。 状态混乱\t客户端可能被不同分区响应矛盾的结果（如A分区说“支付成功”，B分区说“未支付”）。 数据永久丢失\t分区恢复后，冲突写入可能导致部分数据被覆盖或丢弃。 为了防止脑裂，一般分布式一致性协议都会采用多数派原则进行避免，比如五个节点的分布式系统中，需要3个节点的确认才能成为leader,否则会 因为无法选主而停止对外提供服务。\nraft协议 raft协议是分布式系统中多个节点对于某个资源的一致性的达成所采用的一种协议，主要有三个部分：\n主从选择 日志复制 安全性和一致性保证 raft协议是强一致的。还有一些其他的一致性组件比如zookeeper。raft协议提供了强一致性的方案。 zookeeper 实践 常见的使用场景 一些常见的开源软件的使用我们会经常遇到这个场景。拿最常见的redis为例，redis的分布式部署方案有三种，主从、哨兵、cluster。\ngo 简单的实践 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/hashicorp/raft\u0026#34; bolt \u0026#34;github.com/hashicorp/raft-boltdb\u0026#34; ) // 简单的 FSM：提交即打印 type FSM struct{} func (f *FSM) Apply(l *raft.Log) interface{} { fmt.Printf(\u0026#34;Apply: %s\\n\u0026#34;, string(l.Data)) return nil } func (f *FSM) Snapshot() (raft.FSMSnapshot, error) { return \u0026amp;snapshot{}, nil } func (f *FSM) Restore(io.ReadCloser) error { return nil } type snapshot struct{} func (s *snapshot) Persist(sink raft.SnapshotSink) error { return sink.Close() } func (s *snapshot) Release() {} func main() { // 1) 配置 config := raft.DefaultConfig() config.LocalID = raft.ServerID(os.Args[1]) // 节点 ID 来自第一个参数 // 2) 网络传输：TCP addr, err := net.ResolveTCPAddr(\u0026#34;tcp\u0026#34;, os.Args[2]) if err != nil { log.Fatal(err) } transport, err := raft.NewTCPTransport(os.Args[2], addr, 3, 10*time.Second, os.Stdout) if err != nil { log.Fatal(err) } // 3) 日志与快照存储 store, err := bolt.NewBoltStore(fmt.Sprintf(\u0026#34;raft-%s.db\u0026#34;, os.Args[1])) if err != nil { log.Fatal(err) } snapshotStore := raft.NewInmemSnapshotStore() // 4) 创建 Raft 实例 r, err := raft.NewRaft(config, \u0026amp;FSM{}, store, store, snapshotStore, transport) if err != nil { log.Fatal(err) } // 5) Bootstrap 第一个节点 if os.Args[1] == \u0026#34;node1\u0026#34; { cfg := raft.Configuration{ Servers: []raft.Server{ {ID: \u0026#34;node1\u0026#34;, Address: transport.LocalAddr()}, {ID: \u0026#34;node2\u0026#34;, Address: raft.ServerAddress(\u0026#34;127.0.0.1:12002\u0026#34;)}, {ID: \u0026#34;node3\u0026#34;, Address: raft.ServerAddress(\u0026#34;127.0.0.1:12003\u0026#34;)}, }, } r.BootstrapCluster(cfg) } // 6) 简单命令行提交 if config.LocalID == \u0026#34;node1\u0026#34; { go func() { for { time.Sleep(3 * time.Second) f := r.Apply([]byte(\u0026#34;hello raft\u0026#34;), 5*time.Second) if err := f.Error(); err != nil { log.Println(\u0026#34;apply error:\u0026#34;, err) } } }() } select {} // 阻塞 } `\n执行 go run main.go node1 127.0.0.1:12001 执行 go run main.go node1 127.0.0.1:12002 执行 go run main.go node1 127.0.0.1:12003 停掉node1 会重新触发选主 ` 拓展点-状态机 状态机可以看作是ifelse 的封装将强版本，更容易集中管理动作之后状态的变更。\n特点 FSM（如 looplab/fsm） 传统 if-else 结构清晰 明确状态转换图，逻辑集中 逻辑分散，耦合高 易于扩展 增加状态只需配置 增加逻辑可能动很多 if 便于测试 每个状态转换可单测 if else 混杂，不好测 可视化 易转为状态图 很难 条件钩子 before_event/after_event 很方便 手写控制流程 状态合法性控制 内建校验非法状态跳转 自己加判断 使用开源库可以感受一下\npackage workflow import ( \u0026#34;errors\u0026#34; \u0026#34;github.com/looplab/fsm\u0026#34; ) // 所有可能的状态 const ( StateA = \u0026#34;A_PENDING\u0026#34; // 初始由 A 审批 StateCountersign = \u0026#34;COUNTERSIGN_PENDING\u0026#34;// B、C 会签阶段 StateD = \u0026#34;D_PENDING\u0026#34; // D 审批 StateE = \u0026#34;E_PENDING\u0026#34; // E 审批 StateDone = \u0026#34;APPROVED\u0026#34; // 最终审批通过 StateRejected = \u0026#34;REJECTED\u0026#34; // 流程终止（可选） ) // 事件名 const ( EventAApprove = \u0026#34;a_approve\u0026#34; EventACancel = \u0026#34;a_cancel\u0026#34; // A 拒绝或撤回 EventCountersignOK = \u0026#34;countersign_ok\u0026#34; // B、C 会签完成（都同意） EventDCancel = \u0026#34;d_reject\u0026#34; // D 拒绝 EventDApprove = \u0026#34;d_approve\u0026#34; EventECancel = \u0026#34;e_reject\u0026#34; // E 拒绝 EventEApprove = \u0026#34;e_approve\u0026#34; ) // NewWorkflowFSM 创建并返回一个基于当前状态的 FSM func NewWorkflowFSM(currentState string) *fsm.FSM { return fsm.NewFSM( currentState, fsm.Events{ // A 同意，进入会签阶段 {Name: EventAApprove, Src: []string{StateA}, Dst: StateCountersign}, // 会签完成后，进入 D 阶段 {Name: EventCountersignOK, Src: []string{StateCountersign}, Dst: StateD}, // D 同意，进入 E {Name: EventDApprove, Src: []string{StateD}, Dst: StateE}, // E 同意，整个流程完成 {Name: EventEApprove, Src: []string{StateE}, Dst: StateDone}, // 驳回／回退逻辑 {Name: EventDCancel, Src: []string{StateD}, Dst: StateA}, {Name: EventECancel, Src: []string{StateE}, Dst: StateD}, {Name: EventACancel, Src: []string{StateA, StateCountersign}, Dst: StateRejected}, }, fsm.Callbacks{ \u0026#34;enter_state\u0026#34;: func(e *fsm.Event) { // 通用进状态日志；也可针对具体状态做扩展 // fmt.Printf(\u0026#34;Transition: %s -\u0026gt; %s via %s\\n\u0026#34;, e.Src, e.Dst, e.Event) }, }, ) } // 业务层调用示例： // wf := NewWorkflowFSM(dbRecord.State) // if err := wf.Event(EventAApprove); err != nil { … } // dbRecord.State = wf.Current() // save(dbRecord) type ApprovalRecord struct { ID string State string // 存储在 DB：FSM 当前状态 ApprovedByB bool ApprovedByC bool } // B、C 审批 API 调用示例 func ApproveByB(record *ApprovalRecord) error { if record.State != StateCountersign { return errors.New(\u0026#34;不在会签阶段\u0026#34;) } record.ApprovedByB = true return tryFinishCountersign(record) } func ApproveByC(record *ApprovalRecord) error { if record.State != StateCountersign { return errors.New(\u0026#34;不在会签阶段\u0026#34;) } record.ApprovedByC = true return tryFinishCountersign(record) } // 当 B、C 都同意后，触发 FSM 的 countersign_ok func tryFinishCountersign(record *ApprovalRecord) error { if record.ApprovedByB \u0026amp;\u0026amp; record.ApprovedByC { wf := NewWorkflowFSM(record.State) if err := wf.Event(EventCountersignOK); err != nil { return err } record.State = wf.Current() // 持久化 record.State、ApprovedByB/C 到数据库 } return nil } redis 的sentinel 和cluster redis有两种分布式部署方案，分别是sentinel哨兵实现主从架构，哨兵负责监控和主节点下线之后的选主。cluster实现数据分片 和主从切换。\n哨兵只有一个主节点，cluster模式通常有多个主节点。cluster要求至少需要三主三从，cluster如果请求的数据不在当前节点会返回moved和ask,需要支持 cluster的客户端进行重定向，比如go-redis等。\n需要注意的是在分布式部署下，分布式锁都会出现问题，比如redis sentinel模式下主从切换、客户端未感知主从切换导致锁失效。 cluster模式下会出现不能多key操作以及sentinel出现的主备切换客户端无法感知等问题。\n数据分片 数据分片是指将一个大数据集按照某个规则分散成较小的数据集\n注意事项 这个理论提醒我们在分布式系统中需要根据具体的需求做出取舍。 raft协议的只保证写强一致，对于读默认是从leader读就没问题，如果从follower可能会不一致。需要注意 raft协议是在非拜占庭情况下为了达成一致性的一种协议，需要注意这点。 raft协议的组件不适合做分布式锁的实现，因为分布式锁一般对性能要求比较高，而raft需要写日志，同步等比较费时的操作。 redis分布式锁在分布式部署情况下的问题 简单来说需要把所有锁操作限定到一个槽里面，其次可以使用开源的解决方案比如redLock,以及优秀的redis客户端在发生key在其他节点会自动帮助我们 处理move操作\n参考资料 维基百科编者. CAP定理. 维基百科. 最后修订于2023年11月9日. 访问于2025年7月16日. CNBLOG. ZooKeeper 是什么. 维基百科. 最后修订于2020-12-30 10:53. 访问于2025年7月20日. DTM. DTM. 访问于2025年8月20日. ",
"tags":null,
"categories":null
},{
"title":"Socket",
"permalink": "http://localhost:1313/posts/network/socket/",
"summary": "Socket IO模型 常见的IO模型有四种：多进程、多线程、IO复用、协程\n多进程：最原始的一种模式，好处是开发难度小，同一个进程共享内容，缺点是创建和销毁的成本很高。常见的比如php的php-fpm 多线程：相比于多进程开销更小，但是遇到C10K问题还是会出现瓶颈，线程的内存占用通常以M为单位。提高了效率，但是遇到高并发，资源占用还是比较大。常见的比如java的多线程 IO模型: 基于事件的IO处理机制，是单线程模型，通过监听文件句柄socket,注册事件， 当有IO事件发生时，会触发回调函数。由于在单线程模型，开销更小，适合处理高并发。常见的如nodejs、redis。 协程: 协程是态线程，协程的切换开销小，通常以kb为单位，通常一个协程只占用4KB，适合处理高并发。常见的如go语言。 Socket定义 socket是应用层和传输层的一组API接口，用于实现网络通信。 linux当中一切皆文件，操作系统为了统一处理IO模型，将socket也视作文件句柄。\n特性 普通文件 Socket（网络文件） 底层对象 struct inode + struct file struct socket + struct file 操作集 read/write 操作读写磁盘数据 recv/send（也支持 read/write，最终映射到网络收发） 偏移量（offset） 有，指示文件读写位置 无意义，总是以流／报文方式收发 阻塞／非阻塞 可设置阻塞或非阻塞 同样支持阻塞模式和非阻塞模式 I/O 多路复用 支持 select/poll/epoll 完全支持 通过监听文件句柄，结合select/pull/epoll, 可以实现网络编程。\nwebsocket websocket是一种基于http的协议，用于浏览器和服务器之间进行长连接实时通信。一般会通过对http请求升级upgrade，将http协议升级为websocket协议。\n如何使用 tcp连接需要指定五元组：ip、端口、协议、源ip、源端口，同样的socket也需要指定这些参数。 server端的建立过程：\nsocket() bind() listen() accept() close client端的建立过程：\nsocket() connect() accept() close() 代码示例 原始方案，使用net包:\nsever端\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;syscall\u0026#34; ) func check(err error) { if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;错误：\u0026#34;, err) os.Exit(1) } } func main() { // 1. 创建 socket fd, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_STREAM, syscall.IPPROTO_TCP) check(err) defer syscall.Close(fd) // 2. 绑定到本地地址 0.0.0.0:8888 sa := \u0026amp;syscall.SockaddrInet4{Port: 8888} // IP 全 0 表示 INADDR_ANY check(syscall.Bind(fd, sa)) // 3. 开始监听（backlog 128） check(syscall.Listen(fd, 128)) fmt.Println(\u0026#34;raw socket 服务器已启动，端口 8888\u0026#34;) // 4. 接受连接 nfd, rsa, err := syscall.Accept(fd) check(err) fmt.Printf(\u0026#34;接收到客户端：%v\\n\u0026#34;, rsa) defer syscall.Close(nfd) // 5. 全双工：一个 goroutine 从 stdin 发出去，一个 goroutine 从 socket 读进来 go func() { buf := make([]byte, 1024) for { // 从标准输入读 n, err := syscall.Read(syscall.Stdin, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;stdin 读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { _, err = syscall.Write(nfd, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;向客户端写入错误：\u0026#34;, err) return } } } }() // 主 goroutine 负责从 socket 读并写到 stdout buf := make([]byte, 1024) for { n, err := syscall.Read(nfd, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;从客户端读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { // 打印到标准输出 _, err = syscall.Write(syscall.Stdout, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;写到 stdout 错误：\u0026#34;, err) return } } } } client端\n",
"content": "Socket IO模型 常见的IO模型有四种：多进程、多线程、IO复用、协程\n多进程：最原始的一种模式，好处是开发难度小，同一个进程共享内容，缺点是创建和销毁的成本很高。常见的比如php的php-fpm 多线程：相比于多进程开销更小，但是遇到C10K问题还是会出现瓶颈，线程的内存占用通常以M为单位。提高了效率，但是遇到高并发，资源占用还是比较大。常见的比如java的多线程 IO模型: 基于事件的IO处理机制，是单线程模型，通过监听文件句柄socket,注册事件， 当有IO事件发生时，会触发回调函数。由于在单线程模型，开销更小，适合处理高并发。常见的如nodejs、redis。 协程: 协程是态线程，协程的切换开销小，通常以kb为单位，通常一个协程只占用4KB，适合处理高并发。常见的如go语言。 Socket定义 socket是应用层和传输层的一组API接口，用于实现网络通信。 linux当中一切皆文件，操作系统为了统一处理IO模型，将socket也视作文件句柄。\n特性 普通文件 Socket（网络文件） 底层对象 struct inode + struct file struct socket + struct file 操作集 read/write 操作读写磁盘数据 recv/send（也支持 read/write，最终映射到网络收发） 偏移量（offset） 有，指示文件读写位置 无意义，总是以流／报文方式收发 阻塞／非阻塞 可设置阻塞或非阻塞 同样支持阻塞模式和非阻塞模式 I/O 多路复用 支持 select/poll/epoll 完全支持 通过监听文件句柄，结合select/pull/epoll, 可以实现网络编程。\nwebsocket websocket是一种基于http的协议，用于浏览器和服务器之间进行长连接实时通信。一般会通过对http请求升级upgrade，将http协议升级为websocket协议。\n如何使用 tcp连接需要指定五元组：ip、端口、协议、源ip、源端口，同样的socket也需要指定这些参数。 server端的建立过程：\nsocket() bind() listen() accept() close client端的建立过程：\nsocket() connect() accept() close() 代码示例 原始方案，使用net包:\nsever端\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;syscall\u0026#34; ) func check(err error) { if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;错误：\u0026#34;, err) os.Exit(1) } } func main() { // 1. 创建 socket fd, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_STREAM, syscall.IPPROTO_TCP) check(err) defer syscall.Close(fd) // 2. 绑定到本地地址 0.0.0.0:8888 sa := \u0026amp;syscall.SockaddrInet4{Port: 8888} // IP 全 0 表示 INADDR_ANY check(syscall.Bind(fd, sa)) // 3. 开始监听（backlog 128） check(syscall.Listen(fd, 128)) fmt.Println(\u0026#34;raw socket 服务器已启动，端口 8888\u0026#34;) // 4. 接受连接 nfd, rsa, err := syscall.Accept(fd) check(err) fmt.Printf(\u0026#34;接收到客户端：%v\\n\u0026#34;, rsa) defer syscall.Close(nfd) // 5. 全双工：一个 goroutine 从 stdin 发出去，一个 goroutine 从 socket 读进来 go func() { buf := make([]byte, 1024) for { // 从标准输入读 n, err := syscall.Read(syscall.Stdin, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;stdin 读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { _, err = syscall.Write(nfd, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;向客户端写入错误：\u0026#34;, err) return } } } }() // 主 goroutine 负责从 socket 读并写到 stdout buf := make([]byte, 1024) for { n, err := syscall.Read(nfd, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;从客户端读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { // 打印到标准输出 _, err = syscall.Write(syscall.Stdout, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;写到 stdout 错误：\u0026#34;, err) return } } } } client端\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;syscall\u0026#34; ) func check(err error) { if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;错误：\u0026#34;, err) os.Exit(1) } } func main() { // 1. 创建 socket fd, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_STREAM, syscall.IPPROTO_TCP) check(err) defer syscall.Close(fd) // 2. 连接到服务器 127.0.0.1:8888 sa := \u0026amp;syscall.SockaddrInet4{Port: 8888} copy(sa.Addr[:], []byte{127, 0, 0, 1}) check(syscall.Connect(fd, sa)) fmt.Println(\u0026#34;raw socket 已连接到 127.0.0.1:8888\u0026#34;) // 3. 全双工：一个 goroutine 从 stdin 发出去，一个从 socket 读进来 go func() { buf := make([]byte, 1024) for { n, err := syscall.Read(syscall.Stdin, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;stdin 读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { _, err = syscall.Write(fd, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;写到服务器错误：\u0026#34;, err) return } } } }() // 主 goroutine 负责从 socket 读并写到 stdout buf := make([]byte, 1024) for { n, err := syscall.Read(fd, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;从服务器读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { _, err = syscall.Write(syscall.Stdout, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;写到 stdout 错误：\u0026#34;, err) return } } } } 封装成net包，代码更简洁。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; ) func main() { // socket bind listen con, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:8099\u0026#34;) if err != nil { panic(err) } conn, err := con.Accept() go func() { if _, err := io.Copy(conn, os.Stdin); err != nil { fmt.Errorf(\u0026#34;server to client :%w\u0026#34;, err) } }() if _, err := io.Copy(os.Stdout, conn); err != nil { fmt.Errorf(\u0026#34;from client :%w\u0026#34;, err) } } client端\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; ) func main() { // socket connect conn, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:8099\u0026#34;) if err != nil { panic(err) } go func() { if _, err := io.Copy(conn, os.Stdin); err != nil { fmt.Errorf(\u0026#34; to server :%w\u0026#34;, err) } }() if _, err := io.Copy(os.Stdout, conn); err != nil { fmt.Errorf(\u0026#34;from server :%w\u0026#34;, err) } } 注意事项 注意关闭文件句柄 实现高可用，需要处理重试逻辑 ",
"tags":null,
"categories":null
},{
"title":"BFS\u0026\u0026DFS",
"permalink": "http://localhost:1313/posts/datastructalgorithm/bfs_dfs/",
"summary": "树的遍历 深度优先遍历DFS package main import \u0026#34;fmt\u0026#34; func main() { root := \u0026amp;TreeNode{ Val: 1, } root.Left = \u0026amp;TreeNode{Val: 2} root.Right = \u0026amp;TreeNode{Val: 3} root.Right.Left = \u0026amp;TreeNode{Val: 4} root.Left.Left = \u0026amp;TreeNode{Val: 5} list := make([]int, 0) var treeDFS = func(root *TreeNode) {} treeDFS = func(root *TreeNode) { if root == nil { return } list = append(list, root.Val) treeDFS(root.Left) treeDFS(root.Right) } treeDFS(root) fmt.Println(list) //list2 := TreeBFS(root) //fmt.Println(list2) } type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 函数版本\npackage main import \u0026#34;fmt\u0026#34; func main() { root := \u0026amp;TreeNode{ Val: 1, } root.Left = \u0026amp;TreeNode{Val: 2} root.Right = \u0026amp;TreeNode{Val: 3} root.Right.Left = \u0026amp;TreeNode{Val: 4} root.Left.Left = \u0026amp;TreeNode{Val: 5} list := make([]int, 0) TreeDFS(root, \u0026amp;list) fmt.Println(list) //list2 := TreeBFS(root) //fmt.Println(list2) } func TreeDFS(root *TreeNode, list *[]int) { if root == nil { return } *list = append(*list, root.Val) TreeDFS(root.Left, list) TreeDFS(root.Right, list) } type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 广度优先遍历BFS list2 := make([]int, 0) queue := make([]*TreeNode, 0) queue = append(queue, root) for len(queue) \u0026gt; 0 { count := len(queue) for i := 0; i \u0026lt; count; i++ { node := queue[0] queue = queue[1:] list2 = append(list2, node.Val) if node.Left != nil { queue = append(queue, node.Left) } if node.Right != nil { queue = append(queue, node.Right) } } } fmt.Println(list2) 根据先序遍历和中序遍历构造二叉树 package main import \u0026#34;fmt\u0026#34; func main() { // 1 // [1 2 5 3 4] 先序 // [2 5 1 3 4] 中序 // 1 [2 5] [2 5] i = 2 [3 4] // [2 5 3 4] [2 5] // [5 3 4] [5] copyTreeRoot := BuildTree([]int{1, 2, 5, 3, 4}, []int{2, 5, 1, 3, 4}) fmt.Println(copyTreeRoot) list3 := make([]int, 0) TreeDFS(copyTreeRoot, \u0026amp;list3) fmt.Println(\u0026#34;list3:\u0026#34;, list3) //SliceTest() } func BuildTree(first []int, mid []int) *TreeNode { if len(first) == 0 { return nil } root := \u0026amp;TreeNode{Val: first[0]} node := first[0] i := 0 for ; i \u0026lt; len(mid); i++ { if mid[i] == node { break } } root.Left = BuildTree(first[1:i+1], mid[:i]) root.Right = BuildTree(first[i+1:], mid[i+1:]) return root } 图的遍历 深度优先遍历DFS \u0026amp;\u0026amp; 广度优先遍历BFS package main import ( \u0026#34;container/list\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { // 0 // 1 -\u0026gt; 4 -\u0026gt; 5 // 0 2 -\u0026gt; 6 -\u0026gt; 7 // 3 -\u0026gt;^ g := make([][]int, 8) //g = append(g, []int{1, 2, 3} g[0] = []int{1, 2, 3} g[1] = []int{4} g[2] = []int{6} g[3] = []int{6} g[4] = []int{5} g[6] = []int{7} g2 := make(map[int][]int) g2[0] = []int{1, 2, 3} g2[1] = []int{4} g2[2] = []int{6} g2[3] = []int{6} g2[4] = []int{5} g2[6] = []int{7} graphDFS(0, g) //graphBFS(g) fmt.Println(\u0026#34;-----\u0026#34;) graphBFSWithQueue(g2) fmt.Println(\u0026#34;-----\u0026#34;) listC := graphBFSWithC(g2) fmt.Println(listC) } func graphDFS(root int, graph [][]int) { fmt.Println(root) if graph[root] == nil { return } //fmt.Println(root) for i := 0; i \u0026lt; len(graph[root]); i++ { graphDFS(graph[root][i], graph) } return } func graphBFSWithQueue(graph map[int][]int) { queue := make([]int, 0) queue = append(queue, 0) fmt.Println(0) visited := make(map[int]bool) for len(queue) \u0026gt; 0 { node := queue[0] queue = queue[1:] g := graph[node] size := len(g) for i := 0; i \u0026lt; size; i++ { if visited[g[i]] { continue } else { fmt.Println(g[i]) queue = append(queue, g[i]) visited[g[i]] = true } } } } func graphBFSWithC(graph map[int][]int) []int { queue := list.New() order := make([]int, 0) visited := make(map[int]bool) queue.PushBack(0) for queue.Len() \u0026gt; 0 { node := queue.Remove(queue.Front()).(int) order = append(order, node) neighbor := graph[node] size := len(neighbor) for i := 0; i \u0026lt; size; i++ { if visited[neighbor[i]] { continue } else { queue.PushBack(neighbor[i]) visited[neighbor[i]] = true } } } return order } 带权图的最短路径算法 dijkstra 参考 可视化网站. 可视化网站. ",
"content": "树的遍历 深度优先遍历DFS package main import \u0026#34;fmt\u0026#34; func main() { root := \u0026amp;TreeNode{ Val: 1, } root.Left = \u0026amp;TreeNode{Val: 2} root.Right = \u0026amp;TreeNode{Val: 3} root.Right.Left = \u0026amp;TreeNode{Val: 4} root.Left.Left = \u0026amp;TreeNode{Val: 5} list := make([]int, 0) var treeDFS = func(root *TreeNode) {} treeDFS = func(root *TreeNode) { if root == nil { return } list = append(list, root.Val) treeDFS(root.Left) treeDFS(root.Right) } treeDFS(root) fmt.Println(list) //list2 := TreeBFS(root) //fmt.Println(list2) } type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 函数版本\npackage main import \u0026#34;fmt\u0026#34; func main() { root := \u0026amp;TreeNode{ Val: 1, } root.Left = \u0026amp;TreeNode{Val: 2} root.Right = \u0026amp;TreeNode{Val: 3} root.Right.Left = \u0026amp;TreeNode{Val: 4} root.Left.Left = \u0026amp;TreeNode{Val: 5} list := make([]int, 0) TreeDFS(root, \u0026amp;list) fmt.Println(list) //list2 := TreeBFS(root) //fmt.Println(list2) } func TreeDFS(root *TreeNode, list *[]int) { if root == nil { return } *list = append(*list, root.Val) TreeDFS(root.Left, list) TreeDFS(root.Right, list) } type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 广度优先遍历BFS list2 := make([]int, 0) queue := make([]*TreeNode, 0) queue = append(queue, root) for len(queue) \u0026gt; 0 { count := len(queue) for i := 0; i \u0026lt; count; i++ { node := queue[0] queue = queue[1:] list2 = append(list2, node.Val) if node.Left != nil { queue = append(queue, node.Left) } if node.Right != nil { queue = append(queue, node.Right) } } } fmt.Println(list2) 根据先序遍历和中序遍历构造二叉树 package main import \u0026#34;fmt\u0026#34; func main() { // 1 // [1 2 5 3 4] 先序 // [2 5 1 3 4] 中序 // 1 [2 5] [2 5] i = 2 [3 4] // [2 5 3 4] [2 5] // [5 3 4] [5] copyTreeRoot := BuildTree([]int{1, 2, 5, 3, 4}, []int{2, 5, 1, 3, 4}) fmt.Println(copyTreeRoot) list3 := make([]int, 0) TreeDFS(copyTreeRoot, \u0026amp;list3) fmt.Println(\u0026#34;list3:\u0026#34;, list3) //SliceTest() } func BuildTree(first []int, mid []int) *TreeNode { if len(first) == 0 { return nil } root := \u0026amp;TreeNode{Val: first[0]} node := first[0] i := 0 for ; i \u0026lt; len(mid); i++ { if mid[i] == node { break } } root.Left = BuildTree(first[1:i+1], mid[:i]) root.Right = BuildTree(first[i+1:], mid[i+1:]) return root } 图的遍历 深度优先遍历DFS \u0026amp;\u0026amp; 广度优先遍历BFS package main import ( \u0026#34;container/list\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { // 0 // 1 -\u0026gt; 4 -\u0026gt; 5 // 0 2 -\u0026gt; 6 -\u0026gt; 7 // 3 -\u0026gt;^ g := make([][]int, 8) //g = append(g, []int{1, 2, 3} g[0] = []int{1, 2, 3} g[1] = []int{4} g[2] = []int{6} g[3] = []int{6} g[4] = []int{5} g[6] = []int{7} g2 := make(map[int][]int) g2[0] = []int{1, 2, 3} g2[1] = []int{4} g2[2] = []int{6} g2[3] = []int{6} g2[4] = []int{5} g2[6] = []int{7} graphDFS(0, g) //graphBFS(g) fmt.Println(\u0026#34;-----\u0026#34;) graphBFSWithQueue(g2) fmt.Println(\u0026#34;-----\u0026#34;) listC := graphBFSWithC(g2) fmt.Println(listC) } func graphDFS(root int, graph [][]int) { fmt.Println(root) if graph[root] == nil { return } //fmt.Println(root) for i := 0; i \u0026lt; len(graph[root]); i++ { graphDFS(graph[root][i], graph) } return } func graphBFSWithQueue(graph map[int][]int) { queue := make([]int, 0) queue = append(queue, 0) fmt.Println(0) visited := make(map[int]bool) for len(queue) \u0026gt; 0 { node := queue[0] queue = queue[1:] g := graph[node] size := len(g) for i := 0; i \u0026lt; size; i++ { if visited[g[i]] { continue } else { fmt.Println(g[i]) queue = append(queue, g[i]) visited[g[i]] = true } } } } func graphBFSWithC(graph map[int][]int) []int { queue := list.New() order := make([]int, 0) visited := make(map[int]bool) queue.PushBack(0) for queue.Len() \u0026gt; 0 { node := queue.Remove(queue.Front()).(int) order = append(order, node) neighbor := graph[node] size := len(neighbor) for i := 0; i \u0026lt; size; i++ { if visited[neighbor[i]] { continue } else { queue.PushBack(neighbor[i]) visited[neighbor[i]] = true } } } return order } 带权图的最短路径算法 dijkstra 参考 可视化网站. 可视化网站. ",
"tags":["算法","数据结构","BFS","DFS","dijkstra"],
"categories":null
},{
"title":"https原理",
"permalink": "http://localhost:1313/posts/network/https/",
"summary": "定义 http http是超文本传输协议，用于传输网页内容，它基于TCP，所以是可靠性传输。但是它没有解决数据安全性 方面的问题\nhttp安全方面的问题 http没有对数据进行加密，任何人都可以随意读取这些数据，遭成数据的泄密。 其次没有认证，也就是没有办法知道数据来源的可靠性，攻击者可以中间人攻击来伪造数据 数据完整性，任何人可以读取也可以修改数据 https是什么 https是http的安全版本，https基于ssl，ssl基于tls。http+数据加密+认证+数据完整性就是https。\nhttps怎么解决的这些问题 数据加密 加密算法 加密算法分为对称加密和非对称加密，还有一些摘要算法 / 哈希算法，一下是一些常见的加密算法\n类型 示例 是否可逆 说明 对称加密 DES / AES / 3DES ✅ 加密解密用同一密钥 非对称加密 RSA / ECC ✅ 公钥加密，私钥解密 摘要算法 MD5 / SHA256 ❌ 不可逆，用于校验完整性 签名算法 DSA / RSA签名 ❌ 用私钥签名，公钥验签 服务器端生成密钥对，将公钥发送给客户端，客户端使用公钥加密对称加密使用的秘钥，发送给服务器端，服务器端使用私钥解密数据， 得到秘钥，后续通过这个秘钥对数据进行加密解密。\nCA CA（Certificate Authority）是证书颁发机构，它负责签发证书，并管理证书的颁发和吊销。\n为什么需要CA 客户端无法知晓拿到的公钥是由目标服务器颁发的，为了验证证书的合法性，防护中间人攻击，需要CA证书颁发机构签发证书。\n证书生成 首先，服务器管理员会向CA提起证书申请，CA会验证域名的所属权，做法通常是在域名解析加一个特定值。 验证通过后，CA会将服务器的公钥用自己的私钥进行签名，生成证书。并颁发给服务器管理员。\n证书验证过程 客户端发起连接请求，服务器会返回证书，客户端会验证证书的合法性，并获取证书的公钥。 浏览器会在发版的时候将各大CA机构的公钥预制在浏览器中，使用CA的公钥对服务器的证书进行解密，拿到解密的hash值。同时 使用同样的摘要算法对原始内容进行加密，用得到的摘要和解密的摘要对比，如果相等，说明证书是CA颁发的，也就证明 了证书的合法性和完整性。\n更加深入的了解https http是超文本传输协议，它会有以下几个问题：\n窃听风险，由于TCP传输过程中会经过路由器、主机等多个设备，存在被截获数据的风险，泄漏密码等机密信息 篡改风险，被截获的数据可能被恶意篡改，在交易等重要系统会产生非常大的破坏性 身份伪造，无法知晓我们访问的服务端是否是真实的 https通过以下几个方式解决上述问题\n机密性，通过对称加密算法保证 完整性，通过摘要算法保证（md5、sha256） 身份认证，通过CA(证书颁发机构) 为什么https采用了对策加密+非对称加密+CA? 只用对称加密不好解决密钥传输保存的问题，非对称加密由于加解密比较消耗资源，不适合对大量数据进行加解密。\n",
"content": "定义 http http是超文本传输协议，用于传输网页内容，它基于TCP，所以是可靠性传输。但是它没有解决数据安全性 方面的问题\nhttp安全方面的问题 http没有对数据进行加密，任何人都可以随意读取这些数据，遭成数据的泄密。 其次没有认证，也就是没有办法知道数据来源的可靠性，攻击者可以中间人攻击来伪造数据 数据完整性，任何人可以读取也可以修改数据 https是什么 https是http的安全版本，https基于ssl，ssl基于tls。http+数据加密+认证+数据完整性就是https。\nhttps怎么解决的这些问题 数据加密 加密算法 加密算法分为对称加密和非对称加密，还有一些摘要算法 / 哈希算法，一下是一些常见的加密算法\n类型 示例 是否可逆 说明 对称加密 DES / AES / 3DES ✅ 加密解密用同一密钥 非对称加密 RSA / ECC ✅ 公钥加密，私钥解密 摘要算法 MD5 / SHA256 ❌ 不可逆，用于校验完整性 签名算法 DSA / RSA签名 ❌ 用私钥签名，公钥验签 服务器端生成密钥对，将公钥发送给客户端，客户端使用公钥加密对称加密使用的秘钥，发送给服务器端，服务器端使用私钥解密数据， 得到秘钥，后续通过这个秘钥对数据进行加密解密。\nCA CA（Certificate Authority）是证书颁发机构，它负责签发证书，并管理证书的颁发和吊销。\n为什么需要CA 客户端无法知晓拿到的公钥是由目标服务器颁发的，为了验证证书的合法性，防护中间人攻击，需要CA证书颁发机构签发证书。\n证书生成 首先，服务器管理员会向CA提起证书申请，CA会验证域名的所属权，做法通常是在域名解析加一个特定值。 验证通过后，CA会将服务器的公钥用自己的私钥进行签名，生成证书。并颁发给服务器管理员。\n证书验证过程 客户端发起连接请求，服务器会返回证书，客户端会验证证书的合法性，并获取证书的公钥。 浏览器会在发版的时候将各大CA机构的公钥预制在浏览器中，使用CA的公钥对服务器的证书进行解密，拿到解密的hash值。同时 使用同样的摘要算法对原始内容进行加密，用得到的摘要和解密的摘要对比，如果相等，说明证书是CA颁发的，也就证明 了证书的合法性和完整性。\n更加深入的了解https http是超文本传输协议，它会有以下几个问题：\n窃听风险，由于TCP传输过程中会经过路由器、主机等多个设备，存在被截获数据的风险，泄漏密码等机密信息 篡改风险，被截获的数据可能被恶意篡改，在交易等重要系统会产生非常大的破坏性 身份伪造，无法知晓我们访问的服务端是否是真实的 https通过以下几个方式解决上述问题\n机密性，通过对称加密算法保证 完整性，通过摘要算法保证（md5、sha256） 身份认证，通过CA(证书颁发机构) 为什么https采用了对策加密+非对称加密+CA? 只用对称加密不好解决密钥传输保存的问题，非对称加密由于加解密比较消耗资源，不适合对大量数据进行加解密。\ntls的请求建立具体的流程和代码示例 ",
"tags":["计算机网络","https"],
"categories":null
},{
"title":"About Me",
"permalink": "http://localhost:1313/about/me/",
"summary": " 三年PHP经验，2年全栈经验，三年golang经验，持续学习中\u0026hellip; ",
"content": " 三年PHP经验，2年全栈经验，三年golang经验，持续学习中\u0026hellip; ",
"tags":null,
"categories":null
},{
"title":"golang的interface和reflect",
"permalink": "http://localhost:1313/posts/go/interfacereflect/",
"summary": "interface 鸭子类型 如果一个东西，走起来像鸭子，叫起来像鸭子，那么我们认为他就是鸭子。也就是说我们关注对象的行为，而不是对象本身。\ngo里面通过接口来达到鸭子类型的效果。\n多态 多态是指同一个操作（函数、方法），在不通的对象的作用下，会有不同的行为。 一般多态有两种实现方式：\n继承和组合，比如java、c++。 接口的形式 在go里面它没有继承的概念，但是go里面有组合。组合式是一种更灵活的方式。 他可以通过组合和重写来实现继承。在调用结构体的方法的时候，会优先调用最近的结构体的方法。 我们推荐在go里通过接口来实现多态，会更加清晰明了。\ngo的interface 定义 go里面的接口是一种复合数据类型。他的底层有2种实现，eface和iface。\n//eface 结构 type eface struct { tab *typtab data unsafe.Pointer } // iface结构 type iface struct { tab *itab data unsafe.Pointer } go里面的所有数据类型都实现了eface,也就是说可以借助interface来表示他的数据类型。 还可以通过interface来定义方法集合 。\ntype A interface { method() } 可能你会有一个疑问，那go是怎么确定interface 到底应该是使用eface 还是 iface呢？ go是在编译阶段就会确定好interface 使用的eface 还是 iface。后面不会改变。\n如何使用 什么时候会使用interface 通过接口来实现解耦合，比如依赖注入、适配器模式。 不确定传入参数的类型，需要在运行时来确定。 使用方法 接口列表 type animal interface { move() } type dog struct {} func (d dog) move() { fmt.Println(\u0026#34;dog moving\u0026#34;) } type cat struct {} func (c cat) move() { fmt.Println(\u0026#34;cat moving\u0026#34;) } func main() { var a animal a = dog{} a.move() a = cat{} // a是结构可以同意调用 a.move() // 接口注入 call(a) // 不确定具体的参数 vat func1 = func(param any) {} func1 = func(param any) { fmt.Println(\u0026#34;call any\u0026#34;, param) } } func call(a animal) { fmt.Println(\u0026#34;call animal \\n\u0026#34;) a.move() } 需要注意的点和坑 使用接口会让编译器无法确定数据类型，导致无法再编译阶段发现类型错误，引发运行时错误。 使用接口会让程序变得难以阅读和理解。 性能会损失大概一倍 reflect unsafe.pointer go语言unsafe包提供了一些函数，可以获取指针，修改指针，获取指针指向的数据，修改指针指向的数据。 简单来讲，go本身不能操作指针，但是提供了reflect包让我们可以操作指针来获得程序的 性能提升。\n",
"content": "interface 鸭子类型 如果一个东西，走起来像鸭子，叫起来像鸭子，那么我们认为他就是鸭子。也就是说我们关注对象的行为，而不是对象本身。\ngo里面通过接口来达到鸭子类型的效果。\n多态 多态是指同一个操作（函数、方法），在不通的对象的作用下，会有不同的行为。 一般多态有两种实现方式：\n继承和组合，比如java、c++。 接口的形式 在go里面它没有继承的概念，但是go里面有组合。组合式是一种更灵活的方式。 他可以通过组合和重写来实现继承。在调用结构体的方法的时候，会优先调用最近的结构体的方法。 我们推荐在go里通过接口来实现多态，会更加清晰明了。\ngo的interface 定义 go里面的接口是一种复合数据类型。他的底层有2种实现，eface和iface。\n//eface 结构 type eface struct { tab *typtab data unsafe.Pointer } // iface结构 type iface struct { tab *itab data unsafe.Pointer } go里面的所有数据类型都实现了eface,也就是说可以借助interface来表示他的数据类型。 还可以通过interface来定义方法集合 。\ntype A interface { method() } 可能你会有一个疑问，那go是怎么确定interface 到底应该是使用eface 还是 iface呢？ go是在编译阶段就会确定好interface 使用的eface 还是 iface。后面不会改变。\n如何使用 什么时候会使用interface 通过接口来实现解耦合，比如依赖注入、适配器模式。 不确定传入参数的类型，需要在运行时来确定。 使用方法 接口列表 type animal interface { move() } type dog struct {} func (d dog) move() { fmt.Println(\u0026#34;dog moving\u0026#34;) } type cat struct {} func (c cat) move() { fmt.Println(\u0026#34;cat moving\u0026#34;) } func main() { var a animal a = dog{} a.move() a = cat{} // a是结构可以同意调用 a.move() // 接口注入 call(a) // 不确定具体的参数 vat func1 = func(param any) {} func1 = func(param any) { fmt.Println(\u0026#34;call any\u0026#34;, param) } } func call(a animal) { fmt.Println(\u0026#34;call animal \\n\u0026#34;) a.move() } 需要注意的点和坑 使用接口会让编译器无法确定数据类型，导致无法再编译阶段发现类型错误，引发运行时错误。 使用接口会让程序变得难以阅读和理解。 性能会损失大概一倍 reflect unsafe.pointer go语言unsafe包提供了一些函数，可以获取指针，修改指针，获取指针指向的数据，修改指针指向的数据。 简单来讲，go本身不能操作指针，但是提供了reflect包让我们可以操作指针来获得程序的 性能提升。\n定义 在计算机领域，反射（Reflection）是指程序在运行时能够检查自身，并获取其内部信息。可以修改数据，调用方法的 一种能力。 go语言提供了一种在运行时能够获取数据本身的状态，数据，和调用方法的能力，在编译阶段 是不知道具体的类型的，需要在运行时确定。\n使用 常见使用场景 函数参数的动态传入，通过reflect获取参数的类型 动态修改切片，map，结构体 动态创建函数 GORM,通过反射获取结构体的tag来构建数据的sql语句 使用方法 reflect.ValueOf(a) reflect.TypeOf((a) 对指针解引用 reflect.ValueOf(a).Elem() 获取指针类型 reflect.TypeOf(a).Elem() 获取tag reflect.TypeOf(a).Elem().Field(0).Tag.Get(\u0026#34;json\u0026#34;) 获取字段 reflect.TypeOf(a).Elem().Field(0) 动态创建函数 func1 := reflect.MakeFunc(reflect.TypeOf(func(param any) {}), func(args []reflect.Value) []reflect.Value {}) // 动态调用函数 func1.Call([]reflect.Value{reflect.ValueOf(param)}) 需要注意的点和坑 使用反射会损失性能 使用反射会改变代码的可读性 编译器不能检查数据类型，会引发运行时错误 ",
"tags":["go","interface","reflect"],
"categories":null
}]