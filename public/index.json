[{
"title":"初始化方法比较",
"permalink": "http://localhost:1313/posts/go/%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95%E6%AF%94%E8%BE%83/",
"summary": "make和new的初始化比较 make new 返回值 返回实例化对象本身 返回类型并清空返回实例化对象的指针 作用类型、常见用法 slice、map、channel 所有类型 内部作用机制 初始化结构体，并初始化结构体内部的相关字段机构 初始化对象，清空内存，分配内存，置为零值 为什么new slice map 得到是nil 首先 new 严格遵守返回的是初始化对象指针的原则，而new slice、map的时候，返回的就是对象的引用，只是切片和哈希的 零值就是nil,所以如果new切片和map会出现无法使用的情况。\n",
"content": "make和new的初始化比较 make new 返回值 返回实例化对象本身 返回类型并清空返回实例化对象的指针 作用类型、常见用法 slice、map、channel 所有类型 内部作用机制 初始化结构体，并初始化结构体内部的相关字段机构 初始化对象，清空内存，分配内存，置为零值 为什么new slice map 得到是nil 首先 new 严格遵守返回的是初始化对象指针的原则，而new slice、map的时候，返回的就是对象的引用，只是切片和哈希的 零值就是nil,所以如果new切片和map会出现无法使用的情况。\n",
"tags":["go","make","new","初始化"],
"categories":null
},{
"title":"TCP可靠性保证",
"permalink": "http://localhost:1313/posts/network/tcp%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81/",
"summary": "",
"content": "",
"tags":null,
"categories":null
},{
"title":"数据粘包",
"permalink": "http://localhost:1313/posts/network/%E6%95%B0%E6%8D%AE%E7%B2%98%E5%8C%85/",
"summary": "",
"content": "",
"tags":null,
"categories":null
},{
"title":"内存泄漏",
"permalink": "http://localhost:1313/posts/go/%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F/",
"summary": "什么是内存泄漏 指内存资源长期得不到释放，导致内存溢出\n内存泄漏的常见场景 协程的泄漏 耗时任务或者http请求一直得不到响应，又没有设置超时时间 chan未正确关闭、阻塞 锁未正确释放、导致协程未能释放 channel泄漏 内存泄漏分析工具 pprof分析协程数量，内存占用情况等\n如何针对内存泄漏进行优化 针对协程泄漏 设置超时时间 正确使用channel 正确使用互斥锁，配对使用 针对channel的泄漏 配对使用 在发送方关闭channel 正确使用缓冲channel和非缓冲channel ",
"content": "什么是内存泄漏 指内存资源长期得不到释放，导致内存溢出\n内存泄漏的常见场景 协程的泄漏 耗时任务或者http请求一直得不到响应，又没有设置超时时间 chan未正确关闭、阻塞 锁未正确释放、导致协程未能释放 channel泄漏 内存泄漏分析工具 pprof分析协程数量，内存占用情况等\n如何针对内存泄漏进行优化 针对协程泄漏 设置超时时间 正确使用channel 正确使用互斥锁，配对使用 针对channel的泄漏 配对使用 在发送方关闭channel 正确使用缓冲channel和非缓冲channel ",
"tags":null,
"categories":null
},{
"title":"逃逸分析",
"permalink": "http://localhost:1313/posts/go/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/",
"summary": "什么是逃逸分析 计算机科学中对指针作用范围进行分析就叫做逃逸分析。就是分析变量是分配到堆上还是栈上。\n分配到栈上还是分配到堆上，对于后续编译器进行优化有很大的影响。\n栈 堆 分配方式 随着函数创建自动分配 程序员手动分配 资源消耗 很小 比较大 回收方式 随着函数的结束进行销毁 需要手动回收,或者根据gc算法进行回收 如果对go的程序进行逃逸分析 使用源码go build 分析，看变量是否发生了逃逸\n如何使用 逃逸分析需要注意的点 ",
"content": "什么是逃逸分析 计算机科学中对指针作用范围进行分析就叫做逃逸分析。就是分析变量是分配到堆上还是栈上。\n分配到栈上还是分配到堆上，对于后续编译器进行优化有很大的影响。\n栈 堆 分配方式 随着函数创建自动分配 程序员手动分配 资源消耗 很小 比较大 回收方式 随着函数的结束进行销毁 需要手动回收,或者根据gc算法进行回收 如果对go的程序进行逃逸分析 使用源码go build 分析，看变量是否发生了逃逸\n如何使用 逃逸分析需要注意的点 ",
"tags":null,
"categories":null
},{
"title":"Gc",
"permalink": "http://localhost:1313/posts/go/gc/",
"summary": "什么是GC gc就是内存垃圾回收。c/c++这类语言可以由程序员申请内存，分配到堆上，堆上的数据随着函数结束并不会自动被清零，需要程序员手动清理。 这会给编程增加负担和隐患。高级语言如java/go支持gc,自动分析没有被引用的变量，进行内存回收。\n常见的GC方法 引用计数法 对变量对象的引用次数进行计数，当计数为0就会被回收。它实现简单，但效率不高无法解决循环引用的问题。\n标记清除法 扫描所有对象，将有引用的进行标记。优点是实现简单，但可能出现很多内存碎片，不利于内存重新分配。\n复制法 准备2个大小一样的内存块，将存活的对象放到新的内存块。优点是解决了内存碎片问题，但内存复制比较消耗资源，还需要将引用关系进行复制。\n分代法 将对象创建的不同时间分为青年代、中年代、老年代。\n三色标记法 stw可以是start the world 或者 stop zhe world的缩写，他指的是stop the word 到 start the world 这个间隔的时间。在gc过程总需要暂停用户 代码执行，进行内存扫描，这个stw时间越短，对程序的性能提升越高。\ngo的GC实现 go因为内存分配是采用tcmalloc分配法，所有不需要处理内存碎片问题，同时go团队更加希望的是gc操作可以和用户代码一起执行，不仅是减少 stw的时间。go采用三色标记法对内存进行回收，并采用混合屏障提升并发时的回收效率。\n扫描过程 分为4步\n所有根对象标记为白色 将根对象放入待扫描队列，标记成灰色 扫描队列所有的灰色对象，标记成黑色，并将引用对象标记成灰色。 重复步骤三，直到待扫描的灰色对象为空，所有对象标记成黑色或者白色。白色对象不可达，进行回收。 根对象在垃圾回收术语中被称为根集合，它包含 全局对象，程序在编译阶段就能确定的存在于程序整个生命周期的对象 执行栈，每个goroutine都有自己的内存栈 寄存器，可以是指向变量的指针 没有stw可能得问题 对象被错误删除 假设以下场景：扫描到某个节点，存在a灰色对象引用白色对象b,存在一个黑色对象c。此时现将删除a对b的引用，同时添加 c对b的引用。b本来应该被正确标记成黑色的，由于对象c为黑色不会对它进行扫描，而a又删除了对b的引用，就会造成c始终不可达 造成误删除。 混合写屏障 作用是减少stw的时间，具体的做法如下：\n插入对象直接置为黑色对象 分析工具和分析方法 如何针对GC进行优化",
"content": "什么是GC gc就是内存垃圾回收。c/c++这类语言可以由程序员申请内存，分配到堆上，堆上的数据随着函数结束并不会自动被清零，需要程序员手动清理。 这会给编程增加负担和隐患。高级语言如java/go支持gc,自动分析没有被引用的变量，进行内存回收。\n常见的GC方法 引用计数法 对变量对象的引用次数进行计数，当计数为0就会被回收。它实现简单，但效率不高无法解决循环引用的问题。\n标记清除法 扫描所有对象，将有引用的进行标记。优点是实现简单，但可能出现很多内存碎片，不利于内存重新分配。\n复制法 准备2个大小一样的内存块，将存活的对象放到新的内存块。优点是解决了内存碎片问题，但内存复制比较消耗资源，还需要将引用关系进行复制。\n分代法 将对象创建的不同时间分为青年代、中年代、老年代。\n三色标记法 stw可以是start the world 或者 stop zhe world的缩写，他指的是stop the word 到 start the world 这个间隔的时间。在gc过程总需要暂停用户 代码执行，进行内存扫描，这个stw时间越短，对程序的性能提升越高。\ngo的GC实现 go因为内存分配是采用tcmalloc分配法，所有不需要处理内存碎片问题，同时go团队更加希望的是gc操作可以和用户代码一起执行，不仅是减少 stw的时间。go采用三色标记法对内存进行回收，并采用混合屏障提升并发时的回收效率。\n扫描过程 分为4步\n所有根对象标记为白色 将根对象放入待扫描队列，标记成灰色 扫描队列所有的灰色对象，标记成黑色，并将引用对象标记成灰色。 重复步骤三，直到待扫描的灰色对象为空，所有对象标记成黑色或者白色。白色对象不可达，进行回收。 根对象在垃圾回收术语中被称为根集合，它包含 全局对象，程序在编译阶段就能确定的存在于程序整个生命周期的对象 执行栈，每个goroutine都有自己的内存栈 寄存器，可以是指向变量的指针 没有stw可能得问题 对象被错误删除 假设以下场景：扫描到某个节点，存在a灰色对象引用白色对象b,存在一个黑色对象c。此时现将删除a对b的引用，同时添加 c对b的引用。b本来应该被正确标记成黑色的，由于对象c为黑色不会对它进行扫描，而a又删除了对b的引用，就会造成c始终不可达 造成误删除。 混合写屏障 作用是减少stw的时间，具体的做法如下：\n插入对象直接置为黑色对象 分析工具和分析方法 如何针对GC进行优化 ",
"tags":null,
"categories":null
},{
"title":"分库分表",
"permalink": "http://localhost:1313/posts/database/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/",
"summary": "",
"content": "",
"tags":null,
"categories":null
},{
"title":"Map",
"permalink": "http://localhost:1313/posts/go/map/",
"summary": "go的哈希实现 通用哈希实现 哈希表是一个高效的数据结构，通过对key经过哈希函数计算的值和存储数据的数组的长度，两者求余得到在数组插入的位置。高效的查找效率 时间复杂度为O(1)。\n哈希函数 任意长度的输入有固定输出 同一输入会产生同一个输出 输入的细小改变会造成输入的完全不一样 速度快 单项不可逆 go的哈希底层实现 通过底层结构体hmap来实例化map对象，hmap 包含指向[]bucket数组的指针。bucket结构里面会存储真实的数据 以key1key2 val1value2 的形式进行排列，方便内存对齐。头部有top哈希方便bucket内部进行数据定位，底部有指向溢出bucket的指针。 当发生哈希冲突，冲突的数据会存放到溢出bucket链表。\n插入过程 首先用哈希函数对key计算，得到64位数据（64位机器上）。低B位决定数据落入哪个桶。B是log2count，也就是以2为底bucket元素的长度的对数。 高8位决定落入bucket具体的位置。如果发送哈希冲突，就把数据存入溢出桶。\n遍历过程、查找过程 遍历：从0-bucket长度随机一个数字选择bucket进行遍历。所以go的map是无序。如果bucket遍历完，溢出桶不为空，继续遍历溢出桶。 查找：哈希函数对key计算，低8位找到具体的桶。高8位拿来和bucket的top哈希进行比较，如果一致，再比较具体的key,如果相同就返回， 否则再看溢出桶是否为空，不会空对链表进行遍历。如果都没有就返回查找失败。 go的扩容过程 当哈希函数产生过多的哈希碰撞时，就会导致查询效率低下，为了减少哈希碰撞，需要对底层数组的容量扩容或者对数据进行从新排列。 当满足一下任意条件会触发扩容\n当碰撞因子\u0026gt;6.5, 碰撞因子=count(实际元素个数)/2的B次方（bucket数组总的元素长度） 当溢出桶过多时，当B \u0026lt; 15 , 当溢出桶的个数\u0026gt;B次方，触发扩容。当B\u0026gt;15时，overflow超过2的15次方。 为什么是线程不安全的 sync.map使用 sync.map如何实现的 注意事项",
"content": "go的哈希实现 通用哈希实现 哈希表是一个高效的数据结构，通过对key经过哈希函数计算的值和存储数据的数组的长度，两者求余得到在数组插入的位置。高效的查找效率 时间复杂度为O(1)。\n哈希函数 任意长度的输入有固定输出 同一输入会产生同一个输出 输入的细小改变会造成输入的完全不一样 速度快 单项不可逆 go的哈希底层实现 通过底层结构体hmap来实例化map对象，hmap 包含指向[]bucket数组的指针。bucket结构里面会存储真实的数据 以key1key2 val1value2 的形式进行排列，方便内存对齐。头部有top哈希方便bucket内部进行数据定位，底部有指向溢出bucket的指针。 当发生哈希冲突，冲突的数据会存放到溢出bucket链表。\n插入过程 首先用哈希函数对key计算，得到64位数据（64位机器上）。低B位决定数据落入哪个桶。B是log2count，也就是以2为底bucket元素的长度的对数。 高8位决定落入bucket具体的位置。如果发送哈希冲突，就把数据存入溢出桶。\n遍历过程、查找过程 遍历：从0-bucket长度随机一个数字选择bucket进行遍历。所以go的map是无序。如果bucket遍历完，溢出桶不为空，继续遍历溢出桶。 查找：哈希函数对key计算，低8位找到具体的桶。高8位拿来和bucket的top哈希进行比较，如果一致，再比较具体的key,如果相同就返回， 否则再看溢出桶是否为空，不会空对链表进行遍历。如果都没有就返回查找失败。 go的扩容过程 当哈希函数产生过多的哈希碰撞时，就会导致查询效率低下，为了减少哈希碰撞，需要对底层数组的容量扩容或者对数据进行从新排列。 当满足一下任意条件会触发扩容\n当碰撞因子\u0026gt;6.5, 碰撞因子=count(实际元素个数)/2的B次方（bucket数组总的元素长度） 当溢出桶过多时，当B \u0026lt; 15 , 当溢出桶的个数\u0026gt;B次方，触发扩容。当B\u0026gt;15时，overflow超过2的15次方。 为什么是线程不安全的 sync.map使用 sync.map如何实现的 注意事项 ",
"tags":null,
"categories":null
},{
"title":"Distributed_transaction",
"permalink": "http://localhost:1313/posts/architecture/distributed_transaction/",
"summary": "分布式事务",
"content": "分布式事务 ",
"tags":null,
"categories":null
},{
"title":"Http2_grpc",
"permalink": "http://localhost:1313/posts/network/http2_grpc/",
"summary": "http2 http1的弊端 数据以文本传输，十分低效 header头数据很多 每个tcp链接只能发送一次链接 只能单向传递数据，由浏览器发起 加载无法定义顺序 http2 http2针对这些缺点进行了优化\n对数据进行二进制分帧，基于流传输提高了传输效率，还可以进行流量控制，提升安全性和可靠性 对头数据进行了压缩，采用hpack算法对数据进行压缩，提升了传输效率 采用多路复用，每个tcp连接可以发起任意多的传输请求，减少了tcp的三次握手等频繁建立请求 可以实现服务端推送，从单向传输改为双向传输 可以根据页面不同资源的重要程度设置优先级进行加载 通过以上五个方面http2对h1进行了升级，提高了传输效率，增加更多实现的功能，提升了客户端用户体验。 如何使用 反向代理软件如nginx/apache等设置http2选项 如nginx,首先必须支持ssl/tsl证书，再加上listen 443 ssl http2\ngo的net组件自动支持http2,无需手动升级 grpc rpc rpc是远程过程调用，是一种在不同进程或组件上让函数调用如同本地调用一样的技术。有多种实现，比如json-rpc,xrpc(基于xml),gprc google推出，基于protobuf,通过IDL(接口定义)定义同义的方法和参数，使用代码生成工具生成不同语言的代码。\ngrpc也是基于http2,所以他可以利用http2的各种特性，他有google推出，采用protobuf传输。\n他有以下特点：\n基于IDL生成，接口及定义，可以生成多语言，被客户端和服务端共用。 数据传输效率高，基于http2,拥有双向传输、tcp多路复用、二进制数据帧传输、流量控制等特性 常见于微服务当中，可以方便的定义中间件，进行限流、降级等特性 浏览器一次完整的请求过程 服务器会启动进程监听某个端口，当端口监听到请求，进行处理 通过DNS解析域名拿到目标IP,依次通过浏览器、本地缓存查询，没有就往根dns服务器查询。 如果是http协议需要先通过ssl建立安全通道。 建立TCP连接，通过五元组：协议 ip 端口 目标IP 目标端口 进行三次握手，握手完成后开始发送数据 数据进行封装,数据从应用层（报文）-\u0026gt;传输层（报文+端口号）-\u0026gt;网络IP层（数据段+IP）-\u0026gt;数据链路层(数据包+mac主机物理地址-\u0026gt;数据帧)-\u0026gt;物理层(二进制流)这个层次依次进行传输 通过网络层找到目的主机，通过端口号找到主机监听目的端口的程序。应用程序处理请求。 服务器处理响应，完成后，返回给客户端 断开连接、4次挥手，最后一次等待服务器发送完毕数据 参考资料 https://blog.csdn.net/u012914309/article/details/127507726?spm=1001.2014.3001.5501 ",
"content": "http2 http1的弊端 数据以文本传输，十分低效 header头数据很多 每个tcp链接只能发送一次链接 只能单向传递数据，由浏览器发起 加载无法定义顺序 http2 http2针对这些缺点进行了优化\n对数据进行二进制分帧，基于流传输提高了传输效率，还可以进行流量控制，提升安全性和可靠性 对头数据进行了压缩，采用hpack算法对数据进行压缩，提升了传输效率 采用多路复用，每个tcp连接可以发起任意多的传输请求，减少了tcp的三次握手等频繁建立请求 可以实现服务端推送，从单向传输改为双向传输 可以根据页面不同资源的重要程度设置优先级进行加载 通过以上五个方面http2对h1进行了升级，提高了传输效率，增加更多实现的功能，提升了客户端用户体验。 如何使用 反向代理软件如nginx/apache等设置http2选项 如nginx,首先必须支持ssl/tsl证书，再加上listen 443 ssl http2\ngo的net组件自动支持http2,无需手动升级 grpc rpc rpc是远程过程调用，是一种在不同进程或组件上让函数调用如同本地调用一样的技术。有多种实现，比如json-rpc,xrpc(基于xml),gprc google推出，基于protobuf,通过IDL(接口定义)定义同义的方法和参数，使用代码生成工具生成不同语言的代码。\ngrpc也是基于http2,所以他可以利用http2的各种特性，他有google推出，采用protobuf传输。\n他有以下特点：\n基于IDL生成，接口及定义，可以生成多语言，被客户端和服务端共用。 数据传输效率高，基于http2,拥有双向传输、tcp多路复用、二进制数据帧传输、流量控制等特性 常见于微服务当中，可以方便的定义中间件，进行限流、降级等特性 浏览器一次完整的请求过程 服务器会启动进程监听某个端口，当端口监听到请求，进行处理 通过DNS解析域名拿到目标IP,依次通过浏览器、本地缓存查询，没有就往根dns服务器查询。 如果是http协议需要先通过ssl建立安全通道。 建立TCP连接，通过五元组：协议 ip 端口 目标IP 目标端口 进行三次握手，握手完成后开始发送数据 数据进行封装,数据从应用层（报文）-\u0026gt;传输层（报文+端口号）-\u0026gt;网络IP层（数据段+IP）-\u0026gt;数据链路层(数据包+mac主机物理地址-\u0026gt;数据帧)-\u0026gt;物理层(二进制流)这个层次依次进行传输 通过网络层找到目的主机，通过端口号找到主机监听目的端口的程序。应用程序处理请求。 服务器处理响应，完成后，返回给客户端 断开连接、4次挥手，最后一次等待服务器发送完毕数据 参考资料 https://blog.csdn.net/u012914309/article/details/127507726?spm=1001.2014.3001.5501 ",
"tags":null,
"categories":null
},{
"title":"分布式锁",
"permalink": "http://localhost:1313/posts/architecture/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/",
"summary": "分布式锁 定义 分布式锁是用于并发控制的手段，他需要满足一下几点：\n互斥，redis单线程，内置nx命令，只有当key不存在是才返回成功。满足互斥性。 可重入，可重入是指同一个进程或者线程多次加锁要能获锁成功。这种可以为同一线程生成req_id，并且进行 计数，当计算为0时对锁进行释放 避免死锁。如果持锁的线程挂掉，从而无法正常释放锁，就会造成死锁。可以给锁设置过期时间，比如nx命令传入ttl。 正确释放锁。因为设置了过期时间，所以会导致2个问题 如果a执行时间过长，ttl自动释放，这时b正常拿锁，之后a执行完成，如果直接释放锁，就把b的锁释放掉了。解决办法是在加锁的时候 生成唯一ID,在解锁的时候进行判断，相同才删除。也就是说只有持锁的才能删除。 删除操作是2个命令，第一个是get,第二个是删除，注意需要保证原子性，因为get的时候并发，aget到锁 ，之后ttl过期，b拿锁，a再释放，就出问题了。需要用lua脚本保证原子性。 续期机制。如果持锁的线程执行时间过长超过了ttl设置的时间，就需要能够自动续期。我们可以采用看门狗机制，启动一个线程，轮训key的剩余过期时间， 比如到了3/2的过期时间，自动续期。 分布式下部署下的分布式锁。上面五点基本可以保证单机状态下分布式锁的可靠性。但是单机系统的可用性比较低。如果采用分布式锁需要注意几个问题。 redis的哨兵Sentinel 和 cluster 模式下，不适合做分布式锁。 哨兵模式可能主从延迟、主备切换，比如主节点写入后还没来得及同步就挂掉，从节点成为主节点，锁丢失。 分布式下不允许多key操作，需要视同tag标签将锁落入同一个slot。其次也会发生哨兵模式的主从延迟、主备切换问题 高可以架构可以用redLock或者zookeeper、etcd实现 redLock就是采用多个独立的redis,采用多数派写入保证数据的一致性。 zookeeper可以在某个目录下建立节点，节点最新获取成功，并删除节点。否则循环或者守护进程监听最近的节点，当发生变化，在判断自己是不是最小的 节点 使用 使用场景 使用方法 注意事项 参考资料 美团技术团队. 分布式锁. google. 最后修订于2016年09月29日. 访问于2025年7月20日. 掘金. 分布式锁 ",
"content": "分布式锁 定义 分布式锁是用于并发控制的手段，他需要满足一下几点：\n互斥，redis单线程，内置nx命令，只有当key不存在是才返回成功。满足互斥性。 可重入，可重入是指同一个进程或者线程多次加锁要能获锁成功。这种可以为同一线程生成req_id，并且进行 计数，当计算为0时对锁进行释放 避免死锁。如果持锁的线程挂掉，从而无法正常释放锁，就会造成死锁。可以给锁设置过期时间，比如nx命令传入ttl。 正确释放锁。因为设置了过期时间，所以会导致2个问题 如果a执行时间过长，ttl自动释放，这时b正常拿锁，之后a执行完成，如果直接释放锁，就把b的锁释放掉了。解决办法是在加锁的时候 生成唯一ID,在解锁的时候进行判断，相同才删除。也就是说只有持锁的才能删除。 删除操作是2个命令，第一个是get,第二个是删除，注意需要保证原子性，因为get的时候并发，aget到锁 ，之后ttl过期，b拿锁，a再释放，就出问题了。需要用lua脚本保证原子性。 续期机制。如果持锁的线程执行时间过长超过了ttl设置的时间，就需要能够自动续期。我们可以采用看门狗机制，启动一个线程，轮训key的剩余过期时间， 比如到了3/2的过期时间，自动续期。 分布式下部署下的分布式锁。上面五点基本可以保证单机状态下分布式锁的可靠性。但是单机系统的可用性比较低。如果采用分布式锁需要注意几个问题。 redis的哨兵Sentinel 和 cluster 模式下，不适合做分布式锁。 哨兵模式可能主从延迟、主备切换，比如主节点写入后还没来得及同步就挂掉，从节点成为主节点，锁丢失。 分布式下不允许多key操作，需要视同tag标签将锁落入同一个slot。其次也会发生哨兵模式的主从延迟、主备切换问题 高可以架构可以用redLock或者zookeeper、etcd实现 redLock就是采用多个独立的redis,采用多数派写入保证数据的一致性。 zookeeper可以在某个目录下建立节点，节点最新获取成功，并删除节点。否则循环或者守护进程监听最近的节点，当发生变化，在判断自己是不是最小的 节点 使用 使用场景 使用方法 注意事项 参考资料 美团技术团队. 分布式锁. google. 最后修订于2016年09月29日. 访问于2025年7月20日. 掘金. 分布式锁 ",
"tags":null,
"categories":null
},{
"title":"CAP",
"permalink": "http://localhost:1313/posts/architecture/cap/",
"summary": "定义 CAP理论是指分布式当中一致性、可用性以及分区容错性三者不可兼得。我们需要根据实际应用场景做出相应的取舍， 在现实中，一般来说分布式系统中的网络是不可能完全保证可用的，所以就需要在CP和AP中做出选择。\n拜占庭将军问题 是指分布式系统中可能有恶意节点对数据一致性造成破坏。如果系统中的节点是f个，为了解决非拜占庭将军问题，至少需要3f+1 个节点。能容忍拜占庭容错的系统一般是高安全性要求的系统，比如区跨链、金融、军事等。\n脑裂 脑裂是指分布式系统中由于网络波动或中断，导致系统被分成多个子系统，子系统在内部选举leader，对外提供服务。这会导致 严重的问题，比如\n数据不一致\t两个分区同时写入同一数据（如账户余额），导致冲突且无法自动合并。 资源冲突\t两个“领导者”同时操作共享资源（如分配同一IP地址、锁定同一文件）。 状态混乱\t客户端可能被不同分区响应矛盾的结果（如A分区说“支付成功”，B分区说“未支付”）。 数据永久丢失\t分区恢复后，冲突写入可能导致部分数据被覆盖或丢弃。 为了防止脑裂，一般分布式一致性协议都会采用多数派原则进行避免，比如五个节点的分布式系统中，需要3个节点的确认才能成为leader,否则会 因为无法选主而停止对外提供服务。\nraft协议 raft协议是分布式系统中多个节点对于某个资源的一致性的达成所采用的一种协议，主要有三个部分：\n主从选择 日志复制 安全性和一致性保证 raft协议是强一致的。还有一些其他的一致性组件比如zookeeper。raft协议提供了强一致性的方案。 zookeeper 实践 常见的使用场景 一些常见的开源软件的使用我们会经常遇到这个场景。拿最常见的redis为例，redis的分布式部署方案有三种，主从、哨兵、cluster。\ngo 简单的实践 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/hashicorp/raft\u0026#34; bolt \u0026#34;github.com/hashicorp/raft-boltdb\u0026#34; ) // 简单的 FSM：提交即打印 type FSM struct{} func (f *FSM) Apply(l *raft.Log) interface{} { fmt.Printf(\u0026#34;Apply: %s\\n\u0026#34;, string(l.Data)) return nil } func (f *FSM) Snapshot() (raft.FSMSnapshot, error) { return \u0026amp;snapshot{}, nil } func (f *FSM) Restore(io.ReadCloser) error { return nil } type snapshot struct{} func (s *snapshot) Persist(sink raft.SnapshotSink) error { return sink.Close() } func (s *snapshot) Release() {} func main() { // 1) 配置 config := raft.DefaultConfig() config.LocalID = raft.ServerID(os.Args[1]) // 节点 ID 来自第一个参数 // 2) 网络传输：TCP addr, err := net.ResolveTCPAddr(\u0026#34;tcp\u0026#34;, os.Args[2]) if err != nil { log.Fatal(err) } transport, err := raft.NewTCPTransport(os.Args[2], addr, 3, 10*time.Second, os.Stdout) if err != nil { log.Fatal(err) } // 3) 日志与快照存储 store, err := bolt.NewBoltStore(fmt.Sprintf(\u0026#34;raft-%s.db\u0026#34;, os.Args[1])) if err != nil { log.Fatal(err) } snapshotStore := raft.NewInmemSnapshotStore() // 4) 创建 Raft 实例 r, err := raft.NewRaft(config, \u0026amp;FSM{}, store, store, snapshotStore, transport) if err != nil { log.Fatal(err) } // 5) Bootstrap 第一个节点 if os.Args[1] == \u0026#34;node1\u0026#34; { cfg := raft.Configuration{ Servers: []raft.Server{ {ID: \u0026#34;node1\u0026#34;, Address: transport.LocalAddr()}, {ID: \u0026#34;node2\u0026#34;, Address: raft.ServerAddress(\u0026#34;127.0.0.1:12002\u0026#34;)}, {ID: \u0026#34;node3\u0026#34;, Address: raft.ServerAddress(\u0026#34;127.0.0.1:12003\u0026#34;)}, }, } r.BootstrapCluster(cfg) } // 6) 简单命令行提交 if config.LocalID == \u0026#34;node1\u0026#34; { go func() { for { time.Sleep(3 * time.Second) f := r.Apply([]byte(\u0026#34;hello raft\u0026#34;), 5*time.Second) if err := f.Error(); err != nil { log.Println(\u0026#34;apply error:\u0026#34;, err) } } }() } select {} // 阻塞 } `\n",
"content": "定义 CAP理论是指分布式当中一致性、可用性以及分区容错性三者不可兼得。我们需要根据实际应用场景做出相应的取舍， 在现实中，一般来说分布式系统中的网络是不可能完全保证可用的，所以就需要在CP和AP中做出选择。\n拜占庭将军问题 是指分布式系统中可能有恶意节点对数据一致性造成破坏。如果系统中的节点是f个，为了解决非拜占庭将军问题，至少需要3f+1 个节点。能容忍拜占庭容错的系统一般是高安全性要求的系统，比如区跨链、金融、军事等。\n脑裂 脑裂是指分布式系统中由于网络波动或中断，导致系统被分成多个子系统，子系统在内部选举leader，对外提供服务。这会导致 严重的问题，比如\n数据不一致\t两个分区同时写入同一数据（如账户余额），导致冲突且无法自动合并。 资源冲突\t两个“领导者”同时操作共享资源（如分配同一IP地址、锁定同一文件）。 状态混乱\t客户端可能被不同分区响应矛盾的结果（如A分区说“支付成功”，B分区说“未支付”）。 数据永久丢失\t分区恢复后，冲突写入可能导致部分数据被覆盖或丢弃。 为了防止脑裂，一般分布式一致性协议都会采用多数派原则进行避免，比如五个节点的分布式系统中，需要3个节点的确认才能成为leader,否则会 因为无法选主而停止对外提供服务。\nraft协议 raft协议是分布式系统中多个节点对于某个资源的一致性的达成所采用的一种协议，主要有三个部分：\n主从选择 日志复制 安全性和一致性保证 raft协议是强一致的。还有一些其他的一致性组件比如zookeeper。raft协议提供了强一致性的方案。 zookeeper 实践 常见的使用场景 一些常见的开源软件的使用我们会经常遇到这个场景。拿最常见的redis为例，redis的分布式部署方案有三种，主从、哨兵、cluster。\ngo 简单的实践 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/hashicorp/raft\u0026#34; bolt \u0026#34;github.com/hashicorp/raft-boltdb\u0026#34; ) // 简单的 FSM：提交即打印 type FSM struct{} func (f *FSM) Apply(l *raft.Log) interface{} { fmt.Printf(\u0026#34;Apply: %s\\n\u0026#34;, string(l.Data)) return nil } func (f *FSM) Snapshot() (raft.FSMSnapshot, error) { return \u0026amp;snapshot{}, nil } func (f *FSM) Restore(io.ReadCloser) error { return nil } type snapshot struct{} func (s *snapshot) Persist(sink raft.SnapshotSink) error { return sink.Close() } func (s *snapshot) Release() {} func main() { // 1) 配置 config := raft.DefaultConfig() config.LocalID = raft.ServerID(os.Args[1]) // 节点 ID 来自第一个参数 // 2) 网络传输：TCP addr, err := net.ResolveTCPAddr(\u0026#34;tcp\u0026#34;, os.Args[2]) if err != nil { log.Fatal(err) } transport, err := raft.NewTCPTransport(os.Args[2], addr, 3, 10*time.Second, os.Stdout) if err != nil { log.Fatal(err) } // 3) 日志与快照存储 store, err := bolt.NewBoltStore(fmt.Sprintf(\u0026#34;raft-%s.db\u0026#34;, os.Args[1])) if err != nil { log.Fatal(err) } snapshotStore := raft.NewInmemSnapshotStore() // 4) 创建 Raft 实例 r, err := raft.NewRaft(config, \u0026amp;FSM{}, store, store, snapshotStore, transport) if err != nil { log.Fatal(err) } // 5) Bootstrap 第一个节点 if os.Args[1] == \u0026#34;node1\u0026#34; { cfg := raft.Configuration{ Servers: []raft.Server{ {ID: \u0026#34;node1\u0026#34;, Address: transport.LocalAddr()}, {ID: \u0026#34;node2\u0026#34;, Address: raft.ServerAddress(\u0026#34;127.0.0.1:12002\u0026#34;)}, {ID: \u0026#34;node3\u0026#34;, Address: raft.ServerAddress(\u0026#34;127.0.0.1:12003\u0026#34;)}, }, } r.BootstrapCluster(cfg) } // 6) 简单命令行提交 if config.LocalID == \u0026#34;node1\u0026#34; { go func() { for { time.Sleep(3 * time.Second) f := r.Apply([]byte(\u0026#34;hello raft\u0026#34;), 5*time.Second) if err := f.Error(); err != nil { log.Println(\u0026#34;apply error:\u0026#34;, err) } } }() } select {} // 阻塞 } `\n执行 go run main.go node1 127.0.0.1:12001 执行 go run main.go node1 127.0.0.1:12002 执行 go run main.go node1 127.0.0.1:12003 停掉node1 会重新触发选主 ` 拓展点-状态机 状态机可以看作是ifelse 的封装将强版本，更容易集中管理动作之后状态的变更。\n特点 FSM（如 looplab/fsm） 传统 if-else 结构清晰 明确状态转换图，逻辑集中 逻辑分散，耦合高 易于扩展 增加状态只需配置 增加逻辑可能动很多 if 便于测试 每个状态转换可单测 if else 混杂，不好测 可视化 易转为状态图 很难 条件钩子 before_event/after_event 很方便 手写控制流程 状态合法性控制 内建校验非法状态跳转 自己加判断 使用开源库可以感受一下\npackage workflow import ( \u0026#34;errors\u0026#34; \u0026#34;github.com/looplab/fsm\u0026#34; ) // 所有可能的状态 const ( StateA = \u0026#34;A_PENDING\u0026#34; // 初始由 A 审批 StateCountersign = \u0026#34;COUNTERSIGN_PENDING\u0026#34;// B、C 会签阶段 StateD = \u0026#34;D_PENDING\u0026#34; // D 审批 StateE = \u0026#34;E_PENDING\u0026#34; // E 审批 StateDone = \u0026#34;APPROVED\u0026#34; // 最终审批通过 StateRejected = \u0026#34;REJECTED\u0026#34; // 流程终止（可选） ) // 事件名 const ( EventAApprove = \u0026#34;a_approve\u0026#34; EventACancel = \u0026#34;a_cancel\u0026#34; // A 拒绝或撤回 EventCountersignOK = \u0026#34;countersign_ok\u0026#34; // B、C 会签完成（都同意） EventDCancel = \u0026#34;d_reject\u0026#34; // D 拒绝 EventDApprove = \u0026#34;d_approve\u0026#34; EventECancel = \u0026#34;e_reject\u0026#34; // E 拒绝 EventEApprove = \u0026#34;e_approve\u0026#34; ) // NewWorkflowFSM 创建并返回一个基于当前状态的 FSM func NewWorkflowFSM(currentState string) *fsm.FSM { return fsm.NewFSM( currentState, fsm.Events{ // A 同意，进入会签阶段 {Name: EventAApprove, Src: []string{StateA}, Dst: StateCountersign}, // 会签完成后，进入 D 阶段 {Name: EventCountersignOK, Src: []string{StateCountersign}, Dst: StateD}, // D 同意，进入 E {Name: EventDApprove, Src: []string{StateD}, Dst: StateE}, // E 同意，整个流程完成 {Name: EventEApprove, Src: []string{StateE}, Dst: StateDone}, // 驳回／回退逻辑 {Name: EventDCancel, Src: []string{StateD}, Dst: StateA}, {Name: EventECancel, Src: []string{StateE}, Dst: StateD}, {Name: EventACancel, Src: []string{StateA, StateCountersign}, Dst: StateRejected}, }, fsm.Callbacks{ \u0026#34;enter_state\u0026#34;: func(e *fsm.Event) { // 通用进状态日志；也可针对具体状态做扩展 // fmt.Printf(\u0026#34;Transition: %s -\u0026gt; %s via %s\\n\u0026#34;, e.Src, e.Dst, e.Event) }, }, ) } // 业务层调用示例： // wf := NewWorkflowFSM(dbRecord.State) // if err := wf.Event(EventAApprove); err != nil { … } // dbRecord.State = wf.Current() // save(dbRecord) type ApprovalRecord struct { ID string State string // 存储在 DB：FSM 当前状态 ApprovedByB bool ApprovedByC bool } // B、C 审批 API 调用示例 func ApproveByB(record *ApprovalRecord) error { if record.State != StateCountersign { return errors.New(\u0026#34;不在会签阶段\u0026#34;) } record.ApprovedByB = true return tryFinishCountersign(record) } func ApproveByC(record *ApprovalRecord) error { if record.State != StateCountersign { return errors.New(\u0026#34;不在会签阶段\u0026#34;) } record.ApprovedByC = true return tryFinishCountersign(record) } // 当 B、C 都同意后，触发 FSM 的 countersign_ok func tryFinishCountersign(record *ApprovalRecord) error { if record.ApprovedByB \u0026amp;\u0026amp; record.ApprovedByC { wf := NewWorkflowFSM(record.State) if err := wf.Event(EventCountersignOK); err != nil { return err } record.State = wf.Current() // 持久化 record.State、ApprovedByB/C 到数据库 } return nil } redis 的sentinel 和cluster redis有两种分布式部署方案，分别是sentinel哨兵实现主从架构，哨兵负责监控和主节点下线之后的选主。cluster实现数据分片 和主从切换。\n哨兵只有一个主节点，cluster模式通常有多个主节点。cluster要求至少需要三主三从，cluster如果请求的数据不在当前节点会返回moved和ask,需要支持 cluster的客户端进行重定向，比如go-redis等。\n需要注意的是在分布式部署下，分布式锁都会出现问题，比如redis sentinel模式下主从切换、客户端未感知主从切换导致锁失效。 cluster模式下会出现不能多key操作以及sentinel出现的主备切换客户端无法感知等问题。\n数据分片 数据分片是指将一个大数据集按照某个规则分散成较小的数据集\n注意事项 这个理论提醒我们在分布式系统中需要根据具体的需求做出取舍。 raft协议的只保证写强一致，对于读默认是从leader读就没问题，如果从follower可能会不一致。需要注意 raft协议是在非拜占庭情况下为了达成一致性的一种协议，需要注意这点。 raft协议的组件不适合做分布式锁的实现，因为分布式锁一般对性能要求比较高，而raft需要写日志，同步等比较费时的操作。 redis分布式锁在分布式部署情况下的问题 简单来说需要把所有锁操作限定到一个槽里面，其次可以使用开源的解决方案比如redLock,以及优秀的redis客户端在发生key在其他节点会自动帮助我们 处理move操作\n参考资料 维基百科编者. CAP定理. 维基百科. 最后修订于2023年11月9日. 访问于2025年7月16日. CNBLOG. ZooKeeper 是什么. 维基百科. 最后修订于2020-12-30 10:53. 访问于2025年7月20日. ",
"tags":null,
"categories":null
},{
"title":"HeapSort",
"permalink": "http://localhost:1313/posts/datastructalgorithm/heapsort/",
"summary": "HeapSort 堆排序 我发现字节好像很喜欢考这个堆排序，再结合一些其他的场景，所以这里做下堆排序相关的总结。\n通用写法 ",
"content": "HeapSort 堆排序 我发现字节好像很喜欢考这个堆排序，再结合一些其他的场景，所以这里做下堆排序相关的总结。\n通用写法 ",
"tags":null,
"categories":null
},{
"title":"Socket",
"permalink": "http://localhost:1313/posts/network/socket/",
"summary": "Socket IO模型 常见的IO模型有四种：多进程、多线程、IO复用、协程\n多进程：最原始的一种模式，好处是开发难度小，同一个进程共享内容，缺点是创建和销毁的成本很高。常见的比如php的php-fpm 多线程：相比于多进程开销更小，但是遇到C10K问题还是会出现瓶颈，线程的内存占用通常以M为单位。提高了效率，但是遇到高并发，资源占用还是比较大。常见的比如java的多线程 IO模型: 基于事件的IO处理机制，是单线程模型，通过监听文件句柄socket,注册事件， 当有IO事件发生时，会触发回调函数。由于在单线程模型，开销更小，适合处理高并发。常见的如nodejs、redis。 协程: 协程是态线程，协程的切换开销小，通常以kb为单位，通常一个协程只占用4KB，适合处理高并发。常见的如go语言。 Socket定义 socket是应用层和传输层的一组API接口，用于实现网络通信。 linux当中一切皆文件，操作系统为了统一处理IO模型，将socket也视作文件句柄。\n特性 普通文件 Socket（网络文件） 底层对象 struct inode + struct file struct socket + struct file 操作集 read/write 操作读写磁盘数据 recv/send（也支持 read/write，最终映射到网络收发） 偏移量（offset） 有，指示文件读写位置 无意义，总是以流／报文方式收发 阻塞／非阻塞 可设置阻塞或非阻塞 同样支持阻塞模式和非阻塞模式 I/O 多路复用 支持 select/poll/epoll 完全支持 通过监听文件句柄，结合select/pull/epoll, 可以实现网络编程。\nwebsocket websocket是一种基于http的协议，用于浏览器和服务器之间进行长连接实时通信。一般会通过对http请求升级upgrade，将http协议升级为websocket协议。\n如何使用 tcp连接需要指定五元组：ip、端口、协议、源ip、源端口，同样的socket也需要指定这些参数。 server端的建立过程：\nsocket() bind() listen() accept() close client端的建立过程：\nsocket() connect() accept() close() 代码示例 原始方案，使用net包:\nsever端\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;syscall\u0026#34; ) func check(err error) { if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;错误：\u0026#34;, err) os.Exit(1) } } func main() { // 1. 创建 socket fd, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_STREAM, syscall.IPPROTO_TCP) check(err) defer syscall.Close(fd) // 2. 绑定到本地地址 0.0.0.0:8888 sa := \u0026amp;syscall.SockaddrInet4{Port: 8888} // IP 全 0 表示 INADDR_ANY check(syscall.Bind(fd, sa)) // 3. 开始监听（backlog 128） check(syscall.Listen(fd, 128)) fmt.Println(\u0026#34;raw socket 服务器已启动，端口 8888\u0026#34;) // 4. 接受连接 nfd, rsa, err := syscall.Accept(fd) check(err) fmt.Printf(\u0026#34;接收到客户端：%v\\n\u0026#34;, rsa) defer syscall.Close(nfd) // 5. 全双工：一个 goroutine 从 stdin 发出去，一个 goroutine 从 socket 读进来 go func() { buf := make([]byte, 1024) for { // 从标准输入读 n, err := syscall.Read(syscall.Stdin, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;stdin 读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { _, err = syscall.Write(nfd, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;向客户端写入错误：\u0026#34;, err) return } } } }() // 主 goroutine 负责从 socket 读并写到 stdout buf := make([]byte, 1024) for { n, err := syscall.Read(nfd, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;从客户端读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { // 打印到标准输出 _, err = syscall.Write(syscall.Stdout, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;写到 stdout 错误：\u0026#34;, err) return } } } } client端\n",
"content": "Socket IO模型 常见的IO模型有四种：多进程、多线程、IO复用、协程\n多进程：最原始的一种模式，好处是开发难度小，同一个进程共享内容，缺点是创建和销毁的成本很高。常见的比如php的php-fpm 多线程：相比于多进程开销更小，但是遇到C10K问题还是会出现瓶颈，线程的内存占用通常以M为单位。提高了效率，但是遇到高并发，资源占用还是比较大。常见的比如java的多线程 IO模型: 基于事件的IO处理机制，是单线程模型，通过监听文件句柄socket,注册事件， 当有IO事件发生时，会触发回调函数。由于在单线程模型，开销更小，适合处理高并发。常见的如nodejs、redis。 协程: 协程是态线程，协程的切换开销小，通常以kb为单位，通常一个协程只占用4KB，适合处理高并发。常见的如go语言。 Socket定义 socket是应用层和传输层的一组API接口，用于实现网络通信。 linux当中一切皆文件，操作系统为了统一处理IO模型，将socket也视作文件句柄。\n特性 普通文件 Socket（网络文件） 底层对象 struct inode + struct file struct socket + struct file 操作集 read/write 操作读写磁盘数据 recv/send（也支持 read/write，最终映射到网络收发） 偏移量（offset） 有，指示文件读写位置 无意义，总是以流／报文方式收发 阻塞／非阻塞 可设置阻塞或非阻塞 同样支持阻塞模式和非阻塞模式 I/O 多路复用 支持 select/poll/epoll 完全支持 通过监听文件句柄，结合select/pull/epoll, 可以实现网络编程。\nwebsocket websocket是一种基于http的协议，用于浏览器和服务器之间进行长连接实时通信。一般会通过对http请求升级upgrade，将http协议升级为websocket协议。\n如何使用 tcp连接需要指定五元组：ip、端口、协议、源ip、源端口，同样的socket也需要指定这些参数。 server端的建立过程：\nsocket() bind() listen() accept() close client端的建立过程：\nsocket() connect() accept() close() 代码示例 原始方案，使用net包:\nsever端\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;syscall\u0026#34; ) func check(err error) { if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;错误：\u0026#34;, err) os.Exit(1) } } func main() { // 1. 创建 socket fd, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_STREAM, syscall.IPPROTO_TCP) check(err) defer syscall.Close(fd) // 2. 绑定到本地地址 0.0.0.0:8888 sa := \u0026amp;syscall.SockaddrInet4{Port: 8888} // IP 全 0 表示 INADDR_ANY check(syscall.Bind(fd, sa)) // 3. 开始监听（backlog 128） check(syscall.Listen(fd, 128)) fmt.Println(\u0026#34;raw socket 服务器已启动，端口 8888\u0026#34;) // 4. 接受连接 nfd, rsa, err := syscall.Accept(fd) check(err) fmt.Printf(\u0026#34;接收到客户端：%v\\n\u0026#34;, rsa) defer syscall.Close(nfd) // 5. 全双工：一个 goroutine 从 stdin 发出去，一个 goroutine 从 socket 读进来 go func() { buf := make([]byte, 1024) for { // 从标准输入读 n, err := syscall.Read(syscall.Stdin, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;stdin 读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { _, err = syscall.Write(nfd, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;向客户端写入错误：\u0026#34;, err) return } } } }() // 主 goroutine 负责从 socket 读并写到 stdout buf := make([]byte, 1024) for { n, err := syscall.Read(nfd, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;从客户端读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { // 打印到标准输出 _, err = syscall.Write(syscall.Stdout, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;写到 stdout 错误：\u0026#34;, err) return } } } } client端\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;syscall\u0026#34; ) func check(err error) { if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;错误：\u0026#34;, err) os.Exit(1) } } func main() { // 1. 创建 socket fd, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_STREAM, syscall.IPPROTO_TCP) check(err) defer syscall.Close(fd) // 2. 连接到服务器 127.0.0.1:8888 sa := \u0026amp;syscall.SockaddrInet4{Port: 8888} copy(sa.Addr[:], []byte{127, 0, 0, 1}) check(syscall.Connect(fd, sa)) fmt.Println(\u0026#34;raw socket 已连接到 127.0.0.1:8888\u0026#34;) // 3. 全双工：一个 goroutine 从 stdin 发出去，一个从 socket 读进来 go func() { buf := make([]byte, 1024) for { n, err := syscall.Read(syscall.Stdin, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;stdin 读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { _, err = syscall.Write(fd, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;写到服务器错误：\u0026#34;, err) return } } } }() // 主 goroutine 负责从 socket 读并写到 stdout buf := make([]byte, 1024) for { n, err := syscall.Read(fd, buf) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;从服务器读取错误：\u0026#34;, err) return } if n \u0026gt; 0 { _, err = syscall.Write(syscall.Stdout, buf[:n]) if err != nil { fmt.Fprintln(os.Stderr, \u0026#34;写到 stdout 错误：\u0026#34;, err) return } } } } 封装成net包，代码更简洁。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; ) func main() { // socket bind listen con, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:8099\u0026#34;) if err != nil { panic(err) } conn, err := con.Accept() go func() { if _, err := io.Copy(conn, os.Stdin); err != nil { fmt.Errorf(\u0026#34;server to client :%w\u0026#34;, err) } }() if _, err := io.Copy(os.Stdout, conn); err != nil { fmt.Errorf(\u0026#34;from client :%w\u0026#34;, err) } } client端\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; ) func main() { // socket connect conn, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:8099\u0026#34;) if err != nil { panic(err) } go func() { if _, err := io.Copy(conn, os.Stdin); err != nil { fmt.Errorf(\u0026#34; to server :%w\u0026#34;, err) } }() if _, err := io.Copy(os.Stdout, conn); err != nil { fmt.Errorf(\u0026#34;from server :%w\u0026#34;, err) } } 注意事项 注意关闭文件句柄 实现高可用，需要处理重试逻辑 ",
"tags":null,
"categories":null
},{
"title":"BFS\u0026\u0026DFS",
"permalink": "http://localhost:1313/posts/datastructalgorithm/bfs_dfs/",
"summary": "树的遍历 深度优先遍历DFS package main import \u0026#34;fmt\u0026#34; func main() { root := \u0026amp;TreeNode{ Val: 1, } root.Left = \u0026amp;TreeNode{Val: 2} root.Right = \u0026amp;TreeNode{Val: 3} root.Right.Left = \u0026amp;TreeNode{Val: 4} root.Left.Left = \u0026amp;TreeNode{Val: 5} list := make([]int, 0) var treeDFS = func(root *TreeNode) {} treeDFS = func(root *TreeNode) { if root == nil { return } list = append(list, root.Val) treeDFS(root.Left) treeDFS(root.Right) } treeDFS(root) fmt.Println(list) //list2 := TreeBFS(root) //fmt.Println(list2) } type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 函数版本\npackage main import \u0026#34;fmt\u0026#34; func main() { root := \u0026amp;TreeNode{ Val: 1, } root.Left = \u0026amp;TreeNode{Val: 2} root.Right = \u0026amp;TreeNode{Val: 3} root.Right.Left = \u0026amp;TreeNode{Val: 4} root.Left.Left = \u0026amp;TreeNode{Val: 5} list := make([]int, 0) TreeDFS(root, \u0026amp;list) fmt.Println(list) //list2 := TreeBFS(root) //fmt.Println(list2) } func TreeDFS(root *TreeNode, list *[]int) { if root == nil { return } *list = append(*list, root.Val) TreeDFS(root.Left, list) TreeDFS(root.Right, list) } type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 广度优先遍历BFS list2 := make([]int, 0) queue := make([]*TreeNode, 0) queue = append(queue, root) for len(queue) \u0026gt; 0 { count := len(queue) for i := 0; i \u0026lt; count; i++ { node := queue[0] queue = queue[1:] list2 = append(list2, node.Val) if node.Left != nil { queue = append(queue, node.Left) } if node.Right != nil { queue = append(queue, node.Right) } } } fmt.Println(list2) 根据先序遍历和中序遍历构造二叉树 package main import \u0026#34;fmt\u0026#34; func main() { // 1 // [1 2 5 3 4] 先序 // [2 5 1 3 4] 中序 // 1 [2 5] [2 5] i = 2 [3 4] // [2 5 3 4] [2 5] // [5 3 4] [5] copyTreeRoot := BuildTree([]int{1, 2, 5, 3, 4}, []int{2, 5, 1, 3, 4}) fmt.Println(copyTreeRoot) list3 := make([]int, 0) TreeDFS(copyTreeRoot, \u0026amp;list3) fmt.Println(\u0026#34;list3:\u0026#34;, list3) //SliceTest() } func BuildTree(first []int, mid []int) *TreeNode { if len(first) == 0 { return nil } root := \u0026amp;TreeNode{Val: first[0]} node := first[0] i := 0 for ; i \u0026lt; len(mid); i++ { if mid[i] == node { break } } root.Left = BuildTree(first[1:i+1], mid[:i]) root.Right = BuildTree(first[i+1:], mid[i+1:]) return root } 图的遍历 深度优先遍历DFS \u0026amp;\u0026amp; 广度优先遍历BFS package main import ( \u0026#34;container/list\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { // 0 // 1 -\u0026gt; 4 -\u0026gt; 5 // 0 2 -\u0026gt; 6 -\u0026gt; 7 // 3 -\u0026gt;^ g := make([][]int, 8) //g = append(g, []int{1, 2, 3} g[0] = []int{1, 2, 3} g[1] = []int{4} g[2] = []int{6} g[3] = []int{6} g[4] = []int{5} g[6] = []int{7} g2 := make(map[int][]int) g2[0] = []int{1, 2, 3} g2[1] = []int{4} g2[2] = []int{6} g2[3] = []int{6} g2[4] = []int{5} g2[6] = []int{7} graphDFS(0, g) //graphBFS(g) fmt.Println(\u0026#34;-----\u0026#34;) graphBFSWithQueue(g2) fmt.Println(\u0026#34;-----\u0026#34;) listC := graphBFSWithC(g2) fmt.Println(listC) } func graphDFS(root int, graph [][]int) { fmt.Println(root) if graph[root] == nil { return } //fmt.Println(root) for i := 0; i \u0026lt; len(graph[root]); i++ { graphDFS(graph[root][i], graph) } return } func graphBFSWithQueue(graph map[int][]int) { queue := make([]int, 0) queue = append(queue, 0) fmt.Println(0) visited := make(map[int]bool) for len(queue) \u0026gt; 0 { node := queue[0] queue = queue[1:] g := graph[node] size := len(g) for i := 0; i \u0026lt; size; i++ { if visited[g[i]] { continue } else { fmt.Println(g[i]) queue = append(queue, g[i]) visited[g[i]] = true } } } } func graphBFSWithC(graph map[int][]int) []int { queue := list.New() order := make([]int, 0) visited := make(map[int]bool) queue.PushBack(0) for queue.Len() \u0026gt; 0 { node := queue.Remove(queue.Front()).(int) order = append(order, node) neighbor := graph[node] size := len(neighbor) for i := 0; i \u0026lt; size; i++ { if visited[neighbor[i]] { continue } else { queue.PushBack(neighbor[i]) visited[neighbor[i]] = true } } } return order } 带权图的最短路径算法 dijkstra 参考 可视化网站. 可视化网站. ",
"content": "树的遍历 深度优先遍历DFS package main import \u0026#34;fmt\u0026#34; func main() { root := \u0026amp;TreeNode{ Val: 1, } root.Left = \u0026amp;TreeNode{Val: 2} root.Right = \u0026amp;TreeNode{Val: 3} root.Right.Left = \u0026amp;TreeNode{Val: 4} root.Left.Left = \u0026amp;TreeNode{Val: 5} list := make([]int, 0) var treeDFS = func(root *TreeNode) {} treeDFS = func(root *TreeNode) { if root == nil { return } list = append(list, root.Val) treeDFS(root.Left) treeDFS(root.Right) } treeDFS(root) fmt.Println(list) //list2 := TreeBFS(root) //fmt.Println(list2) } type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 函数版本\npackage main import \u0026#34;fmt\u0026#34; func main() { root := \u0026amp;TreeNode{ Val: 1, } root.Left = \u0026amp;TreeNode{Val: 2} root.Right = \u0026amp;TreeNode{Val: 3} root.Right.Left = \u0026amp;TreeNode{Val: 4} root.Left.Left = \u0026amp;TreeNode{Val: 5} list := make([]int, 0) TreeDFS(root, \u0026amp;list) fmt.Println(list) //list2 := TreeBFS(root) //fmt.Println(list2) } func TreeDFS(root *TreeNode, list *[]int) { if root == nil { return } *list = append(*list, root.Val) TreeDFS(root.Left, list) TreeDFS(root.Right, list) } type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 广度优先遍历BFS list2 := make([]int, 0) queue := make([]*TreeNode, 0) queue = append(queue, root) for len(queue) \u0026gt; 0 { count := len(queue) for i := 0; i \u0026lt; count; i++ { node := queue[0] queue = queue[1:] list2 = append(list2, node.Val) if node.Left != nil { queue = append(queue, node.Left) } if node.Right != nil { queue = append(queue, node.Right) } } } fmt.Println(list2) 根据先序遍历和中序遍历构造二叉树 package main import \u0026#34;fmt\u0026#34; func main() { // 1 // [1 2 5 3 4] 先序 // [2 5 1 3 4] 中序 // 1 [2 5] [2 5] i = 2 [3 4] // [2 5 3 4] [2 5] // [5 3 4] [5] copyTreeRoot := BuildTree([]int{1, 2, 5, 3, 4}, []int{2, 5, 1, 3, 4}) fmt.Println(copyTreeRoot) list3 := make([]int, 0) TreeDFS(copyTreeRoot, \u0026amp;list3) fmt.Println(\u0026#34;list3:\u0026#34;, list3) //SliceTest() } func BuildTree(first []int, mid []int) *TreeNode { if len(first) == 0 { return nil } root := \u0026amp;TreeNode{Val: first[0]} node := first[0] i := 0 for ; i \u0026lt; len(mid); i++ { if mid[i] == node { break } } root.Left = BuildTree(first[1:i+1], mid[:i]) root.Right = BuildTree(first[i+1:], mid[i+1:]) return root } 图的遍历 深度优先遍历DFS \u0026amp;\u0026amp; 广度优先遍历BFS package main import ( \u0026#34;container/list\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { // 0 // 1 -\u0026gt; 4 -\u0026gt; 5 // 0 2 -\u0026gt; 6 -\u0026gt; 7 // 3 -\u0026gt;^ g := make([][]int, 8) //g = append(g, []int{1, 2, 3} g[0] = []int{1, 2, 3} g[1] = []int{4} g[2] = []int{6} g[3] = []int{6} g[4] = []int{5} g[6] = []int{7} g2 := make(map[int][]int) g2[0] = []int{1, 2, 3} g2[1] = []int{4} g2[2] = []int{6} g2[3] = []int{6} g2[4] = []int{5} g2[6] = []int{7} graphDFS(0, g) //graphBFS(g) fmt.Println(\u0026#34;-----\u0026#34;) graphBFSWithQueue(g2) fmt.Println(\u0026#34;-----\u0026#34;) listC := graphBFSWithC(g2) fmt.Println(listC) } func graphDFS(root int, graph [][]int) { fmt.Println(root) if graph[root] == nil { return } //fmt.Println(root) for i := 0; i \u0026lt; len(graph[root]); i++ { graphDFS(graph[root][i], graph) } return } func graphBFSWithQueue(graph map[int][]int) { queue := make([]int, 0) queue = append(queue, 0) fmt.Println(0) visited := make(map[int]bool) for len(queue) \u0026gt; 0 { node := queue[0] queue = queue[1:] g := graph[node] size := len(g) for i := 0; i \u0026lt; size; i++ { if visited[g[i]] { continue } else { fmt.Println(g[i]) queue = append(queue, g[i]) visited[g[i]] = true } } } } func graphBFSWithC(graph map[int][]int) []int { queue := list.New() order := make([]int, 0) visited := make(map[int]bool) queue.PushBack(0) for queue.Len() \u0026gt; 0 { node := queue.Remove(queue.Front()).(int) order = append(order, node) neighbor := graph[node] size := len(neighbor) for i := 0; i \u0026lt; size; i++ { if visited[neighbor[i]] { continue } else { queue.PushBack(neighbor[i]) visited[neighbor[i]] = true } } } return order } 带权图的最短路径算法 dijkstra 参考 可视化网站. 可视化网站. ",
"tags":["算法","数据结构","BFS","DFS","dijkstra"],
"categories":null
},{
"title":"https原理",
"permalink": "http://localhost:1313/posts/network/https/",
"summary": "定义 http http是超文本传输协议，用于传输网页内容，它基于TCP，所以是可靠性传输。但是它没有解决数据安全性 方面的问题\nhttp安全方面的问题 http没有对数据进行加密，任何人都可以随意读取这些数据，遭成数据的泄密。 其次没有认证，也就是没有办法知道数据来源的可靠性，攻击者可以中间人攻击来伪造数据 数据完整性，任何人可以读取也可以修改数据 https是什么 https是http的安全版本，https基于ssl，ssl基于tls。http+数据加密+认证+数据完整性就是https。\nhttps怎么解决的这些问题 数据加密 加密算法 加密算法分为对称加密和非对称加密，还有一些摘要算法 / 哈希算法，一下是一些常见的加密算法\n类型 示例 是否可逆 说明 对称加密 DES / AES / 3DES ✅ 加密解密用同一密钥 非对称加密 RSA / ECC ✅ 公钥加密，私钥解密 摘要算法 MD5 / SHA256 ❌ 不可逆，用于校验完整性 签名算法 DSA / RSA签名 ❌ 用私钥签名，公钥验签 服务器端生成密钥对，将公钥发送给客户端，客户端使用公钥加密对称加密使用的秘钥，发送给服务器端，服务器端使用私钥解密数据， 得到秘钥，后续通过这个秘钥对数据进行加密解密。\nCA CA（Certificate Authority）是证书颁发机构，它负责签发证书，并管理证书的颁发和吊销。\n为什么需要CA 客户端无法知晓拿到的公钥是由目标服务器颁发的，为了验证证书的合法性，防护中间人攻击，需要CA证书颁发机构签发证书。\n证书生成 首先，服务器管理员会向CA提起证书申请，CA会验证域名的所属权，做法通常是在域名解析加一个特定值。 验证通过后，CA会将服务器的公钥用自己的私钥进行签名，生成证书。并颁发给服务器管理员。\n证书验证过程 客户端发起连接请求，服务器会返回证书，客户端会验证证书的合法性，并获取证书的公钥。 浏览器会在发版的时候将各大CA机构的公钥预制在浏览器中，使用CA的公钥对服务器的证书进行解密，拿到解密的hash值。同时 使用同样的摘要算法对原始内容进行加密，用得到的摘要和解密的摘要对比，如果相等，说明证书是CA颁发的，也就证明 了证书的合法性和完整性。\n",
"content": "定义 http http是超文本传输协议，用于传输网页内容，它基于TCP，所以是可靠性传输。但是它没有解决数据安全性 方面的问题\nhttp安全方面的问题 http没有对数据进行加密，任何人都可以随意读取这些数据，遭成数据的泄密。 其次没有认证，也就是没有办法知道数据来源的可靠性，攻击者可以中间人攻击来伪造数据 数据完整性，任何人可以读取也可以修改数据 https是什么 https是http的安全版本，https基于ssl，ssl基于tls。http+数据加密+认证+数据完整性就是https。\nhttps怎么解决的这些问题 数据加密 加密算法 加密算法分为对称加密和非对称加密，还有一些摘要算法 / 哈希算法，一下是一些常见的加密算法\n类型 示例 是否可逆 说明 对称加密 DES / AES / 3DES ✅ 加密解密用同一密钥 非对称加密 RSA / ECC ✅ 公钥加密，私钥解密 摘要算法 MD5 / SHA256 ❌ 不可逆，用于校验完整性 签名算法 DSA / RSA签名 ❌ 用私钥签名，公钥验签 服务器端生成密钥对，将公钥发送给客户端，客户端使用公钥加密对称加密使用的秘钥，发送给服务器端，服务器端使用私钥解密数据， 得到秘钥，后续通过这个秘钥对数据进行加密解密。\nCA CA（Certificate Authority）是证书颁发机构，它负责签发证书，并管理证书的颁发和吊销。\n为什么需要CA 客户端无法知晓拿到的公钥是由目标服务器颁发的，为了验证证书的合法性，防护中间人攻击，需要CA证书颁发机构签发证书。\n证书生成 首先，服务器管理员会向CA提起证书申请，CA会验证域名的所属权，做法通常是在域名解析加一个特定值。 验证通过后，CA会将服务器的公钥用自己的私钥进行签名，生成证书。并颁发给服务器管理员。\n证书验证过程 客户端发起连接请求，服务器会返回证书，客户端会验证证书的合法性，并获取证书的公钥。 浏览器会在发版的时候将各大CA机构的公钥预制在浏览器中，使用CA的公钥对服务器的证书进行解密，拿到解密的hash值。同时 使用同样的摘要算法对原始内容进行加密，用得到的摘要和解密的摘要对比，如果相等，说明证书是CA颁发的，也就证明 了证书的合法性和完整性。\n",
"tags":["计算机网络","https"],
"categories":null
},{
"title":"About Me",
"permalink": "http://localhost:1313/about/me/",
"summary": " 三年PHP经验，2年全栈经验，三年golang经验，持续学习中\u0026hellip; ",
"content": " 三年PHP经验，2年全栈经验，三年golang经验，持续学习中\u0026hellip; ",
"tags":null,
"categories":null
},{
"title":"golang的interface和reflect",
"permalink": "http://localhost:1313/posts/go/interfacereflect/",
"summary": "interface 鸭子类型 如果一个东西，走起来像鸭子，叫起来像鸭子，那么我们认为他就是鸭子。也就是说我们关注对象的行为，而不是对象本身。\ngo里面通过接口来达到鸭子类型的效果。\n多态 多态是指同一个操作（函数、方法），在不通的对象的作用下，会有不同的行为。 一般多态有两种实现方式：\n继承和组合，比如java、c++。 接口的形式 在go里面它没有继承的概念，但是go里面有组合。组合式是一种更灵活的方式。 他可以通过组合和重写来实现继承。在调用结构体的方法的时候，会优先调用最近的结构体的方法。 我们推荐在go里通过接口来实现多态，会更加清晰明了。\ngo的interface 定义 go里面的接口是一种复合数据类型。他的底层有2种实现，eface和iface。\n//eface 结构 type eface struct { tab *typtab data unsafe.Pointer } // iface结构 type iface struct { tab *itab data unsafe.Pointer } go里面的所有数据类型都实现了eface,也就是说可以借助interface来表示他的数据类型。 还可以通过interface来定义方法集合 。\ntype A interface { method() } 可能你会有一个疑问，那go是怎么确定interface 到底应该是使用eface 还是 iface呢？ go是在编译阶段就会确定好interface 使用的eface 还是 iface。后面不会改变。\n如何使用 什么时候会使用interface 通过接口来实现解耦合，比如依赖注入、适配器模式。 不确定传入参数的类型，需要在运行时来确定。 使用方法 接口列表 type animal interface { move() } type dog struct {} func (d dog) move() { fmt.Println(\u0026#34;dog moving\u0026#34;) } type cat struct {} func (c cat) move() { fmt.Println(\u0026#34;cat moving\u0026#34;) } func main() { var a animal a = dog{} a.move() a = cat{} // a是结构可以同意调用 a.move() // 接口注入 call(a) // 不确定具体的参数 vat func1 = func(param any) {} func1 = func(param any) { fmt.Println(\u0026#34;call any\u0026#34;, param) } } func call(a animal) { fmt.Println(\u0026#34;call animal \\n\u0026#34;) a.move() } 需要注意的点和坑 使用接口会让编译器无法确定数据类型，导致无法再编译阶段发现类型错误，引发运行时错误。 使用接口会让程序变得难以阅读和理解。 性能会损失大概一倍 reflect unsafe.pointer go语言unsafe包提供了一些函数，可以获取指针，修改指针，获取指针指向的数据，修改指针指向的数据。 简单来讲，go本身不能操作指针，但是提供了reflect包让我们可以操作指针来获得程序的 性能提升。\n",
"content": "interface 鸭子类型 如果一个东西，走起来像鸭子，叫起来像鸭子，那么我们认为他就是鸭子。也就是说我们关注对象的行为，而不是对象本身。\ngo里面通过接口来达到鸭子类型的效果。\n多态 多态是指同一个操作（函数、方法），在不通的对象的作用下，会有不同的行为。 一般多态有两种实现方式：\n继承和组合，比如java、c++。 接口的形式 在go里面它没有继承的概念，但是go里面有组合。组合式是一种更灵活的方式。 他可以通过组合和重写来实现继承。在调用结构体的方法的时候，会优先调用最近的结构体的方法。 我们推荐在go里通过接口来实现多态，会更加清晰明了。\ngo的interface 定义 go里面的接口是一种复合数据类型。他的底层有2种实现，eface和iface。\n//eface 结构 type eface struct { tab *typtab data unsafe.Pointer } // iface结构 type iface struct { tab *itab data unsafe.Pointer } go里面的所有数据类型都实现了eface,也就是说可以借助interface来表示他的数据类型。 还可以通过interface来定义方法集合 。\ntype A interface { method() } 可能你会有一个疑问，那go是怎么确定interface 到底应该是使用eface 还是 iface呢？ go是在编译阶段就会确定好interface 使用的eface 还是 iface。后面不会改变。\n如何使用 什么时候会使用interface 通过接口来实现解耦合，比如依赖注入、适配器模式。 不确定传入参数的类型，需要在运行时来确定。 使用方法 接口列表 type animal interface { move() } type dog struct {} func (d dog) move() { fmt.Println(\u0026#34;dog moving\u0026#34;) } type cat struct {} func (c cat) move() { fmt.Println(\u0026#34;cat moving\u0026#34;) } func main() { var a animal a = dog{} a.move() a = cat{} // a是结构可以同意调用 a.move() // 接口注入 call(a) // 不确定具体的参数 vat func1 = func(param any) {} func1 = func(param any) { fmt.Println(\u0026#34;call any\u0026#34;, param) } } func call(a animal) { fmt.Println(\u0026#34;call animal \\n\u0026#34;) a.move() } 需要注意的点和坑 使用接口会让编译器无法确定数据类型，导致无法再编译阶段发现类型错误，引发运行时错误。 使用接口会让程序变得难以阅读和理解。 性能会损失大概一倍 reflect unsafe.pointer go语言unsafe包提供了一些函数，可以获取指针，修改指针，获取指针指向的数据，修改指针指向的数据。 简单来讲，go本身不能操作指针，但是提供了reflect包让我们可以操作指针来获得程序的 性能提升。\n定义 在计算机领域，反射（Reflection）是指程序在运行时能够检查自身，并获取其内部信息。可以修改数据，调用方法的 一种能力。 go语言提供了一种在运行时能够获取数据本身的状态，数据，和调用方法的能力，在编译阶段 是不知道具体的类型的，需要在运行时确定。\n使用 常见使用场景 函数参数的动态传入，通过reflect获取参数的类型 动态修改切片，map，结构体 动态创建函数 GORM,通过反射获取结构体的tag来构建数据的sql语句 使用方法 reflect.ValueOf(a) reflect.TypeOf((a) 对指针解引用 reflect.ValueOf(a).Elem() 获取指针类型 reflect.TypeOf(a).Elem() 获取tag reflect.TypeOf(a).Elem().Field(0).Tag.Get(\u0026#34;json\u0026#34;) 获取字段 reflect.TypeOf(a).Elem().Field(0) 动态创建函数 func1 := reflect.MakeFunc(reflect.TypeOf(func(param any) {}), func(args []reflect.Value) []reflect.Value {}) // 动态调用函数 func1.Call([]reflect.Value{reflect.ValueOf(param)}) 需要注意的点和坑 使用反射会损失性能 使用反射会改变代码的可读性 编译器不能检查数据类型，会引发运行时错误 ",
"tags":["go","interface","reflect"],
"categories":null
}]